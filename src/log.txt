file_path :  src/mnist_train.csv
save_file :  src/mnist_train.npz
file_path :  src/mnist_test.csv
save_file :  src/mnist_test.npz
Weights loaded from src/weights_.npz
batch_rate :  0.001
  LR: 0.9
  LR: 0.9, Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  LR: 0.9, Hidden Size: 784, Sample: 1/1
  LR: 0.9, Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.9
    batch_rate :          0.001
      exponential decayed learning_rate :              0.9
      batch rate adapted learning_rate :              0.0009000000000000001
      fit adapted learning_rate :              0.0009000000000000001
    epoch : 0 ; learning_rate : 0.0009000000000000001 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 0.7990018389620848
    Epoch 0, Loss: 1.3250906522935977, fit: 0.5166666666666667
    Epoch 0, Loss: 1.3250906522935977
      Weights saved to src/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_0.9145691605781531_fit_0.51666666666666672024-01-02170720
  self.fit : 0.5166666666666667
  self.loss : 0.9145691605781531
  current_accuracy : 0.4766
  LR: 0.9, Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          0.9
    batch_rate :          0.001
      exponential decayed learning_rate :              0.9
      batch rate adapted learning_rate :              0.0009000000000000001
      fit adapted learning_rate :              2.680504184676138e-06
    epoch : 0 ; learning_rate : 2.680504184676138e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.6352921711507652
    Epoch 0, Loss: 1.0065801660479994, fit: 0.48333333333333334
    Epoch 0, Loss: 1.0065801660479994
      exponential decayed learning_rate :              0.8900553503645301
      batch rate adapted learning_rate :              0.0008900553503645301
      fit adapted learning_rate :              4.5196058572454425e-06
    epoch : 1 ; learning_rate : 4.5196058572454425e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.6338202237185573
    Epoch 1, Loss: 1.0049481237974445, fit: 0.4
      exponential decayed learning_rate :              0.8802205852361404
      batch rate adapted learning_rate :              0.0008802205852361405
      fit adapted learning_rate :              1.4784325784919849e-05
    epoch : 2 ; learning_rate : 1.4784325784919849e-05 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.5698927985098209
    Epoch 2, Loss: 1.0006864202960701, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.8704944904338053
      batch rate adapted learning_rate :              0.0008704944904338053
      fit adapted learning_rate :              5.698438298676083e-06
    epoch : 3 ; learning_rate : 5.698438298676083e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.5702861464369489
    Epoch 3, Loss: 0.9963236096596072, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.8608758651927264
      batch rate adapted learning_rate :              0.0008608758651927265
      fit adapted learning_rate :              2.228431569421747e-05
    epoch : 4 ; learning_rate : 2.228431569421747e-05 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.5948343471157254
    Epoch 4, Loss: 0.9904549610845245, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.8513635220160889
      batch rate adapted learning_rate :              0.0008513635220160889
      fit adapted learning_rate :              7.73437285543277e-07
    epoch : 5 ; learning_rate : 7.73437285543277e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.6106664155510598
    Epoch 5, Loss: 0.9857157325788847, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.841956286528456
      batch rate adapted learning_rate :              0.0008419562865284561
      fit adapted learning_rate :              1.8938422089454287e-06
    epoch : 6 ; learning_rate : 1.8938422089454287e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.639556978505571
    Epoch 6, Loss: 0.9851826437559861, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.8326529973307818
      batch rate adapted learning_rate :              0.0008326529973307818
      fit adapted learning_rate :              1.1163449226604947e-05
    epoch : 7 ; learning_rate : 1.1163449226604947e-05 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.5265371286642941
    Epoch 7, Loss: 0.982603496644073, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.8234525058570279
      batch rate adapted learning_rate :              0.0008234525058570279
      fit adapted learning_rate :              8.75507536205191e-06
    epoch : 8 ; learning_rate : 8.75507536205191e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.6160241459449247
    Epoch 8, Loss: 0.9787114256586198, fit: 0.5333333333333333
      Weights saved to src/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_0.8937479157941765_fit_0.53333333333333332024-01-02170823
  self.fit : 0.5333333333333333
  self.loss : 0.8937479157941765
  current_accuracy : 0.4915
  LR: 0.9, Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          0.9
    batch_rate :          0.001
      exponential decayed learning_rate :              0.9
      batch rate adapted learning_rate :              0.0009000000000000001
      fit adapted learning_rate :              2.0244019972565163e-06
    epoch : 0 ; learning_rate : 2.0244019972565163e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.558118964046926
    Epoch 0, Loss: 0.9766090205275447, fit: 0.38333333333333336
    Epoch 0, Loss: 0.9766090205275447
      exponential decayed learning_rate :              0.8989893319423155
      batch rate adapted learning_rate :              0.0008989893319423154
      fit adapted learning_rate :              1.880002070557526e-05
    epoch : 1 ; learning_rate : 1.880002070557526e-05 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.6480970982899069
    Epoch 1, Loss: 0.9726297541321697, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8979797988289894
      batch rate adapted learning_rate :              0.0008979797988289894
      fit adapted learning_rate :              2.019857886939345e-06
    epoch : 2 ; learning_rate : 2.019857886939345e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5404300478310325
    Epoch 2, Loss: 0.9687765588133203, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.8969713993855201
      batch rate adapted learning_rate :              0.0008969713993855201
      fit adapted learning_rate :              5.871761661039723e-06
    epoch : 3 ; learning_rate : 5.871761661039723e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.6295907759821839
    Epoch 3, Loss: 0.9673405879587398, fit: 0.45
      exponential decayed learning_rate :              0.895964132338836
      batch rate adapted learning_rate :              0.000895964132338836
      fit adapted learning_rate :              7.502260500948787e-06
    epoch : 4 ; learning_rate : 7.502260500948787e-06 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.5617422303812591
    Epoch 4, Loss: 0.9648607747354959, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.8949579964172959
      batch rate adapted learning_rate :              0.0008949579964172959
      fit adapted learning_rate :              1.199877762402337e-05
    epoch : 5 ; learning_rate : 1.199877762402337e-05 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.5489964466015392
    Epoch 5, Loss: 0.9613450466024899, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8939529903506866
      batch rate adapted learning_rate :              0.0008939529903506867
      fit adapted learning_rate :              2.0108002434659613e-06
    epoch : 6 ; learning_rate : 2.0108002434659613e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5565565744276617
    Epoch 6, Loss: 0.958866861295347, fit: 0.45
      exponential decayed learning_rate :              0.8929491128702209
      batch rate adapted learning_rate :              0.000892949112870221
      fit adapted learning_rate :              7.477014555656383e-06
    epoch : 7 ; learning_rate : 7.477014555656383e-06 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.6069308822135857
    Epoch 7, Loss: 0.9571877064142015, fit: 0.5
      exponential decayed learning_rate :              0.8919463627085368
      batch rate adapted learning_rate :              0.0008919463627085368
      fit adapted learning_rate :              3.484165479330222e-06
    epoch : 8 ; learning_rate : 3.484165479330222e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.6046845151913037
    Epoch 8, Loss: 0.955235778024106, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8909447385996951
      batch rate adapted learning_rate :              0.0008909447385996951
      fit adapted learning_rate :              4.524122075563068e-06
    epoch : 9 ; learning_rate : 4.524122075563068e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.5210115882859931
    Epoch 9, Loss: 0.9537991213576785, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.8899442392791785
      batch rate adapted learning_rate :              0.0008899442392791785
      fit adapted learning_rate :              8.084866674613723e-07
    epoch : 10 ; learning_rate : 8.084866674613723e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.5499309549710101
    Epoch 10, Loss: 0.9528660834874343, fit: 0.43333333333333335
    Epoch 10, Loss: 0.9528660834874343
      exponential decayed learning_rate :              0.8889448634838898
      batch rate adapted learning_rate :              0.0008889448634838898
      fit adapted learning_rate :              9.451400314108325e-06
    epoch : 11 ; learning_rate : 9.451400314108325e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.5668127698834647
    Epoch 11, Loss: 0.9510453685128144, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8879466099521498
      batch rate adapted learning_rate :              0.0008879466099521498
      fit adapted learning_rate :              1.9972898784936494e-06
    epoch : 12 ; learning_rate : 1.9972898784936494e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.6038993116481833
    Epoch 12, Loss: 0.949054214392666, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.8869494774236966
      batch rate adapted learning_rate :              0.0008869494774236965
      fit adapted learning_rate :              2.2959247620800717e-05
    epoch : 13 ; learning_rate : 2.2959247620800717e-05 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.5968828816090469
    Epoch 13, Loss: 0.9448380883375321, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.8859534646396829
      batch rate adapted learning_rate :              0.0008859534646396829
      fit adapted learning_rate :              5.79963596464766e-06
    epoch : 14 ; learning_rate : 5.79963596464766e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.5168128936757165
    Epoch 14, Loss: 0.9398388388343649, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8849585703426759
      batch rate adapted learning_rate :              0.0008849585703426759
      fit adapted learning_rate :              1.99056877476776e-06
    epoch : 15 ; learning_rate : 1.99056877476776e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5414556936717752
    Epoch 15, Loss: 0.938486916609266, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.883964793276654
      batch rate adapted learning_rate :              0.000883964793276654
      fit adapted learning_rate :              9.398451431613542e-06
    epoch : 16 ; learning_rate : 9.398451431613542e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.50583945587249
    Epoch 16, Loss: 0.9366117409707747, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8829721321870068
      batch rate adapted learning_rate :              0.0008829721321870068
      fit adapted learning_rate :              4.483638033053194e-06
    epoch : 17 ; learning_rate : 4.483638033053194e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.5179139682251497
    Epoch 17, Loss: 0.9342997138094034, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8819805858205323
      batch rate adapted learning_rate :              0.0008819805858205323
      fit adapted learning_rate :              1.983870288307286e-06
    epoch : 18 ; learning_rate : 1.983870288307286e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.6007759494818947
    Epoch 18, Loss: 0.9332361577844693, fit: 0.55
      exponential decayed learning_rate :              0.8809901529254359
      batch rate adapted learning_rate :              0.000880990152925436
      fit adapted learning_rate :              1.4813959889347089e-06
    epoch : 19 ; learning_rate : 1.4813959889347089e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.5803436343583811
    Epoch 19, Loss: 0.9326631076367449, fit: 0.6833333333333333
      exponential decayed learning_rate :              0.8800008322513287
      batch rate adapted learning_rate :              0.0008800008322513288
      fit adapted learning_rate :              8.898194355538946e-08
    epoch : 20 ; learning_rate : 8.898194355538946e-08 ; fit : 0.6833333333333333
    batch_size :          60
    best_batch_loss : 0.5533704525924179
    Epoch 20, Loss: 0.9324121397311802, fit: 0.4166666666666667
    Epoch 20, Loss: 0.9324121397311802
      exponential decayed learning_rate :              0.8790126225492262
      batch rate adapted learning_rate :              0.0008790126225492262
      fit adapted learning_rate :              1.178499664665818e-05
    epoch : 21 ; learning_rate : 1.178499664665818e-05 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.5278928146913935
    Epoch 21, Loss: 0.9305091491366161, fit: 0.55
      exponential decayed learning_rate :              0.8780255225715461
      batch rate adapted learning_rate :              0.0008780255225715461
      fit adapted learning_rate :              1.4764109258209578e-06
    epoch : 22 ; learning_rate : 1.4764109258209578e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.5588616263993255
    Epoch 22, Loss: 0.9283609320160485, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8770395310721073
      batch rate adapted learning_rate :              0.0008770395310721073
      fit adapted learning_rate :              1.0904253757460025e-06
    epoch : 23 ; learning_rate : 1.0904253757460025e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5617147323943648
    Epoch 23, Loss: 0.9279461517962695, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8760546468061281
      batch rate adapted learning_rate :              0.0008760546468061281
      fit adapted learning_rate :              1.970540863000197e-06
    epoch : 24 ; learning_rate : 1.970540863000197e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5700405151603545
    Epoch 24, Loss: 0.9274542164138441, fit: 0.55
      exponential decayed learning_rate :              0.8750708685302246
      batch rate adapted learning_rate :              0.0008750708685302247
      fit adapted learning_rate :              1.471442638001884e-06
    epoch : 25 ; learning_rate : 1.471442638001884e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.5481121241901692
    Epoch 25, Loss: 0.9269070713898266, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8740881950024092
      batch rate adapted learning_rate :              0.0008740881950024093
      fit adapted learning_rate :              1.086755972453748e-06
    epoch : 26 ; learning_rate : 1.086755972453748e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5215744226640123
    Epoch 26, Loss: 0.9265018467006143, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.873106624982089
      batch rate adapted learning_rate :              0.000873106624982089
      fit adapted learning_rate :              2.6004066243699433e-06
    epoch : 27 ; learning_rate : 2.6004066243699433e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5106787786239362
    Epoch 27, Loss: 0.9259285657721924, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.8721261572300644
      batch rate adapted learning_rate :              0.0008721261572300643
      fit adapted learning_rate :              9.272581208334638e-06
    epoch : 28 ; learning_rate : 9.272581208334638e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.5254807962684637
    Epoch 28, Loss: 0.9240480037349996, fit: 0.6333333333333333
      exponential decayed learning_rate :              0.8711467905085268
      batch rate adapted learning_rate :              0.0008711467905085269
      fit adapted learning_rate :              2.846182764824712e-07
    epoch : 29 ; learning_rate : 2.846182764824712e-07 ; fit : 0.6333333333333333
    batch_size :          60
    best_batch_loss : 0.5455977829210835
    Epoch 29, Loss: 0.922547135498891, fit: 0.55
      exponential decayed learning_rate :              0.8701685235810587
      batch rate adapted learning_rate :              0.0008701685235810587
      fit adapted learning_rate :              1.4631992834990518e-06
    epoch : 30 ; learning_rate : 1.4631992834990518e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.48123508955127847
    Epoch 30, Loss: 0.9222780504069857, fit: 0.5
    Epoch 30, Loss: 0.9222780504069857
      exponential decayed learning_rate :              0.8691913552126297
      batch rate adapted learning_rate :              0.0008691913552126297
      fit adapted learning_rate :              3.3952787312993346e-06
    epoch : 31 ; learning_rate : 3.3952787312993346e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.5257020736973631
    Epoch 31, Loss: 0.9215294796017992, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8682152841695976
      batch rate adapted learning_rate :              0.0008682152841695976
      fit adapted learning_rate :              1.079454168173885e-06
    epoch : 32 ; learning_rate : 1.079454168173885e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.39536691282064934
    Epoch 32, Loss: 0.920820665044714, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.8672403092197045
      batch rate adapted learning_rate :              0.0008672403092197046
      fit adapted learning_rate :              9.220634110919819e-06
    epoch : 33 ; learning_rate : 9.220634110919819e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.5304451316263378
    Epoch 33, Loss: 0.9192420762750536, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.8662664291320767
      batch rate adapted learning_rate :              0.0008662664291320767
      fit adapted learning_rate :              7.869761132337067e-07
    epoch : 34 ; learning_rate : 7.869761132337067e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.48719255297716135
    Epoch 34, Loss: 0.9176909172089462, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.8652936426772231
      batch rate adapted learning_rate :              0.0008652936426772231
      fit adapted learning_rate :              7.860923669894778e-07
    epoch : 35 ; learning_rate : 7.860923669894778e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.5123285889090873
    Epoch 35, Loss: 0.9174455102511122, fit: 0.45
      exponential decayed learning_rate :              0.8643219486270326
      batch rate adapted learning_rate :              0.0008643219486270326
      fit adapted learning_rate :              7.237308036383997e-06
    epoch : 36 ; learning_rate : 7.237308036383997e-06 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.5333919249746032
    Epoch 36, Loss: 0.916239257660092, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8633513457547737
      batch rate adapted learning_rate :              0.0008633513457547737
      fit adapted learning_rate :              1.073406821747999e-06
    epoch : 37 ; learning_rate : 1.073406821747999e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.4660323100171369
    Epoch 37, Loss: 0.9149627503706145, fit: 0.5
      exponential decayed learning_rate :              0.8623818328350921
      batch rate adapted learning_rate :              0.0008623818328350921
      fit adapted learning_rate :              3.3686790345120784e-06
    epoch : 38 ; learning_rate : 3.3686790345120784e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.5145755715776039
    Epoch 38, Loss: 0.9142928728954094, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8614134086440098
      batch rate adapted learning_rate :              0.0008614134086440099
      fit adapted learning_rate :              2.565580274007116e-06
    epoch : 39 ; learning_rate : 2.565580274007116e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5730930188542162
    Epoch 39, Loss: 0.9134109486650069, fit: 0.6166666666666667
      exponential decayed learning_rate :              0.8604460719589235
      batch rate adapted learning_rate :              0.0008604460719589236
      fit adapted learning_rate :              4.011772909776371e-07
    epoch : 40 ; learning_rate : 4.011772909776371e-07 ; fit : 0.6166666666666667
    batch_size :          60
    best_batch_loss : 0.5345495677079043
    Epoch 40, Loss: 0.9129485331475016, fit: 0.5
    Epoch 40, Loss: 0.9129485331475016
      exponential decayed learning_rate :              0.8594798215586023
      batch rate adapted learning_rate :              0.0008594798215586023
      fit adapted learning_rate :              3.3573430529632903e-06
    epoch : 41 ; learning_rate : 3.3573430529632903e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.5960214079963108
    Epoch 41, Loss: 0.9123962547731871, fit: 0.55
      exponential decayed learning_rate :              0.858514656223187
      batch rate adapted learning_rate :              0.000858514656223187
      fit adapted learning_rate :              1.4436031594082194e-06
    epoch : 42 ; learning_rate : 1.4436031594082194e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.49873111272358994
    Epoch 42, Loss: 0.9116621888082502, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8575505747341883
      batch rate adapted learning_rate :              0.0008575505747341883
      fit adapted learning_rate :              1.9289189958226264e-06
    epoch : 43 ; learning_rate : 1.9289189958226264e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5117207546089995
    Epoch 43, Loss: 0.9111536344764141, fit: 0.6166666666666667
      exponential decayed learning_rate :              0.856587575874485
      batch rate adapted learning_rate :              0.0008565875758744849
      fit adapted learning_rate :              3.993782926942481e-07
    epoch : 44 ; learning_rate : 3.993782926942481e-07 ; fit : 0.6166666666666667
    batch_size :          60
    best_batch_loss : 0.5355198341250241
    Epoch 44, Loss: 0.9108109552118366, fit: 0.5
      exponential decayed learning_rate :              0.8556256584283229
      batch rate adapted learning_rate :              0.000855625658428323
      fit adapted learning_rate :              3.3422877282356366e-06
    epoch : 45 ; learning_rate : 3.3422877282356366e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.488793589630977
    Epoch 45, Loss: 0.9102584149367023, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.8546648211813132
      batch rate adapted learning_rate :              0.0008546648211813131
      fit adapted learning_rate :              9.086929562439381e-06
    epoch : 46 ; learning_rate : 9.086929562439381e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.5298344726916526
    Epoch 46, Loss: 0.9084329461633502, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.85370506292043
      batch rate adapted learning_rate :              0.00085370506292043
      fit adapted learning_rate :              2.542622215152687e-06
    epoch : 47 ; learning_rate : 2.542622215152687e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5042625902248469
    Epoch 47, Loss: 0.9066840703483395, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8527463824340109
      batch rate adapted learning_rate :              0.0008527463824340109
      fit adapted learning_rate :              4.330154909147106e-06
    epoch : 48 ; learning_rate : 4.330154909147106e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.46353540523807274
    Epoch 48, Loss: 0.905656852758531, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8517887785117528
      batch rate adapted learning_rate :              0.0008517887785117528
      fit adapted learning_rate :              1.0590310538562743e-06
    epoch : 49 ; learning_rate : 1.0590310538562743e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5540995801047939
    Epoch 49, Loss: 0.9048713887827845, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.8508322499447127
      batch rate adapted learning_rate :              0.0008508322499447128
      fit adapted learning_rate :              9.046181067816796e-06
    epoch : 50 ; learning_rate : 9.046181067816796e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.5227496725587856
    Epoch 50, Loss: 0.9034095673297141, fit: 0.4666666666666667
    Epoch 50, Loss: 0.9034095673297141
      exponential decayed learning_rate :              0.849876795525305
      batch rate adapted learning_rate :              0.0008498767955253051
      fit adapted learning_rate :              5.563470572184825e-06
    epoch : 51 ; learning_rate : 5.563470572184825e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.5489217074085708
    Epoch 51, Loss: 0.9012494604755407, fit: 0.55
      exponential decayed learning_rate :              0.8489224140472996
      batch rate adapted learning_rate :              0.0008489224140472996
      fit adapted learning_rate :              1.4274736839117406e-06
    epoch : 52 ; learning_rate : 1.4274736839117406e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.5310841626582903
    Epoch 52, Loss: 0.9002294482598847, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8479691043058217
      batch rate adapted learning_rate :              0.0008479691043058218
      fit adapted learning_rate :              2.5255385917420353e-06
    epoch : 53 ; learning_rate : 2.5255385917420353e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.46770968666273693
    Epoch 53, Loss: 0.8996655255293076, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8470168650973491
      batch rate adapted learning_rate :              0.0008470168650973491
      fit adapted learning_rate :              4.30106103301529e-06
    epoch : 54 ; learning_rate : 4.30106103301529e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.49098409288904954
    Epoch 54, Loss: 0.8986637273665096, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8460656952197113
      batch rate adapted learning_rate :              0.0008460656952197113
      fit adapted learning_rate :              1.9030856480144515e-06
    epoch : 55 ; learning_rate : 1.9030856480144515e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.49639417580299344
    Epoch 55, Loss: 0.8977763636427526, fit: 0.6166666666666667
      exponential decayed learning_rate :              0.8451155934720876
      batch rate adapted learning_rate :              0.0008451155934720877
      fit adapted learning_rate :              3.9402955676259453e-07
    epoch : 56 ; learning_rate : 3.9402955676259453e-07 ; fit : 0.6166666666666667
    batch_size :          60
    best_batch_loss : 0.5574389959451813
    Epoch 56, Loss: 0.8974418559351159, fit: 0.6
      exponential decayed learning_rate :              0.844166558655006
      batch rate adapted learning_rate :              0.000844166558655006
      fit adapted learning_rate :              5.53232995880145e-07
    epoch : 57 ; learning_rate : 5.53232995880145e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.4163939963513368
    Epoch 57, Loss: 0.8973052120037974, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.8432185895703413
      batch rate adapted learning_rate :              0.0008432185895703414
      fit adapted learning_rate :              5.519884568791133e-06
    epoch : 58 ; learning_rate : 5.519884568791133e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.502720946956318
    Epoch 58, Loss: 0.8964126509703931, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.842271685021314
      batch rate adapted learning_rate :              0.000842271685021314
      fit adapted learning_rate :              1.8945516459886214e-06
    epoch : 59 ; learning_rate : 1.8945516459886214e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.4452815479378572
    Epoch 59, Loss: 0.8953766299941874, fit: 0.6
      exponential decayed learning_rate :              0.8413258438124882
      batch rate adapted learning_rate :              0.0008413258438124882
      fit adapted learning_rate :              5.513713050009525e-07
    epoch : 60 ; learning_rate : 5.513713050009525e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.5252604722053207
    Epoch 60, Loss: 0.8950202727576718, fit: 0.4666666666666667
    Epoch 60, Loss: 0.8950202727576718
      exponential decayed learning_rate :              0.8403810647497706
      batch rate adapted learning_rate :              0.0008403810647497706
      fit adapted learning_rate :              5.501309540127911e-06
    epoch : 61 ; learning_rate : 5.501309540127911e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.5432923667901772
    Epoch 61, Loss: 0.8941707812141936, fit: 0.6
      exponential decayed learning_rate :              0.8394373466404088
      batch rate adapted learning_rate :              0.0008394373466404088
      fit adapted learning_rate :              5.501336594942586e-07
    epoch : 62 ; learning_rate : 5.501336594942586e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.49244680800031065
    Epoch 62, Loss: 0.8932934624436594, fit: 0.35
      exponential decayed learning_rate :              0.83849468829299
      batch rate adapted learning_rate :              0.00083849468829299
      fit adapted learning_rate :              2.6718198306090283e-05
    epoch : 63 ; learning_rate : 2.6718198306090283e-05 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.5235218567313106
    Epoch 63, Loss: 0.8894724534333014, fit: 0.6
      exponential decayed learning_rate :              0.8375530885174388
      batch rate adapted learning_rate :              0.0008375530885174388
      fit adapted learning_rate :              5.48898792090789e-07
    epoch : 64 ; learning_rate : 5.48898792090789e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.46112549904583905
    Epoch 64, Loss: 0.8855878049058391, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.836612546125017
      batch rate adapted learning_rate :              0.000836612546125017
      fit adapted learning_rate :              1.0401624073284653e-06
    epoch : 65 ; learning_rate : 1.0401624073284653e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5407824724739603
    Epoch 65, Loss: 0.8853687945110954, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8356730599283205
      batch rate adapted learning_rate :              0.0008356730599283205
      fit adapted learning_rate :              4.24345840384802e-06
    epoch : 66 ; learning_rate : 4.24345840384802e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.5186145523668161
    Epoch 66, Loss: 0.8846176535431228, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.8347346287412793
      batch rate adapted learning_rate :              0.0008347346287412794
      fit adapted learning_rate :              5.464346793602341e-06
    epoch : 67 ; learning_rate : 5.464346793602341e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.4785043631613185
    Epoch 67, Loss: 0.8832699036845838, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8337972513791548
      batch rate adapted learning_rate :              0.0008337972513791549
      fit adapted learning_rate :              4.233933248696256e-06
    epoch : 68 ; learning_rate : 4.233933248696256e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.46756477335843855
    Epoch 68, Loss: 0.8819349479278779, fit: 0.6333333333333333
      exponential decayed learning_rate :              0.8328609266585392
      batch rate adapted learning_rate :              0.0008328609266585392
      fit adapted learning_rate :              2.7210964223006806e-07
    epoch : 69 ; learning_rate : 2.7210964223006806e-07 ; fit : 0.6333333333333333
    batch_size :          60
    best_batch_loss : 0.5102189168260469
    Epoch 69, Loss: 0.8813089872775091, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8319256533973531
      batch rate adapted learning_rate :              0.0008319256533973531
      fit adapted learning_rate :              2.4777557725233726e-06
    epoch : 70 ; learning_rate : 2.4777557725233726e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5591282217119328
    Epoch 70, Loss: 0.8809177787069922, fit: 0.5333333333333333
    Epoch 70, Loss: 0.8809177787069922
      exponential decayed learning_rate :              0.8309914304148452
      batch rate adapted learning_rate :              0.0008309914304148453
      fit adapted learning_rate :              1.8691785682609575e-06
    epoch : 71 ; learning_rate : 1.8691785682609575e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.4946899641139492
    Epoch 71, Loss: 0.8803376841484957, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.8300582565315897
      batch rate adapted learning_rate :              0.0008300582565315898
      fit adapted learning_rate :              7.540821143643567e-07
    epoch : 72 ; learning_rate : 7.540821143643567e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.44654739882239836
    Epoch 72, Loss: 0.8799744334858823, fit: 0.5
      exponential decayed learning_rate :              0.8291261305694854
      batch rate adapted learning_rate :              0.0008291261305694854
      fit adapted learning_rate :              3.238773947537052e-06
    epoch : 73 ; learning_rate : 3.238773947537052e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.5182351505063875
    Epoch 73, Loss: 0.879437917027355, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8281950513517541
      batch rate adapted learning_rate :              0.0008281950513517541
      fit adapted learning_rate :              4.20548587624135e-06
    epoch : 74 ; learning_rate : 4.20548587624135e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.5505410126066013
    Epoch 74, Loss: 0.8783903097385406, fit: 0.5
      exponential decayed learning_rate :              0.8272650177029388
      batch rate adapted learning_rate :              0.0008272650177029388
      fit adapted learning_rate :              3.2315039754021048e-06
    epoch : 75 ; learning_rate : 3.2315039754021048e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.42278986725734147
    Epoch 75, Loss: 0.8773961119057638, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.826336028448903
      batch rate adapted learning_rate :              0.000826336028448903
      fit adapted learning_rate :              2.4611079802288274e-06
    epoch : 76 ; learning_rate : 2.4611079802288274e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.4986928424769397
    Epoch 76, Loss: 0.876628050799929, fit: 0.6
      exponential decayed learning_rate :              0.8254080824168282
      batch rate adapted learning_rate :              0.0008254080824168282
      fit adapted learning_rate :              5.409394408926928e-07
    epoch : 77 ; learning_rate : 5.409394408926928e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.4835914526179324
    Epoch 77, Loss: 0.8762246889545556, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8244811784352133
      batch rate adapted learning_rate :              0.0008244811784352133
      fit adapted learning_rate :              2.4555836099803364e-06
    epoch : 78 ; learning_rate : 2.4555836099803364e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5058123504074926
    Epoch 78, Loss: 0.8758225635697744, fit: 0.6
      exponential decayed learning_rate :              0.8235553153338726
      batch rate adapted learning_rate :              0.0008235553153338726
      fit adapted learning_rate :              5.397252114572071e-07
    epoch : 79 ; learning_rate : 5.397252114572071e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.502082369553772
    Epoch 79, Loss: 0.8754201363378921, fit: 0.6
      exponential decayed learning_rate :              0.8226304919439344
      batch rate adapted learning_rate :              0.0008226304919439345
      fit adapted learning_rate :              5.391191192003771e-07
    epoch : 80 ; learning_rate : 5.391191192003771e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.48502375325575625
    Epoch 80, Loss: 0.8752732150825235, fit: 0.5166666666666667
    Epoch 80, Loss: 0.8752732150825235
      exponential decayed learning_rate :              0.8217067070978399
      batch rate adapted learning_rate :              0.0008217067070978399
      fit adapted learning_rate :              2.447320296613566e-06
    epoch : 81 ; learning_rate : 2.447320296613566e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.46714370401253114
    Epoch 81, Loss: 0.8748814734386772, fit: 0.6333333333333333
      exponential decayed learning_rate :              0.8207839596293409
      batch rate adapted learning_rate :              0.0008207839596293409
      fit adapted learning_rate :              2.6816389441989756e-07
    epoch : 82 ; learning_rate : 2.6816389441989756e-07 ; fit : 0.6333333333333333
    batch_size :          60
    best_batch_loss : 0.5329854646723573
    Epoch 82, Loss: 0.8745094202866859, fit: 0.6166666666666667
      exponential decayed learning_rate :              0.8198622483734995
      batch rate adapted learning_rate :              0.0008198622483734996
      fit adapted learning_rate :              3.82255351609086e-07
    epoch : 83 ; learning_rate : 3.82255351609086e-07 ; fit : 0.6166666666666667
    batch_size :          60
    best_batch_loss : 0.5167756036551265
    Epoch 83, Loss: 0.8744222482845146, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8189415721666855
      batch rate adapted learning_rate :              0.0008189415721666856
      fit adapted learning_rate :              1.0181920425551047e-06
    epoch : 84 ; learning_rate : 1.0181920425551047e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.45286078468119856
    Epoch 84, Loss: 0.8742346254126757, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.8180219298465756
      batch rate adapted learning_rate :              0.0008180219298465757
      fit adapted learning_rate :              1.0967289266195798e-05
    epoch : 85 ; learning_rate : 1.0967289266195798e-05 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.5118967628204707
    Epoch 85, Loss: 0.8726263399627942, fit: 0.6
      exponential decayed learning_rate :              0.8171033202521518
      batch rate adapted learning_rate :              0.0008171033202521519
      fit adapted learning_rate :              5.354968319604505e-07
    epoch : 86 ; learning_rate : 5.354968319604505e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.456464560728799
    Epoch 86, Loss: 0.8711141956125966, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8161857422236997
      batch rate adapted learning_rate :              0.0008161857422236997
      fit adapted learning_rate :              2.430876997226252e-06
    epoch : 87 ; learning_rate : 2.430876997226252e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5136472655846417
    Epoch 87, Loss: 0.8707247582488793, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8152691946028073
      batch rate adapted learning_rate :              0.0008152691946028074
      fit adapted learning_rate :              1.0136261666246571e-06
    epoch : 88 ; learning_rate : 1.0136261666246571e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5051851590830235
    Epoch 88, Loss: 0.8702674375835326, fit: 0.4666666666666667
      Weights saved to src/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_0.9980433955256809_fit_0.46666666666666672024-01-02171858
  self.fit : 0.4666666666666667
  self.loss : 0.9980433955256809
  current_accuracy : 0.5504
  LR: 0.9, Epochs: 1, Hidden Size: 784, Samples: 1, Accuracy mean: 0.4766
  LR: 0.9, Epochs: 10, Hidden Size: 784, Samples: 1, Accuracy mean: 0.4915
  LR: 0.9, Epochs: 100, Hidden Size: 784, Samples: 1, Accuracy mean: 0.5504
  LR: 0.1
  LR: 0.1, Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  LR: 0.1, Hidden Size: 784, Sample: 1/1
  LR: 0.1, Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.1
    batch_rate :          0.001
      exponential decayed learning_rate :              0.1
      batch rate adapted learning_rate :              0.0001
      fit adapted learning_rate :              0.0001
    epoch : 0 ; learning_rate : 0.0001 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.4286856554502099
    Epoch 0, Loss: 1.7138725106476305, fit: 0.11666666666666667
    Epoch 0, Loss: 1.7138725106476305
      Weights saved to src/weights_tanh_softmax_learning_rate_0.1_hidden_size_784_loss_1.6634480377574283_fit_0.116666666666666672024-01-02171906
  self.fit : 0.11666666666666667
  self.loss : 1.6634480377574283
  current_accuracy : 0.1424
  LR: 0.1, Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          0.1
    batch_rate :          0.001
      exponential decayed learning_rate :              0.1
      batch rate adapted learning_rate :              0.0001
      fit adapted learning_rate :              3.70678121733545e-05
    epoch : 0 ; learning_rate : 3.70678121733545e-05 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.3519359083431277
    Epoch 0, Loss: 1.646859041499858, fit: 0.11666666666666667
    Epoch 0, Loss: 1.646859041499858
      exponential decayed learning_rate :              0.09889503892939223
      batch rate adapted learning_rate :              9.889503892939224e-05
      fit adapted learning_rate :              3.665822727911293e-05
    epoch : 1 ; learning_rate : 3.665822727911293e-05 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.2931786010874902
    Epoch 1, Loss: 1.608533348986554, fit: 0.15
      exponential decayed learning_rate :              0.09780228724846006
      batch rate adapted learning_rate :              9.780228724846007e-05
      fit adapted learning_rate :              2.6650196602354087e-05
    epoch : 2 ; learning_rate : 2.6650196602354087e-05 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.2419094008823033
    Epoch 2, Loss: 1.573230420338443, fit: 0.16666666666666666
      exponential decayed learning_rate :              0.0967216100482006
      batch rate adapted learning_rate :              9.672161004820059e-05
      fit adapted learning_rate :              2.2494355212785762e-05
    epoch : 3 ; learning_rate : 2.2494355212785762e-05 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.1487748778608662
    Epoch 3, Loss: 1.5445565660151497, fit: 0.15
      exponential decayed learning_rate :              0.09565287391030293
      batch rate adapted learning_rate :              9.565287391030293e-05
      fit adapted learning_rate :              2.6064501833313684e-05
    epoch : 4 ; learning_rate : 2.6064501833313684e-05 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.221996698767272
    Epoch 4, Loss: 1.5165663741451312, fit: 0.3
      exponential decayed learning_rate :              0.09459594689067655
      batch rate adapted learning_rate :              9.459594689067654e-05
      fit adapted learning_rate :              5.453268092313188e-06
    epoch : 5 ; learning_rate : 5.453268092313188e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 1.1883117349792367
    Epoch 5, Loss: 1.4985609500095112, fit: 0.2833333333333333
      exponential decayed learning_rate :              0.09355069850316178
      batch rate adapted learning_rate :              9.355069850316178e-05
      fit adapted learning_rate :              6.510055275815562e-06
    epoch : 6 ; learning_rate : 6.510055275815562e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.1296624309226695
    Epoch 6, Loss: 1.491769208526765, fit: 0.23333333333333334
      exponential decayed learning_rate :              0.0925169997034202
      batch rate adapted learning_rate :              9.25169997034202e-05
      fit adapted learning_rate :              1.1042672461540643e-05
    epoch : 7 ; learning_rate : 1.1042672461540643e-05 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.1806974595211686
    Epoch 7, Loss: 1.4818405829023549, fit: 0.2
      exponential decayed learning_rate :              0.0914947228730031
      batch rate adapted learning_rate :              9.14947228730031e-05
      fit adapted learning_rate :              1.5350267285005144e-05
    epoch : 8 ; learning_rate : 1.5350267285005144e-05 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.151037122781065
    Epoch 8, Loss: 1.467199639858141, fit: 0.16666666666666666
      Weights saved to src/weights_tanh_softmax_learning_rate_0.1_hidden_size_784_loss_1.6012157499879887_fit_0.166666666666666662024-01-02172012
  self.fit : 0.16666666666666666
  self.loss : 1.6012157499879887
  current_accuracy : 0.2474
  LR: 0.1, Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          0.1
    batch_rate :          0.001
      exponential decayed learning_rate :              0.1
      batch rate adapted learning_rate :              0.0001
      fit adapted learning_rate :              2.3256803936137793e-05
    epoch : 0 ; learning_rate : 2.3256803936137793e-05 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.0382840859517897
    Epoch 0, Loss: 1.44564701151898, fit: 0.3
    Epoch 0, Loss: 1.44564701151898
      exponential decayed learning_rate :              0.09988770354914617
      batch rate adapted learning_rate :              9.988770354914618e-05
      fit adapted learning_rate :              5.758327333078211e-06
    epoch : 1 ; learning_rate : 5.758327333078211e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 1.0624061993097789
    Epoch 1, Loss: 1.429319356785065, fit: 0.16666666666666666
      exponential decayed learning_rate :              0.09977553320322105
      batch rate adapted learning_rate :              9.977553320322105e-05
      fit adapted learning_rate :              2.3204600133309184e-05
    epoch : 2 ; learning_rate : 2.3204600133309184e-05 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.0029823812269614
    Epoch 2, Loss: 1.413121177666635, fit: 0.26666666666666666
      exponential decayed learning_rate :              0.09966348882061334
      batch rate adapted learning_rate :              9.966348882061334e-05
      fit adapted learning_rate :              8.335804006518108e-06
    epoch : 3 ; learning_rate : 8.335804006518108e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.0377230273782496
    Epoch 3, Loss: 1.396022397039059, fit: 0.2
      exponential decayed learning_rate :              0.09955157025987066
      batch rate adapted learning_rate :              9.955157025987067e-05
      fit adapted learning_rate :              1.670198197389027e-05
    epoch : 4 ; learning_rate : 1.670198197389027e-05 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.03146431525538
    Epoch 4, Loss: 1.382517915831635, fit: 0.25
      exponential decayed learning_rate :              0.09943977737969956
      batch rate adapted learning_rate :              9.943977737969956e-05
      fit adapted learning_rate :              9.955205984317152e-06
    epoch : 5 ; learning_rate : 9.955205984317152e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 0.9056240821490189
    Epoch 5, Loss: 1.3680208135606822, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.09932811003896519
      batch rate adapted learning_rate :              9.932811003896519e-05
      fit adapted learning_rate :              2.5711708864352226e-06
    epoch : 6 ; learning_rate : 2.5711708864352226e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.9867311428815245
    Epoch 6, Loss: 1.3613415309139498, fit: 0.25
      exponential decayed learning_rate :              0.09921656809669122
      batch rate adapted learning_rate :              9.921656809669122e-05
      fit adapted learning_rate :              9.932859852331408e-06
    epoch : 7 ; learning_rate : 9.932859852331408e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.0334752893886292
    Epoch 7, Loss: 1.3546289167373269, fit: 0.21666666666666667
      exponential decayed learning_rate :              0.09910515141205965
      batch rate adapted learning_rate :              9.910515141205966e-05
      fit adapted learning_rate :              1.4049765957991471e-05
    epoch : 8 ; learning_rate : 1.4049765957991471e-05 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 0.9034317096026769
    Epoch 8, Loss: 1.3420418559891056, fit: 0.2833333333333333
      exponential decayed learning_rate :              0.09899385984441057
      batch rate adapted learning_rate :              9.899385984441058e-05
      fit adapted learning_rate :              6.8888368538656115e-06
    epoch : 9 ; learning_rate : 6.8888368538656115e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 0.9098092077918563
    Epoch 9, Loss: 1.3312284981216878, fit: 0.3
      exponential decayed learning_rate :              0.09888269325324206
      batch rate adapted learning_rate :              9.888269325324206e-05
      fit adapted learning_rate :              5.700390489489828e-06
    epoch : 10 ; learning_rate : 5.700390489489828e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 0.9556233076394882
    Epoch 10, Loss: 1.3248814974095822, fit: 0.35
    Epoch 10, Loss: 1.3248814974095822
      exponential decayed learning_rate :              0.09877165149820999
      batch rate adapted learning_rate :              9.877165149820999e-05
      fit adapted learning_rate :              3.147307441054515e-06
    epoch : 11 ; learning_rate : 3.147307441054515e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.9612949259776412
    Epoch 11, Loss: 1.3205351086822452, fit: 0.35
      exponential decayed learning_rate :              0.09866073443912776
      batch rate adapted learning_rate :              9.866073443912777e-05
      fit adapted learning_rate :              3.143773126500752e-06
    epoch : 12 ; learning_rate : 3.143773126500752e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.9793103500892532
    Epoch 12, Loss: 1.3174808368587991, fit: 0.26666666666666666
      exponential decayed learning_rate :              0.09854994193596628
      batch rate adapted learning_rate :              9.854994193596629e-05
      fit adapted learning_rate :              8.242667505956764e-06
    epoch : 13 ; learning_rate : 8.242667505956764e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 0.9592192128218472
    Epoch 13, Loss: 1.3120590308361706, fit: 0.2833333333333333
      exponential decayed learning_rate :              0.09843927384885366
      batch rate adapted learning_rate :              9.843927384885367e-05
      fit adapted learning_rate :              6.850244031534663e-06
    epoch : 14 ; learning_rate : 6.850244031534663e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 0.8844738368202464
    Epoch 14, Loss: 1.3049282377956695, fit: 0.23333333333333334
      exponential decayed learning_rate :              0.0983287300380751
      batch rate adapted learning_rate :              9.83287300380751e-05
      fit adapted learning_rate :              1.1736350755542017e-05
    epoch : 15 ; learning_rate : 1.1736350755542017e-05 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 0.8778528551230874
    Epoch 15, Loss: 1.2963067887266682, fit: 0.26666666666666666
      exponential decayed learning_rate :              0.09821831036407268
      batch rate adapted learning_rate :              9.821831036407269e-05
      fit adapted learning_rate :              8.214930008319546e-06
    epoch : 16 ; learning_rate : 8.214930008319546e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 0.8998605783811378
    Epoch 16, Loss: 1.287329413770152, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.0981080146874452
      batch rate adapted learning_rate :              9.81080146874452e-05
      fit adapted learning_rate :              3.828021911291876e-06
    epoch : 17 ; learning_rate : 3.828021911291876e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.8599267239854943
    Epoch 17, Loss: 1.2819346393308264, fit: 0.35
      exponential decayed learning_rate :              0.09799784286894803
      batch rate adapted learning_rate :              9.799784286894803e-05
      fit adapted learning_rate :              3.1226504304660826e-06
    epoch : 18 ; learning_rate : 3.1226504304660826e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.9118270986781217
    Epoch 18, Loss: 1.2788427558533184, fit: 0.2833333333333333
      exponential decayed learning_rate :              0.09788779476949289
      batch rate adapted learning_rate :              9.788779476949289e-05
      fit adapted learning_rate :              6.8118674149242244e-06
    epoch : 19 ; learning_rate : 6.8118674149242244e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 0.9073700013043886
    Epoch 19, Loss: 1.2744803640151476, fit: 0.35
      exponential decayed learning_rate :              0.09777787025014764
      batch rate adapted learning_rate :              9.777787025014764e-05
      fit adapted learning_rate :              3.1156411170702112e-06
    epoch : 20 ; learning_rate : 3.1156411170702112e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.8617913078064922
    Epoch 20, Loss: 1.2701383193219473, fit: 0.35
    Epoch 20, Loss: 1.2701383193219473
      exponential decayed learning_rate :              0.09766806917213625
      batch rate adapted learning_rate :              9.766806917213625e-05
      fit adapted learning_rate :              3.1121423626743987e-06
    epoch : 21 ; learning_rate : 3.1121423626743987e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.8713109306254517
    Epoch 21, Loss: 1.2674392812573105, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09755839139683846
      batch rate adapted learning_rate :              9.755839139683846e-05
      fit adapted learning_rate :              2.040179691899687e-06
    epoch : 22 ; learning_rate : 2.040179691899687e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.9142626943124534
    Epoch 22, Loss: 1.265204498153999, fit: 0.4
      exponential decayed learning_rate :              0.0974488367857897
      batch rate adapted learning_rate :              9.74488367857897e-05
      fit adapted learning_rate :              1.636766254468009e-06
    epoch : 23 ; learning_rate : 1.636766254468009e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.8405427692675062
    Epoch 23, Loss: 1.2635918680687157, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.0973394052006809
      batch rate adapted learning_rate :              9.733940520068091e-05
      fit adapted learning_rate :              1.3050376461613146e-06
    epoch : 24 ; learning_rate : 1.3050376461613146e-06 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.7849734825189258
    Epoch 24, Loss: 1.2623507940335645, fit: 0.4
      exponential decayed learning_rate :              0.09723009650335829
      batch rate adapted learning_rate :              9.723009650335829e-05
      fit adapted learning_rate :              1.6330922576858458e-06
    epoch : 25 ; learning_rate : 1.6330922576858458e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.8364494869321244
    Epoch 25, Loss: 1.2610954929635534, fit: 0.2833333333333333
      exponential decayed learning_rate :              0.09712091055582324
      batch rate adapted learning_rate :              9.712091055582324e-05
      fit adapted learning_rate :              6.758501072384612e-06
    epoch : 26 ; learning_rate : 6.758501072384612e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 0.8036824310117358
    Epoch 26, Loss: 1.2575225089933304, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09701184722023211
      batch rate adapted learning_rate :              9.701184722023212e-05
      fit adapted learning_rate :              3.7852511642096397e-06
    epoch : 27 ; learning_rate : 3.7852511642096397e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.8696624003495378
    Epoch 27, Loss: 1.2530569161437726, fit: 0.31666666666666665
      exponential decayed learning_rate :              0.09690290635889603
      batch rate adapted learning_rate :              9.690290635889603e-05
      fit adapted learning_rate :              4.6067819177734605e-06
    epoch : 28 ; learning_rate : 4.6067819177734605e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 0.8941867950590524
    Epoch 28, Loss: 1.2495389452908066, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09679408783428077
      batch rate adapted learning_rate :              9.679408783428078e-05
      fit adapted learning_rate :              3.7767545321713004e-06
    epoch : 29 ; learning_rate : 3.7767545321713004e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.800098553498628
    Epoch 29, Loss: 1.246048243983695, fit: 0.35
      exponential decayed learning_rate :              0.09668539150900651
      batch rate adapted learning_rate :              9.668539150900652e-05
      fit adapted learning_rate :              3.0808298486644216e-06
    epoch : 30 ; learning_rate : 3.0808298486644216e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.8988736721973568
    Epoch 30, Loss: 1.2432718421801225, fit: 0.26666666666666666
    Epoch 30, Loss: 1.2432718421801225
      exponential decayed learning_rate :              0.09657681724584775
      batch rate adapted learning_rate :              9.657681724584776e-05
      fit adapted learning_rate :              8.077636350697346e-06
    epoch : 31 ; learning_rate : 8.077636350697346e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 0.8272839647719301
    Epoch 31, Loss: 1.2387504335308528, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09646836490773307
      batch rate adapted learning_rate :              9.646836490773307e-05
      fit adapted learning_rate :              3.7640453309525514e-06
    epoch : 32 ; learning_rate : 3.7640453309525514e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.769721129312748
    Epoch 32, Loss: 1.2340658022673958, fit: 0.4
      exponential decayed learning_rate :              0.09636003435774494
      batch rate adapted learning_rate :              9.636003435774494e-05
      fit adapted learning_rate :              1.6184785546781807e-06
    epoch : 33 ; learning_rate : 1.6184785546781807e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.8331573441185175
    Epoch 33, Loss: 1.2319377742678468, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09625182545911964
      batch rate adapted learning_rate :              9.625182545911965e-05
      fit adapted learning_rate :              2.012856267906165e-06
    epoch : 34 ; learning_rate : 2.012856267906165e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.8584860978037999
    Epoch 34, Loss: 1.2305113118428903, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09614373807524701
      batch rate adapted learning_rate :              9.614373807524702e-05
      fit adapted learning_rate :              3.751378897616714e-06
    epoch : 35 ; learning_rate : 3.751378897616714e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.8698938419108598
    Epoch 35, Loss: 1.2282526038094592, fit: 0.2833333333333333
      exponential decayed learning_rate :              0.09603577206967029
      batch rate adapted learning_rate :              9.603577206967029e-05
      fit adapted learning_rate :              6.682987883923151e-06
    epoch : 36 ; learning_rate : 6.682987883923151e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 0.8162593044524231
    Epoch 36, Loss: 1.2243081339514916, fit: 0.3
      exponential decayed learning_rate :              0.09592792730608596
      batch rate adapted learning_rate :              9.592792730608595e-05
      fit adapted learning_rate :              5.530054112620514e-06
    epoch : 37 ; learning_rate : 5.530054112620514e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 0.7581785257958731
    Epoch 37, Loss: 1.2196387485869602, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.09582020364834357
      batch rate adapted learning_rate :              9.582020364834356e-05
      fit adapted learning_rate :              1.2846695823353701e-06
    epoch : 38 ; learning_rate : 1.2846695823353701e-06 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.7726407966987412
    Epoch 38, Loss: 1.2171205965973897, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.09571260096044554
      batch rate adapted learning_rate :              9.571260096044555e-05
      fit adapted learning_rate :              1.2832269439892086e-06
    epoch : 39 ; learning_rate : 1.2832269439892086e-06 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.8613193904056248
    Epoch 39, Loss: 1.2161593051234998, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09560511910654707
      batch rate adapted learning_rate :              9.560511910654707e-05
      fit adapted learning_rate :              3.7303628244590873e-06
    epoch : 40 ; learning_rate : 3.7303628244590873e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.8192961903692025
    Epoch 40, Loss: 1.2143305903735773, fit: 0.3
    Epoch 40, Loss: 1.2143305903735773
      exponential decayed learning_rate :              0.09549775795095582
      batch rate adapted learning_rate :              9.549775795095582e-05
      fit adapted learning_rate :              5.505255705334278e-06
    epoch : 41 ; learning_rate : 5.505255705334278e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 0.8466320047773604
    Epoch 41, Loss: 1.2109101047960111, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.0953905173581319
      batch rate adapted learning_rate :              9.53905173581319e-05
      fit adapted learning_rate :              1.278908741865783e-06
    epoch : 42 ; learning_rate : 1.278908741865783e-06 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.8130272733835148
    Epoch 42, Loss: 1.2084262420200405, fit: 0.5
      exponential decayed learning_rate :              0.09528339719268758
      batch rate adapted learning_rate :              9.528339719268758e-05
      fit adapted learning_rate :              3.7220077028393587e-07
    epoch : 43 ; learning_rate : 3.7220077028393587e-07 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.8728780221909267
    Epoch 43, Loss: 1.2078191182994569, fit: 0.31666666666666665
      exponential decayed learning_rate :              0.09517639731938722
      batch rate adapted learning_rate :              9.517639731938723e-05
      fit adapted learning_rate :              4.524703361794717e-06
    epoch : 44 ; learning_rate : 4.524703361794717e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 0.7240934752666651
    Epoch 44, Loss: 1.206000948342873, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.095069517603147
      batch rate adapted learning_rate :              9.5069517603147e-05
      fit adapted learning_rate :              2.460934530544895e-06
    epoch : 45 ; learning_rate : 2.460934530544895e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.8024612420686653
    Epoch 45, Loss: 1.2035073358125956, fit: 0.3
      exponential decayed learning_rate :              0.0949627579090348
      batch rate adapted learning_rate :              9.49627579090348e-05
      fit adapted learning_rate :              5.4744140175676145e-06
    epoch : 46 ; learning_rate : 5.4744140175676145e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 0.7435067429716521
    Epoch 46, Loss: 1.2006347646597337, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.09485611810227002
      batch rate adapted learning_rate :              9.485611810227002e-05
      fit adapted learning_rate :              1.0085250292276859e-06
    epoch : 47 ; learning_rate : 1.0085250292276859e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.8145076532026596
    Epoch 47, Loss: 1.19825945299907, fit: 0.3
      exponential decayed learning_rate :              0.09474959804822343
      batch rate adapted learning_rate :              9.474959804822344e-05
      fit adapted learning_rate :              5.462125775779962e-06
    epoch : 48 ; learning_rate : 5.462125775779962e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 0.849055708209813
    Epoch 48, Loss: 1.195890108049054, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.09464319761241699
      batch rate adapted learning_rate :              9.4643197612417e-05
      fit adapted learning_rate :              1.0062612253998646e-06
    epoch : 49 ; learning_rate : 1.0062612253998646e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.8187410094017745
    Epoch 49, Loss: 1.1936052238932515, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09453691666052365
      batch rate adapted learning_rate :              9.453691666052365e-05
      fit adapted learning_rate :              1.976993416394767e-06
    epoch : 50 ; learning_rate : 1.976993416394767e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.7870610183441243
    Epoch 50, Loss: 1.1925153532464365, fit: 0.3333333333333333
    Epoch 50, Loss: 1.1925153532464365
      exponential decayed learning_rate :              0.09443075505836723
      batch rate adapted learning_rate :              9.443075505836723e-05
      fit adapted learning_rate :              3.684540968593512e-06
    epoch : 51 ; learning_rate : 3.684540968593512e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.7404295627966389
    Epoch 51, Loss: 1.1904763214828797, fit: 0.2833333333333333
      exponential decayed learning_rate :              0.09432471267192219
      batch rate adapted learning_rate :              9.43247126719222e-05
      fit adapted learning_rate :              6.563917781425014e-06
    epoch : 52 ; learning_rate : 6.563917781425014e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 0.8060369905291005
    Epoch 52, Loss: 1.1868253748075095, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.09421878936731354
      batch rate adapted learning_rate :              9.421878936731354e-05
      fit adapted learning_rate :              6.167758253335224e-07
    epoch : 53 ; learning_rate : 6.167758253335224e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.7539151529123769
    Epoch 53, Loss: 1.1842697778078073, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.09411298501081657
      batch rate adapted learning_rate :              9.411298501081657e-05
      fit adapted learning_rate :              1.26178075753099e-06
    epoch : 54 ; learning_rate : 1.26178075753099e-06 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.7493593674914177
    Epoch 54, Loss: 1.1836063751897237, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09400729946885682
      batch rate adapted learning_rate :              9.400729946885681e-05
      fit adapted learning_rate :              3.6680183911030888e-06
    epoch : 55 ; learning_rate : 3.6680183911030888e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.7471786287290124
    Epoch 55, Loss: 1.1818615826548078, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09390173260800974
      batch rate adapted learning_rate :              9.390173260800975e-05
      fit adapted learning_rate :              3.663899336633214e-06
    epoch : 56 ; learning_rate : 3.663899336633214e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.8189951608406763
    Epoch 56, Loss: 1.1792777666306329, fit: 0.45
      exponential decayed learning_rate :              0.09379628429500067
      batch rate adapted learning_rate :              9.379628429500068e-05
      fit adapted learning_rate :              7.853932243528998e-07
    epoch : 57 ; learning_rate : 7.853932243528998e-07 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.75651102192426
    Epoch 57, Loss: 1.1777128266878438, fit: 0.4
      exponential decayed learning_rate :              0.0936909543967046
      batch rate adapted learning_rate :              9.36909543967046e-05
      fit adapted learning_rate :              1.5736482605997533e-06
    epoch : 58 ; learning_rate : 1.5736482605997533e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.8185596566774717
    Epoch 58, Loss: 1.176901109154235, fit: 0.35
      exponential decayed learning_rate :              0.093585742780146
      batch rate adapted learning_rate :              9.3585742780146e-05
      fit adapted learning_rate :              2.982061149740979e-06
    epoch : 59 ; learning_rate : 2.982061149740979e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.7469669344770735
    Epoch 59, Loss: 1.175293928405599, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09348064931249869
      batch rate adapted learning_rate :              9.34806493124987e-05
      fit adapted learning_rate :              1.9549043355704283e-06
    epoch : 60 ; learning_rate : 1.9549043355704283e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.7725060405978373
    Epoch 60, Loss: 1.173587548745361, fit: 0.35
    Epoch 60, Loss: 1.173587548745361
      exponential decayed learning_rate :              0.09337567386108563
      batch rate adapted learning_rate :              9.337567386108563e-05
      fit adapted learning_rate :              2.9753674126001663e-06
    epoch : 61 ; learning_rate : 2.9753674126001663e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.7141034382345908
    Epoch 61, Loss: 1.1718832514956996, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09327081629337876
      batch rate adapted learning_rate :              9.327081629337876e-05
      fit adapted learning_rate :              1.9505162244282804e-06
    epoch : 62 ; learning_rate : 1.9505162244282804e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.7158616876430265
    Epoch 62, Loss: 1.1701814821077268, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.09316607647699889
      batch rate adapted learning_rate :              9.316607647699888e-05
      fit adapted learning_rate :              6.09884547424699e-07
    epoch : 63 ; learning_rate : 6.09884547424699e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.7370050265705537
    Epoch 63, Loss: 1.1692830865249622, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.09306145427971543
      batch rate adapted learning_rate :              9.306145427971543e-05
      fit adapted learning_rate :              1.2476827959978028e-06
    epoch : 64 ; learning_rate : 1.2476827959978028e-06 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.7990537739306522
    Epoch 64, Loss: 1.1686510266595411, fit: 0.45
      exponential decayed learning_rate :              0.09295694956944633
      batch rate adapted learning_rate :              9.295694956944633e-05
      fit adapted learning_rate :              7.783651441749985e-07
    epoch : 65 ; learning_rate : 7.783651441749985e-07 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.631751968871331
    Epoch 65, Loss: 1.1679364482787815, fit: 0.35
      exponential decayed learning_rate :              0.09285256221425785
      batch rate adapted learning_rate :              9.285256221425785e-05
      fit adapted learning_rate :              2.958698731317732e-06
    epoch : 66 ; learning_rate : 2.958698731317732e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.7404752175148545
    Epoch 66, Loss: 1.1666515834694482, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.09274829208236438
      batch rate adapted learning_rate :              9.274829208236437e-05
      fit adapted learning_rate :              9.8611429451851e-07
    epoch : 67 ; learning_rate : 9.8611429451851e-07 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.7818055826839118
    Epoch 67, Loss: 1.1652849718296348, fit: 0.2833333333333333
      exponential decayed learning_rate :              0.09264413904212832
      batch rate adapted learning_rate :              9.264413904212832e-05
      fit adapted learning_rate :              6.446969138602573e-06
    epoch : 68 ; learning_rate : 6.446969138602573e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 0.7891259202821133
    Epoch 68, Loss: 1.1627513755771721, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.0925401029620599
      batch rate adapted learning_rate :              9.25401029620599e-05
      fit adapted learning_rate :              1.240692994745026e-06
    epoch : 69 ; learning_rate : 1.240692994745026e-06 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.817818262024809
    Epoch 69, Loss: 1.160083850515578, fit: 0.4
      exponential decayed learning_rate :              0.09243618371081702
      batch rate adapted learning_rate :              9.243618371081702e-05
      fit adapted learning_rate :              1.5525729313962758e-06
    epoch : 70 ; learning_rate : 1.5525729313962758e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.7484323484815086
    Epoch 70, Loss: 1.1591301908862919, fit: 0.4166666666666667
    Epoch 70, Loss: 1.1591301908862919
      exponential decayed learning_rate :              0.09233238115720503
      batch rate adapted learning_rate :              9.233238115720504e-05
      fit adapted learning_rate :              1.2379080509218611e-06
    epoch : 71 ; learning_rate : 1.2379080509218611e-06 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.7169635761733758
    Epoch 71, Loss: 1.1581635624397553, fit: 0.35
      exponential decayed learning_rate :              0.09222869517017664
      batch rate adapted learning_rate :              9.222869517017664e-05
      fit adapted learning_rate :              2.9388195315647435e-06
    epoch : 72 ; learning_rate : 2.9388195315647435e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.707514985100026
    Epoch 72, Loss: 1.1567620867224728, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.09212512561883171
      batch rate adapted learning_rate :              9.212512561883172e-05
      fit adapted learning_rate :              6.030702662288888e-07
    epoch : 73 ; learning_rate : 6.030702662288888e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.7501744779192959
    Epoch 73, Loss: 1.1555264070826503, fit: 0.26666666666666666
      exponential decayed learning_rate :              0.09202167237241712
      batch rate adapted learning_rate :              9.202167237241712e-05
      fit adapted learning_rate :              7.696646327815867e-06
    epoch : 74 ; learning_rate : 7.696646327815867e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 0.7226524062602
    Epoch 74, Loss: 1.152698952137889, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.09191833530032655
      batch rate adapted learning_rate :              9.191833530032655e-05
      fit adapted learning_rate :              9.772900646785334e-07
    epoch : 75 ; learning_rate : 9.772900646785334e-07 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.7595192343944279
    Epoch 75, Loss: 1.149769512004502, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09181511427210033
      batch rate adapted learning_rate :              9.181511427210033e-05
      fit adapted learning_rate :              1.9200740076312758e-06
    epoch : 76 ; learning_rate : 1.9200740076312758e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.6961256429476574
    Epoch 76, Loss: 1.1488010925209824, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.09171200915742536
      batch rate adapted learning_rate :              9.171200915742537e-05
      fit adapted learning_rate :              2.374023303066457e-06
    epoch : 77 ; learning_rate : 2.374023303066457e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.7040149373792599
    Epoch 77, Loss: 1.1473251044574728, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09160901982613481
      batch rate adapted learning_rate :              9.160901982613482e-05
      fit adapted learning_rate :              3.5744412552187982e-06
    epoch : 78 ; learning_rate : 3.5744412552187982e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.7335730710431243
    Epoch 78, Loss: 1.145341029429744, fit: 0.45
      exponential decayed learning_rate :              0.09150614614820807
      batch rate adapted learning_rate :              9.150614614820807e-05
      fit adapted learning_rate :              7.662169958184514e-07
    epoch : 79 ; learning_rate : 7.662169958184514e-07 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.7222091618521324
    Epoch 79, Loss: 1.1439392850188632, fit: 0.23333333333333334
      exponential decayed learning_rate :              0.0914033879937705
      batch rate adapted learning_rate :              9.14033879937705e-05
      fit adapted learning_rate :              1.0909753653122526e-05
    epoch : 80 ; learning_rate : 1.0909753653122526e-05 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 0.6864130204663127
    Epoch 80, Loss: 1.1400842015262032, fit: 0.4
    Epoch 80, Loss: 1.1400842015262032
      exponential decayed learning_rate :              0.09130074523309333
      batch rate adapted learning_rate :              9.130074523309333e-05
      fit adapted learning_rate :              1.5335019250542723e-06
    epoch : 81 ; learning_rate : 1.5335019250542723e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.7626152142008407
    Epoch 81, Loss: 1.1360089123710027, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.09119821773659344
      batch rate adapted learning_rate :              9.119821773659343e-05
      fit adapted learning_rate :              5.970025341139397e-07
    epoch : 82 ; learning_rate : 5.970025341139397e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.7586919881780202
    Epoch 82, Loss: 1.1353210531978601, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09109580537483329
      batch rate adapted learning_rate :              9.109580537483329e-05
      fit adapted learning_rate :              1.9050315352883532e-06
    epoch : 83 ; learning_rate : 1.9050315352883532e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.6375547342354435
    Epoch 83, Loss: 1.1345115058752118, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09099350801852062
      batch rate adapted learning_rate :              9.099350801852062e-05
      fit adapted learning_rate :              3.550424943261896e-06
    epoch : 84 ; learning_rate : 3.550424943261896e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.775935094091359
    Epoch 84, Loss: 1.132759215913538, fit: 0.5
      exponential decayed learning_rate :              0.09089132553850841
      batch rate adapted learning_rate :              9.089132553850842e-05
      fit adapted learning_rate :              3.550442403847985e-07
    epoch : 85 ; learning_rate : 3.550442403847985e-07 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.7120032958268373
    Epoch 85, Loss: 1.131506505191921, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.09078925780579465
      batch rate adapted learning_rate :              9.078925780579466e-05
      fit adapted learning_rate :              4.6101813913705597e-07
    epoch : 86 ; learning_rate : 4.6101813913705597e-07 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.7234286352614124
    Epoch 86, Loss: 1.1312493875058915, fit: 0.35
      exponential decayed learning_rate :              0.0906873046915222
      batch rate adapted learning_rate :              9.06873046915222e-05
      fit adapted learning_rate :              2.88970392349852e-06
    epoch : 87 ; learning_rate : 2.88970392349852e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.7832147705890479
    Epoch 87, Loss: 1.130181979039146, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.09058546606697859
      batch rate adapted learning_rate :              9.058546606697859e-05
      fit adapted learning_rate :              1.214487012415486e-06
    epoch : 88 ; learning_rate : 1.214487012415486e-06 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.7079496675812057
    Epoch 88, Loss: 1.1288801074924144, fit: 0.4
      Weights saved to src/weights_tanh_softmax_learning_rate_0.1_hidden_size_784_loss_1.1462139001397218_fit_0.42024-01-02173035
  self.fit : 0.4
  self.loss : 1.1462139001397218
  current_accuracy : 0.418
  LR: 0.1, Epochs: 1, Hidden Size: 784, Samples: 1, Accuracy mean: 0.1424
  LR: 0.1, Epochs: 10, Hidden Size: 784, Samples: 1, Accuracy mean: 0.2474
  LR: 0.1, Epochs: 100, Hidden Size: 784, Samples: 1, Accuracy mean: 0.418
  LR: 0.0001
  LR: 0.0001, Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  LR: 0.0001, Hidden Size: 784, Sample: 1/1
  LR: 0.0001, Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.0001
    batch_rate :          0.001
      exponential decayed learning_rate :              0.0001
      batch rate adapted learning_rate :              1.0000000000000001e-07
      fit adapted learning_rate :              1.0000000000000001e-07
    epoch : 0 ; learning_rate : 1.0000000000000001e-07 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.5156943155428202
    Epoch 0, Loss: 1.772134345993451, fit: 0.06666666666666667
    Epoch 0, Loss: 1.772134345993451
      Weights saved to src/weights_tanh_softmax_learning_rate_0.0001_hidden_size_784_loss_1.7634358547677238_fit_0.066666666666666672024-01-02173042
  self.fit : 0.06666666666666667
  self.loss : 1.7634358547677238
  current_accuracy : 0.0799
  LR: 0.0001, Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          0.0001
    batch_rate :          0.001
      exponential decayed learning_rate :              0.0001
      batch rate adapted learning_rate :              1.0000000000000001e-07
      fit adapted learning_rate :              5.7582990144185347e-08
    epoch : 0 ; learning_rate : 5.7582990144185347e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5109106008901538
    Epoch 0, Loss: 1.7720452323666573, fit: 0.06666666666666667
    Epoch 0, Loss: 1.7720452323666573
      exponential decayed learning_rate :              9.889503892939224e-05
      batch rate adapted learning_rate :              9.889503892939224e-08
      fit adapted learning_rate :              5.6946720519800195e-08
    epoch : 1 ; learning_rate : 5.6946720519800195e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5212474491845545
    Epoch 1, Loss: 1.7719855771142596, fit: 0.1
      exponential decayed learning_rate :              9.780228724846005e-05
      batch rate adapted learning_rate :              9.780228724846006e-08
      fit adapted learning_rate :              4.210067772346319e-08
    epoch : 2 ; learning_rate : 4.210067772346319e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4576307184791044
    Epoch 2, Loss: 1.7719299050954238, fit: 0.1
      exponential decayed learning_rate :              9.672161004820059e-05
      batch rate adapted learning_rate :              9.67216100482006e-08
      fit adapted learning_rate :              4.1635481624156887e-08
    epoch : 3 ; learning_rate : 4.1635481624156887e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5161607845604175
    Epoch 3, Loss: 1.7718841097525386, fit: 0.1
      exponential decayed learning_rate :              9.565287391030293e-05
      batch rate adapted learning_rate :              9.565287391030293e-08
      fit adapted learning_rate :              4.11754257606499e-08
    epoch : 4 ; learning_rate : 4.11754257606499e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4841278641561564
    Epoch 4, Loss: 1.7718391148823938, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.459594689067654e-05
      batch rate adapted learning_rate :              9.459594689067654e-08
      fit adapted learning_rate :              7.212510762492029e-08
    epoch : 5 ; learning_rate : 7.212510762492029e-08 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.5170879353729236
    Epoch 5, Loss: 1.771775988727615, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.355069850316179e-05
      batch rate adapted learning_rate :              9.35506985031618e-08
      fit adapted learning_rate :              4.663785280735795e-08
    epoch : 6 ; learning_rate : 4.663785280735795e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5117547884860703
    Epoch 6, Loss: 1.7717111184059222, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.25169997034202e-05
      batch rate adapted learning_rate :              9.251699970342021e-08
      fit adapted learning_rate :              7.054000493758552e-08
    epoch : 7 ; learning_rate : 7.054000493758552e-08 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.5790181029795844
    Epoch 7, Loss: 1.7716468173837328, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.14947228730031e-05
      batch rate adapted learning_rate :              9.149472287300311e-08
      fit adapted learning_rate :              3.391509202309601e-08
    epoch : 8 ; learning_rate : 3.391509202309601e-08 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.5078567985525266
    Epoch 8, Loss: 1.7715900136305083, fit: 0.06666666666666667
      Weights saved to src/weights_tanh_softmax_learning_rate_0.0001_hidden_size_784_loss_1.821069827475121_fit_0.066666666666666672024-01-02173145
  self.fit : 0.06666666666666667
  self.loss : 1.821069827475121
  current_accuracy : 0.08
  LR: 0.0001, Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          0.0001
    batch_rate :          0.001
      exponential decayed learning_rate :              0.0001
      batch rate adapted learning_rate :              1.0000000000000001e-07
      fit adapted learning_rate :              5.7582990144185347e-08
    epoch : 0 ; learning_rate : 5.7582990144185347e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.551472578384048
    Epoch 0, Loss: 1.771539486988067, fit: 0.08333333333333333
    Epoch 0, Loss: 1.771539486988067
      exponential decayed learning_rate :              9.988770354914616e-05
      batch rate adapted learning_rate :              9.988770354914616e-08
      fit adapted learning_rate :              4.9797041496516846e-08
    epoch : 1 ; learning_rate : 4.9797041496516846e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5319975208858252
    Epoch 1, Loss: 1.7714825120677018, fit: 0.05
      exponential decayed learning_rate :              9.977553320322105e-05
      batch rate adapted learning_rate :              9.977553320322105e-08
      fit adapted learning_rate :              6.619312726977706e-08
    epoch : 2 ; learning_rate : 6.619312726977706e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5031011608131808
    Epoch 2, Loss: 1.7714154354135954, fit: 0.18333333333333332
      exponential decayed learning_rate :              9.966348882061334e-05
      batch rate adapted learning_rate :              9.966348882061334e-08
      fit adapted learning_rate :              1.971944661339049e-08
    epoch : 3 ; learning_rate : 1.971944661339049e-08 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.425053332922083
    Epoch 3, Loss: 1.7713705253848437, fit: 0.016666666666666666
      exponential decayed learning_rate :              9.955157025987067e-05
      batch rate adapted learning_rate :              9.955157025987067e-08
      fit adapted learning_rate :              8.702703847459248e-08
    epoch : 4 ; learning_rate : 8.702703847459248e-08 ; fit : 0.016666666666666666
    batch_size :          60
    best_batch_loss : 1.494950844560127
    Epoch 4, Loss: 1.7713145987996044, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.943977737969955e-05
      batch rate adapted learning_rate :              9.943977737969955e-08
      fit adapted learning_rate :              5.7260397207952235e-08
    epoch : 5 ; learning_rate : 5.7260397207952235e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4781075287166323
    Epoch 5, Loss: 1.7712330748804168, fit: 0.05
      exponential decayed learning_rate :              9.932811003896519e-05
      batch rate adapted learning_rate :              9.932811003896519e-08
      fit adapted learning_rate :              6.589629760117772e-08
    epoch : 6 ; learning_rate : 6.589629760117772e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5459463154333577
    Epoch 6, Loss: 1.7711672305489472, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.921656809669122e-05
      batch rate adapted learning_rate :              9.921656809669122e-08
      fit adapted learning_rate :              5.713186662851665e-08
    epoch : 7 ; learning_rate : 5.713186662851665e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4991024112659448
    Epoch 7, Loss: 1.7711024573926921, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.910515141205966e-05
      batch rate adapted learning_rate :              9.910515141205966e-08
      fit adapted learning_rate :              3.673611137954086e-08
    epoch : 8 ; learning_rate : 3.673611137954086e-08 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.5037044423390629
    Epoch 8, Loss: 1.7710465556429007, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.899385984441058e-05
      batch rate adapted learning_rate :              9.899385984441058e-08
      fit adapted learning_rate :              5.70036245575556e-08
    epoch : 9 ; learning_rate : 5.70036245575556e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5544116223039646
    Epoch 9, Loss: 1.7709974280278182, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.888269325324206e-05
      batch rate adapted learning_rate :              9.888269325324207e-08
      fit adapted learning_rate :              5.693961151031941e-08
    epoch : 10 ; learning_rate : 5.693961151031941e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5506053876360995
    Epoch 10, Loss: 1.770933790407297, fit: 0.03333333333333333
    Epoch 10, Loss: 1.770933790407297
      exponential decayed learning_rate :              9.877165149820999e-05
      batch rate adapted learning_rate :              9.877165149821e-08
      fit adapted learning_rate :              7.530889249232363e-08
    epoch : 11 ; learning_rate : 7.530889249232363e-08 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4632635257817697
    Epoch 11, Loss: 1.770865669689217, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.866073443912775e-05
      batch rate adapted learning_rate :              9.866073443912775e-08
      fit adapted learning_rate :              5.681180098826381e-08
    epoch : 12 ; learning_rate : 5.681180098826381e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5072497537079153
    Epoch 12, Loss: 1.7707929260962905, fit: 0.05
      exponential decayed learning_rate :              9.854994193596629e-05
      batch rate adapted learning_rate :              9.854994193596629e-08
      fit adapted learning_rate :              6.53800449826708e-08
    epoch : 13 ; learning_rate : 6.53800449826708e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4679285685470211
    Epoch 13, Loss: 1.7707258865539355, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.843927384885367e-05
      batch rate adapted learning_rate :              9.843927384885367e-08
      fit adapted learning_rate :              3.133178569859643e-08
    epoch : 14 ; learning_rate : 3.133178569859643e-08 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4276320517979504
    Epoch 14, Loss: 1.7706720522575838, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.83287300380751e-05
      batch rate adapted learning_rate :              9.83287300380751e-08
      fit adapted learning_rate :              5.66206229267274e-08
    epoch : 15 ; learning_rate : 5.66206229267274e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.49730847691638
    Epoch 15, Loss: 1.7706254432598645, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.821831036407267e-05
      batch rate adapted learning_rate :              9.821831036407268e-08
      fit adapted learning_rate :              4.896479850005828e-08
    epoch : 16 ; learning_rate : 4.896479850005828e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5292041320248988
    Epoch 16, Loss: 1.7705665608101464, fit: 0.15
      exponential decayed learning_rate :              9.81080146874452e-05
      batch rate adapted learning_rate :              9.810801468744521e-08
      fit adapted learning_rate :              2.6733504432721995e-08
    epoch : 17 ; learning_rate : 2.6733504432721995e-08 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.5037989362807849
    Epoch 17, Loss: 1.770524040763028, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.799784286894803e-05
      batch rate adapted learning_rate :              9.799784286894804e-08
      fit adapted learning_rate :              4.885488878531593e-08
    epoch : 18 ; learning_rate : 4.885488878531593e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4768828719312816
    Epoch 18, Loss: 1.7704837525020363, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.788779476949289e-05
      batch rate adapted learning_rate :              9.78877947694929e-08
      fit adapted learning_rate :              5.636671921447747e-08
    epoch : 19 ; learning_rate : 5.636671921447747e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4474679843169382
    Epoch 19, Loss: 1.7704247974151406, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.777787025014764e-05
      batch rate adapted learning_rate :              9.777787025014764e-08
      fit adapted learning_rate :              5.630342138933685e-08
    epoch : 20 ; learning_rate : 5.630342138933685e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5263311722532271
    Epoch 20, Loss: 1.7703636125978215, fit: 0.2
    Epoch 20, Loss: 1.7703636125978215
      exponential decayed learning_rate :              9.766806917213624e-05
      batch rate adapted learning_rate :              9.766806917213624e-08
      fit adapted learning_rate :              1.6385982928038718e-08
    epoch : 21 ; learning_rate : 1.6385982928038718e-08 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.5283192509129928
    Epoch 21, Loss: 1.7703253189381147, fit: 0.05
      exponential decayed learning_rate :              9.755839139683846e-05
      batch rate adapted learning_rate :              9.755839139683846e-08
      fit adapted learning_rate :              6.472223009635772e-08
    epoch : 22 ; learning_rate : 6.472223009635772e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4915375016780978
    Epoch 22, Loss: 1.7702824181090642, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.74488367857897e-05
      batch rate adapted learning_rate :              9.74488367857897e-08
      fit adapted learning_rate :              7.430030643089962e-08
    epoch : 23 ; learning_rate : 7.430030643089962e-08 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.5359772947712287
    Epoch 23, Loss: 1.7702040794251679, fit: 0.1
      exponential decayed learning_rate :              9.73394052006809e-05
      batch rate adapted learning_rate :              9.73394052006809e-08
      fit adapted learning_rate :              4.19014221797966e-08
    epoch : 24 ; learning_rate : 4.19014221797966e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.549587709204456
    Epoch 24, Loss: 1.7701398150921435, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.723009650335829e-05
      batch rate adapted learning_rate :              9.723009650335828e-08
      fit adapted learning_rate :              5.59879968867107e-08
    epoch : 25 ; learning_rate : 5.59879968867107e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.498306158144366
    Epoch 25, Loss: 1.770085085775162, fit: 0.1
      exponential decayed learning_rate :              9.712091055582324e-05
      batch rate adapted learning_rate :              9.712091055582324e-08
      fit adapted learning_rate :              4.180736739962479e-08
    epoch : 26 ; learning_rate : 4.180736739962479e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5600371365071062
    Epoch 26, Loss: 1.770031764989491, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.70118472202321e-05
      batch rate adapted learning_rate :              9.701184722023211e-08
      fit adapted learning_rate :              5.58623224235184e-08
    epoch : 27 ; learning_rate : 5.58623224235184e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4736535094228216
    Epoch 27, Loss: 1.7699787538580545, fit: 0.05
      exponential decayed learning_rate :              9.690290635889605e-05
      batch rate adapted learning_rate :              9.690290635889605e-08
      fit adapted learning_rate :              6.428736792978243e-08
    epoch : 28 ; learning_rate : 6.428736792978243e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5074240732179591
    Epoch 28, Loss: 1.7699141065312678, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.679408783428076e-05
      batch rate adapted learning_rate :              9.679408783428077e-08
      fit adapted learning_rate :              4.825478049087032e-08
    epoch : 29 ; learning_rate : 4.825478049087032e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5343377116793735
    Epoch 29, Loss: 1.7698502706056585, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.668539150900652e-05
      batch rate adapted learning_rate :              9.668539150900651e-08
      fit adapted learning_rate :              5.5674339463498234e-08
    epoch : 30 ; learning_rate : 5.5674339463498234e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5350067398620397
    Epoch 30, Loss: 1.7697922890963678, fit: 0.11666666666666667
    Epoch 30, Loss: 1.7697922890963678
      exponential decayed learning_rate :              9.657681724584776e-05
      batch rate adapted learning_rate :              9.657681724584776e-08
      fit adapted learning_rate :              3.579891321969468e-08
    epoch : 31 ; learning_rate : 3.579891321969468e-08 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.534897156838903
    Epoch 31, Loss: 1.7697435410411149, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.646836490773307e-05
      batch rate adapted learning_rate :              9.646836490773307e-08
      fit adapted learning_rate :              4.8092397759930044e-08
    epoch : 32 ; learning_rate : 4.8092397759930044e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4809241366291248
    Epoch 32, Loss: 1.7696952414873872, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.636003435774494e-05
      batch rate adapted learning_rate :              9.636003435774494e-08
      fit adapted learning_rate :              3.0669994082259394e-08
    epoch : 33 ; learning_rate : 3.0669994082259394e-08 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.5358108395439738
    Epoch 33, Loss: 1.7696523658244798, fit: 0.1
      exponential decayed learning_rate :              9.625182545911963e-05
      batch rate adapted learning_rate :              9.625182545911963e-08
      fit adapted learning_rate :              4.143325476279421e-08
    epoch : 34 ; learning_rate : 4.143325476279421e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5181653159823394
    Epoch 34, Loss: 1.7696142853329717, fit: 0.1
      exponential decayed learning_rate :              9.614373807524702e-05
      batch rate adapted learning_rate :              9.614373807524701e-08
      fit adapted learning_rate :              4.138672668822236e-08
    epoch : 35 ; learning_rate : 4.138672668822236e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.457866634075908
    Epoch 35, Loss: 1.7695680760296313, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.603577206967029e-05
      batch rate adapted learning_rate :              9.60357720696703e-08
      fit adapted learning_rate :              5.5300269165770544e-08
    epoch : 36 ; learning_rate : 5.5300269165770544e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5425413651682838
    Epoch 36, Loss: 1.7695130317132404, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.592792730608597e-05
      batch rate adapted learning_rate :              9.592792730608597e-08
      fit adapted learning_rate :              3.555838391561199e-08
    epoch : 37 ; learning_rate : 3.555838391561199e-08 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.524657200462063
    Epoch 37, Loss: 1.7694636723571424, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.582020364834356e-05
      batch rate adapted learning_rate :              9.582020364834357e-08
      fit adapted learning_rate :              3.551845311249377e-08
    epoch : 38 ; learning_rate : 3.551845311249377e-08 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.48774431761393
    Epoch 38, Loss: 1.769422625782301, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.571260096044555e-05
      batch rate adapted learning_rate :              9.571260096044555e-08
      fit adapted learning_rate :              4.771562657281259e-08
    epoch : 39 ; learning_rate : 4.771562657281259e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5428173939611944
    Epoch 39, Loss: 1.7693798003016108, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.560511910654706e-05
      batch rate adapted learning_rate :              9.560511910654705e-08
      fit adapted learning_rate :              5.505228631245965e-08
    epoch : 40 ; learning_rate : 5.505228631245965e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4915657018375592
    Epoch 40, Loss: 1.7693193087682355, fit: 0.1
    Epoch 40, Loss: 1.7693193087682355
      exponential decayed learning_rate :              9.549775795095581e-05
      batch rate adapted learning_rate :              9.549775795095581e-08
      fit adapted learning_rate :              4.1108653426403274e-08
    epoch : 41 ; learning_rate : 4.1108653426403274e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4840982491438155
    Epoch 41, Loss: 1.7692674813798366, fit: 0.1
      exponential decayed learning_rate :              9.539051735813189e-05
      batch rate adapted learning_rate :              9.539051735813189e-08
      fit adapted learning_rate :              4.1062489867611614e-08
    epoch : 42 ; learning_rate : 4.1062489867611614e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4234469481704877
    Epoch 42, Loss: 1.7692224401319976, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.528339719268758e-05
      batch rate adapted learning_rate :              9.528339719268759e-08
      fit adapted learning_rate :              4.750165551257104e-08
    epoch : 43 ; learning_rate : 4.750165551257104e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5403412914969679
    Epoch 43, Loss: 1.7691684074090173, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.517639731938723e-05
      batch rate adapted learning_rate :              9.517639731938723e-08
      fit adapted learning_rate :              3.0293259669450874e-08
    epoch : 44 ; learning_rate : 3.0293259669450874e-08 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4968336216912836
    Epoch 44, Loss: 1.769128996989172, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.5069517603147e-05
      batch rate adapted learning_rate :              9.5069517603147e-08
      fit adapted learning_rate :              4.7395030068025e-08
    epoch : 45 ; learning_rate : 4.7395030068025e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4172283931853367
    Epoch 45, Loss: 1.7690838459619118, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.49627579090348e-05
      batch rate adapted learning_rate :              9.49627579090348e-08
      fit adapted learning_rate :              4.73418071313775e-08
    epoch : 46 ; learning_rate : 4.73418071313775e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4757013353558113
    Epoch 46, Loss: 1.7690315233594502, fit: 0.1
      exponential decayed learning_rate :              9.485611810227e-05
      batch rate adapted learning_rate :              9.485611810227001e-08
      fit adapted learning_rate :              4.083244851091467e-08
    epoch : 47 ; learning_rate : 4.083244851091467e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.509538846709942
    Epoch 47, Loss: 1.7689836607065932, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.474959804822344e-05
      batch rate adapted learning_rate :              9.474959804822343e-08
      fit adapted learning_rate :              4.7235540493372425e-08
    epoch : 48 ; learning_rate : 4.7235540493372425e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4544066588236955
    Epoch 48, Loss: 1.7689338943737405, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.464319761241698e-05
      batch rate adapted learning_rate :              9.464319761241699e-08
      fit adapted learning_rate :              7.216113415145661e-08
    epoch : 49 ; learning_rate : 7.216113415145661e-08 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.5291501013171456
    Epoch 49, Loss: 1.7688671605820099, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.453691666052364e-05
      batch rate adapted learning_rate :              9.453691666052365e-08
      fit adapted learning_rate :              5.4437183403246044e-08
    epoch : 50 ; learning_rate : 5.4437183403246044e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4370037480491153
    Epoch 50, Loss: 1.7687954866406164, fit: 0.06666666666666667
    Epoch 50, Loss: 1.7687954866406164
      exponential decayed learning_rate :              9.443075505836723e-05
      batch rate adapted learning_rate :              9.443075505836723e-08
      fit adapted learning_rate :              5.43760523783394e-08
    epoch : 51 ; learning_rate : 5.43760523783394e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5193823665604638
    Epoch 51, Loss: 1.768730404412647, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.43247126719222e-05
      batch rate adapted learning_rate :              9.432471267192219e-08
      fit adapted learning_rate :              3.0022180863057686e-08
    epoch : 52 ; learning_rate : 3.0022180863057686e-08 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.5455685070442589
    Epoch 52, Loss: 1.7686876402057574, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.421878936731354e-05
      batch rate adapted learning_rate :              9.421878936731354e-08
      fit adapted learning_rate :              3.492484387468428e-08
    epoch : 53 ; learning_rate : 3.492484387468428e-08 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4817277531564872
    Epoch 53, Loss: 1.7686520302530935, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.411298501081657e-05
      batch rate adapted learning_rate :              9.411298501081657e-08
      fit adapted learning_rate :              5.419307088317714e-08
    epoch : 54 ; learning_rate : 5.419307088317714e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4072656332596158
    Epoch 54, Loss: 1.7685998063772703, fit: 0.1
      exponential decayed learning_rate :              9.400729946885681e-05
      batch rate adapted learning_rate :              9.400729946885681e-08
      fit adapted learning_rate :              4.046705992199328e-08
    epoch : 55 ; learning_rate : 4.046705992199328e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5038482854014883
    Epoch 55, Loss: 1.7685480221678125, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.390173260800975e-05
      batch rate adapted learning_rate :              9.390173260800975e-08
      fit adapted learning_rate :              3.4807317870662626e-08
    epoch : 56 ; learning_rate : 3.4807317870662626e-08 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4960607426361685
    Epoch 56, Loss: 1.7685041515555413, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.379628429500068e-05
      batch rate adapted learning_rate :              9.379628429500068e-08
      fit adapted learning_rate :              7.151540126146056e-08
    epoch : 57 ; learning_rate : 7.151540126146056e-08 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4873312813339035
    Epoch 57, Loss: 1.7684434873801298, fit: 0.05
      exponential decayed learning_rate :              9.36909543967046e-05
      batch rate adapted learning_rate :              9.36909543967046e-08
      fit adapted learning_rate :              6.215649337374563e-08
    epoch : 58 ; learning_rate : 6.215649337374563e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4965349697244146
    Epoch 58, Loss: 1.7683697120913229, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.3585742780146e-05
      batch rate adapted learning_rate :              9.3585742780146e-08
      fit adapted learning_rate :              7.135487293104533e-08
    epoch : 59 ; learning_rate : 7.135487293104533e-08 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.513554458299318
    Epoch 59, Loss: 1.7682925696185545, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.348064931249869e-05
      batch rate adapted learning_rate :              9.348064931249868e-08
      fit adapted learning_rate :              4.6602931167052816e-08
    epoch : 60 ; learning_rate : 4.6602931167052816e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4756225513719872
    Epoch 60, Loss: 1.7682251278051133, fit: 0.1
    Epoch 60, Loss: 1.7682251278051133
      exponential decayed learning_rate :              9.337567386108562e-05
      batch rate adapted learning_rate :              9.337567386108561e-08
      fit adapted learning_rate :              4.019516580885146e-08
    epoch : 61 ; learning_rate : 4.019516580885146e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5042195929662932
    Epoch 61, Loss: 1.7681779828760589, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.327081629337876e-05
      batch rate adapted learning_rate :              9.327081629337876e-08
      fit adapted learning_rate :              4.649832306025704e-08
    epoch : 62 ; learning_rate : 4.649832306025704e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5471408080918365
    Epoch 62, Loss: 1.768129232610044, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.316607647699888e-05
      batch rate adapted learning_rate :              9.316607647699889e-08
      fit adapted learning_rate :              5.364781263547445e-08
    epoch : 63 ; learning_rate : 5.364781263547445e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5320987334935834
    Epoch 63, Loss: 1.7680689009563486, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.306145427971543e-05
      batch rate adapted learning_rate :              9.306145427971543e-08
      fit adapted learning_rate :              3.449584507819709e-08
    epoch : 64 ; learning_rate : 3.449584507819709e-08 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4638418638310848
    Epoch 64, Loss: 1.7680207857326218, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.295694956944634e-05
      batch rate adapted learning_rate :              9.295694956944634e-08
      fit adapted learning_rate :              4.634185100493195e-08
    epoch : 65 ; learning_rate : 4.634185100493195e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4954319354490886
    Epoch 65, Loss: 1.7679719950754509, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.285256221425784e-05
      batch rate adapted learning_rate :              9.285256221425785e-08
      fit adapted learning_rate :              4.6289810750993425e-08
    epoch : 66 ; learning_rate : 4.6289810750993425e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.501997308691188
    Epoch 66, Loss: 1.7679216217810738, fit: 0.1
      exponential decayed learning_rate :              9.274829208236437e-05
      batch rate adapted learning_rate :              9.274829208236438e-08
      fit adapted learning_rate :              3.9925098524960494e-08
    epoch : 67 ; learning_rate : 3.9925098524960494e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4836838719958036
    Epoch 67, Loss: 1.7678709798704477, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.264413904212832e-05
      batch rate adapted learning_rate :              9.264413904212832e-08
      fit adapted learning_rate :              5.334726545379411e-08
    epoch : 68 ; learning_rate : 5.334726545379411e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5047312118721468
    Epoch 68, Loss: 1.7678179711876847, fit: 0.05
      exponential decayed learning_rate :              9.25401029620599e-05
      batch rate adapted learning_rate :              9.254010296205991e-08
      fit adapted learning_rate :              6.139299501862401e-08
    epoch : 69 ; learning_rate : 6.139299501862401e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5379463783845608
    Epoch 69, Loss: 1.7677540794871114, fit: 0.05
      exponential decayed learning_rate :              9.243618371081702e-05
      batch rate adapted learning_rate :              9.243618371081702e-08
      fit adapted learning_rate :              6.132405286414521e-08
    epoch : 70 ; learning_rate : 6.132405286414521e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5321668364302299
    Epoch 70, Loss: 1.7676800901122531, fit: 0.08333333333333333
    Epoch 70, Loss: 1.7676800901122531
      exponential decayed learning_rate :              9.233238115720502e-05
      batch rate adapted learning_rate :              9.233238115720503e-08
      fit adapted learning_rate :              4.6030484760272095e-08
    epoch : 71 ; learning_rate : 4.6030484760272095e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5188057054838353
    Epoch 71, Loss: 1.7676177343476431, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.222869517017664e-05
      batch rate adapted learning_rate :              9.222869517017665e-08
      fit adapted learning_rate :              5.3108040449953564e-08
    epoch : 72 ; learning_rate : 5.3108040449953564e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4650605346715144
    Epoch 72, Loss: 1.7675606093424274, fit: 0.05
      exponential decayed learning_rate :              9.21251256188317e-05
      batch rate adapted learning_rate :              9.212512561883171e-08
      fit adapted learning_rate :              6.111769057060437e-08
    epoch : 73 ; learning_rate : 6.111769057060437e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5513567581868015
    Epoch 73, Loss: 1.7674952437381524, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.202167237241712e-05
      batch rate adapted learning_rate :              9.202167237241712e-08
      fit adapted learning_rate :              4.58755870331279e-08
    epoch : 74 ; learning_rate : 4.58755870331279e-08 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5416338918967376
    Epoch 74, Loss: 1.7674344405368088, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.191833530032654e-05
      batch rate adapted learning_rate :              9.191833530032654e-08
      fit adapted learning_rate :              5.292932595668627e-08
    epoch : 75 ; learning_rate : 5.292932595668627e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.496670723377753
    Epoch 75, Loss: 1.7673754006430589, fit: 0.05
      exponential decayed learning_rate :              9.181511427210033e-05
      batch rate adapted learning_rate :              9.181511427210033e-08
      fit adapted learning_rate :              6.091202270925134e-08
    epoch : 76 ; learning_rate : 6.091202270925134e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.473084566050394
    Epoch 76, Loss: 1.7673130987383372, fit: 0.23333333333333334
      exponential decayed learning_rate :              9.171200915742537e-05
      batch rate adapted learning_rate :              9.171200915742536e-08
      fit adapted learning_rate :              1.0946590152748163e-08
    epoch : 77 ; learning_rate : 1.0946590152748163e-08 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.5372451771582643
    Epoch 77, Loss: 1.7672685874412666, fit: 0.16666666666666666
      exponential decayed learning_rate :              9.160901982613482e-05
      batch rate adapted learning_rate :              9.160901982613482e-08
      fit adapted learning_rate :              2.1305330128781775e-08
    epoch : 78 ; learning_rate : 2.1305330128781775e-08 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.525859264331655
    Epoch 78, Loss: 1.7672495183839672, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.150614614820807e-05
      batch rate adapted learning_rate :              9.150614614820807e-08
      fit adapted learning_rate :              3.3919326381293025e-08
    epoch : 79 ; learning_rate : 3.3919326381293025e-08 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.5132209432750756
    Epoch 79, Loss: 1.7672170612283535, fit: 0.05
      exponential decayed learning_rate :              9.14033879937705e-05
      batch rate adapted learning_rate :              9.14033879937705e-08
      fit adapted learning_rate :              6.063887508410872e-08
    epoch : 80 ; learning_rate : 6.063887508410872e-08 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.515150880823669
    Epoch 80, Loss: 1.767160745609576, fit: 0.16666666666666666
    Epoch 80, Loss: 1.767160745609576
      exponential decayed learning_rate :              9.130074523309332e-05
      batch rate adapted learning_rate :              9.130074523309332e-08
      fit adapted learning_rate :              2.1233635311093185e-08
    epoch : 81 ; learning_rate : 2.1233635311093185e-08 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.406867928201169
    Epoch 81, Loss: 1.767113491375404, fit: 0.18333333333333332
      exponential decayed learning_rate :              9.119821773659343e-05
      batch rate adapted learning_rate :              9.119821773659343e-08
      fit adapted learning_rate :              1.8044505637666965e-08
    epoch : 82 ; learning_rate : 1.8044505637666965e-08 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.5118505103738002
    Epoch 82, Loss: 1.767092987736301, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.109580537483329e-05
      batch rate adapted learning_rate :              9.10958053748333e-08
      fit adapted learning_rate :              5.245568863075652e-08
    epoch : 83 ; learning_rate : 5.245568863075652e-08 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4403744271999932
    Epoch 83, Loss: 1.767050781666045, fit: 0.1
      exponential decayed learning_rate :              9.099350801852062e-05
      batch rate adapted learning_rate :              9.099350801852062e-08
      fit adapted learning_rate :              3.9169721524845205e-08
    epoch : 84 ; learning_rate : 3.9169721524845205e-08 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.544919230974262
    Epoch 84, Loss: 1.7669973307231572, fit: 0.15
      exponential decayed learning_rate :              9.08913255385084e-05
      batch rate adapted learning_rate :              9.08913255385084e-08
      fit adapted learning_rate :              2.47670250174845e-08
    epoch : 85 ; learning_rate : 2.47670250174845e-08 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.538018046546775
    Epoch 85, Loss: 1.766960344720115, fit: 0.016666666666666666
      exponential decayed learning_rate :              9.078925780579464e-05
      batch rate adapted learning_rate :              9.078925780579464e-08
      fit adapted learning_rate :              7.936710803776779e-08
    epoch : 86 ; learning_rate : 7.936710803776779e-08 ; fit : 0.016666666666666666
    batch_size :          60
    best_batch_loss : 1.5055042998334187
    Epoch 86, Loss: 1.7669011018600587, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.06873046915222e-05
      batch rate adapted learning_rate :              9.06873046915222e-08
      fit adapted learning_rate :              2.8864446933455113e-08
    epoch : 87 ; learning_rate : 2.8864446933455113e-08 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.5320051828132628
    Epoch 87, Loss: 1.7668338271088522, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.058546606697859e-05
      batch rate adapted learning_rate :              9.05854660669786e-08
      fit adapted learning_rate :              6.906729837891545e-08
    epoch : 88 ; learning_rate : 6.906729837891545e-08 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.470713132022211
    Epoch 88, Loss: 1.7667778870173438, fit: 0.11666666666666667
      Weights saved to src/weights_tanh_softmax_learning_rate_0.0001_hidden_size_784_loss_1.7178772999280274_fit_0.116666666666666672024-01-02174204
  self.fit : 0.11666666666666667
  self.loss : 1.7178772999280274
  current_accuracy : 0.0822
  LR: 0.0001, Epochs: 1, Hidden Size: 784, Samples: 1, Accuracy mean: 0.0799
  LR: 0.0001, Epochs: 10, Hidden Size: 784, Samples: 1, Accuracy mean: 0.08
  LR: 0.0001, Epochs: 100, Hidden Size: 784, Samples: 1, Accuracy mean: 0.0822
  LR: 1e-07
  LR: 1e-07, Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  LR: 1e-07, Hidden Size: 784, Sample: 1/1
  LR: 1e-07, Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          1e-07
    batch_rate :          0.001
      exponential decayed learning_rate :              1e-07
      batch rate adapted learning_rate :              1e-10
      fit adapted learning_rate :              1e-10
    epoch : 0 ; learning_rate : 1e-10 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.5109193431622752
    Epoch 0, Loss: 1.7383924416256076, fit: 0.1
    Epoch 0, Loss: 1.7383924416256076
      Weights saved to src/weights_tanh_softmax_learning_rate_1e-07_hidden_size_784_loss_1.7731907420479134_fit_0.12024-01-02174211
  self.fit : 0.1
  self.loss : 1.7731907420479134
  current_accuracy : 0.1041
  LR: 1e-07, Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          1e-07
    batch_rate :          0.001
      exponential decayed learning_rate :              1e-07
      batch rate adapted learning_rate :              1e-10
      fit adapted learning_rate :              4.304672100000001e-11
    epoch : 0 ; learning_rate : 4.304672100000001e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4532084020926905
    Epoch 0, Loss: 1.738392309026006, fit: 0.1
    Epoch 0, Loss: 1.738392309026006
      exponential decayed learning_rate :              9.889503892939223e-08
      batch rate adapted learning_rate :              9.889503892939223e-11
      fit adapted learning_rate :              4.257107149077687e-11
    epoch : 1 ; learning_rate : 4.257107149077687e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4707000137876567
    Epoch 1, Loss: 1.7383922261193023, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.780228724846004e-08
      batch rate adapted learning_rate :              9.780228724846004e-11
      fit adapted learning_rate :              7.45697963350457e-11
    epoch : 2 ; learning_rate : 7.45697963350457e-11 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.505888172663506
    Epoch 2, Loss: 1.738392109091157, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.672161004820058e-08
      batch rate adapted learning_rate :              9.672161004820058e-11
      fit adapted learning_rate :              5.5695195181352716e-11
    epoch : 3 ; learning_rate : 5.5695195181352716e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4508272436432679
    Epoch 3, Loss: 1.7383919782287929, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.565287391030293e-08
      batch rate adapted learning_rate :              9.565287391030293e-11
      fit adapted learning_rate :              3.54564276394867e-11
    epoch : 4 ; learning_rate : 3.54564276394867e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4940781310660616
    Epoch 4, Loss: 1.7383918921333923, fit: 0.1
      exponential decayed learning_rate :              9.459594689067654e-08
      batch rate adapted learning_rate :              9.459594689067655e-11
      fit adapted learning_rate :              4.072045333533772e-11
    epoch : 5 ; learning_rate : 4.072045333533772e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4993094059285357
    Epoch 5, Loss: 1.7383918114440446, fit: 0.15
      exponential decayed learning_rate :              9.355069850316177e-08
      batch rate adapted learning_rate :              9.355069850316177e-11
      fit adapted learning_rate :              2.5491678952897587e-11
    epoch : 6 ; learning_rate : 2.5491678952897587e-11 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.432680424291546
    Epoch 6, Loss: 1.7383917510524187, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.25169997034202e-08
      batch rate adapted learning_rate :              9.25169997034202e-11
      fit adapted learning_rate :              5.327405482091644e-11
    epoch : 7 ; learning_rate : 5.327405482091644e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4466658822544027
    Epoch 7, Loss: 1.7383916721226684, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.14947228730031e-08
      batch rate adapted learning_rate :              9.14947228730031e-11
      fit adapted learning_rate :              5.268539725441106e-11
    epoch : 8 ; learning_rate : 5.268539725441106e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4311800424318037
    Epoch 8, Loss: 1.7383915744994398, fit: 0.06666666666666667
      Weights saved to src/weights_tanh_softmax_learning_rate_1e-07_hidden_size_784_loss_1.826582025795543_fit_0.066666666666666672024-01-02174316
  self.fit : 0.06666666666666667
  self.loss : 1.826582025795543
  current_accuracy : 0.1041
  LR: 1e-07, Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          1e-07
    batch_rate :          0.001
      exponential decayed learning_rate :              1e-07
      batch rate adapted learning_rate :              1e-10
      fit adapted learning_rate :              5.7582990144185346e-11
    epoch : 0 ; learning_rate : 5.7582990144185346e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4667076918247508
    Epoch 0, Loss: 1.7383914582843807, fit: 0.1
    Epoch 0, Loss: 1.7383914582843807
      exponential decayed learning_rate :              9.988770354914615e-08
      batch rate adapted learning_rate :              9.988770354914615e-11
      fit adapted learning_rate :              4.299838106010805e-11
    epoch : 1 ; learning_rate : 4.299838106010805e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5016240875717122
    Epoch 1, Loss: 1.7383913646062346, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.977553320322104e-08
      batch rate adapted learning_rate :              9.977553320322104e-11
      fit adapted learning_rate :              7.607430663950995e-11
    epoch : 2 ; learning_rate : 7.607430663950995e-11 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4753294238495551
    Epoch 2, Loss: 1.7383912385148408, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.966348882061334e-08
      batch rate adapted learning_rate :              9.966348882061333e-11
      fit adapted learning_rate :              4.9685263672578925e-11
    epoch : 3 ; learning_rate : 4.9685263672578925e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4178067705613286
    Epoch 3, Loss: 1.738391124049494, fit: 0.05
      exponential decayed learning_rate :              9.955157025987065e-08
      batch rate adapted learning_rate :              9.955157025987065e-11
      fit adapted learning_rate :              6.604454567730677e-11
    epoch : 4 ; learning_rate : 6.604454567730677e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.482976030134608
    Epoch 4, Loss: 1.7383910078900788, fit: 0.18333333333333332
      exponential decayed learning_rate :              9.943977737969955e-08
      batch rate adapted learning_rate :              9.943977737969954e-11
      fit adapted learning_rate :              1.9675183003234872e-11
    epoch : 5 ; learning_rate : 1.9675183003234872e-11 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.4254533824521682
    Epoch 5, Loss: 1.7383909227104766, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.932811003896517e-08
      batch rate adapted learning_rate :              9.932811003896517e-11
      fit adapted learning_rate :              5.7196095814142884e-11
    epoch : 6 ; learning_rate : 5.7196095814142884e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4792365315544904
    Epoch 6, Loss: 1.7383908429843904, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.921656809669121e-08
      batch rate adapted learning_rate :              9.921656809669121e-11
      fit adapted learning_rate :              3.1579187125341933e-11
    epoch : 7 ; learning_rate : 3.1579187125341933e-11 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4052806540346465
    Epoch 7, Loss: 1.7383907630048379, fit: 0.18333333333333332
      exponential decayed learning_rate :              9.910515141205964e-08
      batch rate adapted learning_rate :              9.910515141205964e-11
      fit adapted learning_rate :              1.9608973812864203e-11
    epoch : 8 ; learning_rate : 1.9608973812864203e-11 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.4690491521763926
    Epoch 8, Loss: 1.7383907095183435, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.899385984441057e-08
      batch rate adapted learning_rate :              9.899385984441057e-11
      fit adapted learning_rate :              3.6694858030279914e-11
    epoch : 9 ; learning_rate : 3.6694858030279914e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4785498965688666
    Epoch 9, Loss: 1.73839065749075, fit: 0.2
      exponential decayed learning_rate :              9.888269325324206e-08
      batch rate adapted learning_rate :              9.888269325324206e-11
      fit adapted learning_rate :              1.6589763033713856e-11
    epoch : 10 ; learning_rate : 1.6589763033713856e-11 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.495253155440205
    Epoch 10, Loss: 1.7383906021869033, fit: 0.11666666666666667
    Epoch 10, Loss: 1.7383906021869033
      exponential decayed learning_rate :              9.877165149820997e-08
      batch rate adapted learning_rate :              9.877165149820997e-11
      fit adapted learning_rate :              3.6612490257876754e-11
    epoch : 11 ; learning_rate : 3.6612490257876754e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4591716070675569
    Epoch 11, Loss: 1.7383905536983026, fit: 0.05
      exponential decayed learning_rate :              9.866073443912774e-08
      batch rate adapted learning_rate :              9.866073443912775e-11
      fit adapted learning_rate :              6.545354699290177e-11
    epoch : 12 ; learning_rate : 6.545354699290177e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4431096578469178
    Epoch 12, Loss: 1.7383904546945295, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.854994193596627e-08
      batch rate adapted learning_rate :              9.854994193596627e-11
      fit adapted learning_rate :              4.913012686942073e-11
    epoch : 13 ; learning_rate : 4.913012686942073e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4355067002787303
    Epoch 13, Loss: 1.7383903376223762, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.843927384885365e-08
      batch rate adapted learning_rate :              9.843927384885366e-11
      fit adapted learning_rate :              4.9074955480646383e-11
    epoch : 14 ; learning_rate : 4.9074955480646383e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.491679248194338
    Epoch 14, Loss: 1.7383902449257371, fit: 0.15
      exponential decayed learning_rate :              9.832873003807509e-08
      batch rate adapted learning_rate :              9.832873003807509e-11
      fit adapted learning_rate :              2.6793647274499312e-11
    epoch : 15 ; learning_rate : 2.6793647274499312e-11 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4489454275558975
    Epoch 15, Loss: 1.7383901681617269, fit: 0.1
      exponential decayed learning_rate :              9.821831036407267e-08
      batch rate adapted learning_rate :              9.821831036407267e-11
      fit adapted learning_rate :              4.227976203333646e-11
    epoch : 16 ; learning_rate : 4.227976203333646e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4930236257321754
    Epoch 16, Loss: 1.7383900962355208, fit: 0.16666666666666666
      exponential decayed learning_rate :              9.81080146874452e-08
      batch rate adapted learning_rate :              9.81080146874452e-11
      fit adapted learning_rate :              2.28167886214964e-11
    epoch : 17 ; learning_rate : 2.28167886214964e-11 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4592474006804514
    Epoch 17, Loss: 1.7383900353933077, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.799784286894802e-08
      batch rate adapted learning_rate :              9.799784286894802e-11
      fit adapted learning_rate :              3.632565632860073e-11
    epoch : 18 ; learning_rate : 3.632565632860073e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.435585945833098
    Epoch 18, Loss: 1.738389981846317, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.788779476949287e-08
      batch rate adapted learning_rate :              9.788779476949287e-11
      fit adapted learning_rate :              3.115625794776883e-11
    epoch : 19 ; learning_rate : 3.115625794776883e-11 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4587914110496636
    Epoch 19, Loss: 1.7383899112433039, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.777787025014763e-08
      batch rate adapted learning_rate :              9.777787025014763e-11
      fit adapted learning_rate :              3.1121270575874613e-11
    epoch : 20 ; learning_rate : 3.1121270575874613e-11 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.434073001936293
    Epoch 20, Loss: 1.7383898500048987, fit: 0.08333333333333333
    Epoch 20, Loss: 1.7383898500048987
      exponential decayed learning_rate :              9.766806917213623e-08
      batch rate adapted learning_rate :              9.766806917213623e-11
      fit adapted learning_rate :              4.869048662287641e-11
    epoch : 21 ; learning_rate : 4.869048662287641e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.453467705484836
    Epoch 21, Loss: 1.7383897723620056, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.755839139683845e-08
      batch rate adapted learning_rate :              9.755839139683846e-11
      fit adapted learning_rate :              3.616276128232611e-11
    epoch : 22 ; learning_rate : 3.616276128232611e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4817356130998922
    Epoch 22, Loss: 1.7383896874162945, fit: 0.05
      exponential decayed learning_rate :              9.744883678578969e-08
      batch rate adapted learning_rate :              9.74488367857897e-11
      fit adapted learning_rate :              6.464954932904603e-11
    epoch : 23 ; learning_rate : 6.464954932904603e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5039517481822378
    Epoch 23, Loss: 1.7383895895365258, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.73394052006809e-08
      batch rate adapted learning_rate :              9.73394052006809e-11
      fit adapted learning_rate :              4.8526637692092664e-11
    epoch : 24 ; learning_rate : 4.8526637692092664e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4449951217173322
    Epoch 24, Loss: 1.7383894823363455, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.723009650335828e-08
      batch rate adapted learning_rate :              9.723009650335829e-11
      fit adapted learning_rate :              3.604106954783617e-11
    epoch : 25 ; learning_rate : 3.604106954783617e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4274003332871128
    Epoch 25, Loss: 1.738389393155996, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.712091055582324e-08
      batch rate adapted learning_rate :              9.712091055582324e-11
      fit adapted learning_rate :              5.592512435330276e-11
    epoch : 26 ; learning_rate : 5.592512435330276e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4360593403027584
    Epoch 26, Loss: 1.7383893084057238, fit: 0.16666666666666666
      exponential decayed learning_rate :              9.70118472202321e-08
      batch rate adapted learning_rate :              9.70118472202321e-11
      fit adapted learning_rate :              2.256185510283492e-11
    epoch : 27 ; learning_rate : 2.256185510283492e-11 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4610141454651653
    Epoch 27, Loss: 1.73838922818419, fit: 0.15
      exponential decayed learning_rate :              9.690290635889603e-08
      batch rate adapted learning_rate :              9.690290635889603e-11
      fit adapted learning_rate :              2.6405123831546683e-11
    epoch : 28 ; learning_rate : 2.6405123831546683e-11 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4842900907875862
    Epoch 28, Loss: 1.7383891793867494, fit: 0.2
      exponential decayed learning_rate :              9.679408783428076e-08
      batch rate adapted learning_rate :              9.679408783428077e-11
      fit adapted learning_rate :              1.6239353191187016e-11
    epoch : 29 ; learning_rate : 1.6239353191187016e-11 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.4541340146545418
    Epoch 29, Loss: 1.7383891387224728, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.668539150900651e-08
      batch rate adapted learning_rate :              9.668539150900652e-11
      fit adapted learning_rate :              4.820059208501176e-11
    epoch : 30 ; learning_rate : 4.820059208501176e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4188491412114952
    Epoch 30, Loss: 1.7383890781855595, fit: 0.11666666666666667
    Epoch 30, Loss: 1.7383890781855595
      exponential decayed learning_rate :              9.657681724584774e-08
      batch rate adapted learning_rate :              9.657681724584774e-11
      fit adapted learning_rate :              3.5798913219694674e-11
    epoch : 31 ; learning_rate : 3.5798913219694674e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4478063167631845
    Epoch 31, Loss: 1.738388993579129, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.646836490773306e-08
      batch rate adapted learning_rate :              9.646836490773307e-11
      fit adapted learning_rate :              3.5758712310704716e-11
    epoch : 32 ; learning_rate : 3.5758712310704716e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4229367121615144
    Epoch 32, Loss: 1.7383889235651615, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.636003435774494e-08
      batch rate adapted learning_rate :              9.636003435774494e-11
      fit adapted learning_rate :              5.5486989087153876e-11
    epoch : 33 ; learning_rate : 5.5486989087153876e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4179108372972027
    Epoch 33, Loss: 1.7383888332413857, fit: 0.1
      exponential decayed learning_rate :              9.625182545911963e-08
      batch rate adapted learning_rate :              9.625182545911964e-11
      fit adapted learning_rate :              4.143325476279421e-11
    epoch : 34 ; learning_rate : 4.143325476279421e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4989663894300316
    Epoch 34, Loss: 1.7383887365354456, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.6143738075247e-08
      batch rate adapted learning_rate :              9.6143738075247e-11
      fit adapted learning_rate :              3.060115012897065e-11
    epoch : 35 ; learning_rate : 3.060115012897065e-11 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4240085695804807
    Epoch 35, Loss: 1.738388668512726, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.603577206967028e-08
      batch rate adapted learning_rate :              9.603577206967028e-11
      fit adapted learning_rate :              3.056678612345536e-11
    epoch : 36 ; learning_rate : 3.056678612345536e-11 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4310015144676427
    Epoch 36, Loss: 1.7383886041451466, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.592792730608595e-08
      batch rate adapted learning_rate :              9.592792730608596e-11
      fit adapted learning_rate :              5.523816892618476e-11
    epoch : 37 ; learning_rate : 5.523816892618476e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4683915113974426
    Epoch 37, Loss: 1.7383885172551423, fit: 0.05
      exponential decayed learning_rate :              9.582020364834356e-08
      batch rate adapted learning_rate :              9.582020364834356e-11
      fit adapted learning_rate :              6.356908083058987e-11
    epoch : 38 ; learning_rate : 6.356908083058987e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.484439444129317
    Epoch 38, Loss: 1.7383884039534778, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.571260096044553e-08
      batch rate adapted learning_rate :              9.571260096044554e-11
      fit adapted learning_rate :              4.771562657281258e-11
    epoch : 39 ; learning_rate : 4.771562657281258e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4538922136110919
    Epoch 39, Loss: 1.7383882967057707, fit: 0.15
      exponential decayed learning_rate :              9.560511910654705e-08
      batch rate adapted learning_rate :              9.560511910654705e-11
      fit adapted learning_rate :              2.605148910176511e-11
    epoch : 40 ; learning_rate : 2.605148910176511e-11 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.492965134613091
    Epoch 40, Loss: 1.7383882229815795, fit: 0.1
    Epoch 40, Loss: 1.7383882229815795
      exponential decayed learning_rate :              9.549775795095581e-08
      batch rate adapted learning_rate :              9.549775795095581e-11
      fit adapted learning_rate :              4.1108653426403274e-11
    epoch : 41 ; learning_rate : 4.1108653426403274e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4512582536930938
    Epoch 41, Loss: 1.7383881619518695, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.539051735813189e-08
      batch rate adapted learning_rate :              9.539051735813189e-11
      fit adapted learning_rate :              3.535917780550345e-11
    epoch : 42 ; learning_rate : 3.535917780550345e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4391302131585093
    Epoch 42, Loss: 1.7383880807227812, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.528339719268757e-08
      batch rate adapted learning_rate :              9.528339719268757e-11
      fit adapted learning_rate :              3.531947070377676e-11
    epoch : 43 ; learning_rate : 3.531947070377676e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.42409865419205
    Epoch 43, Loss: 1.7383880130102614, fit: 0.21666666666666667
      exponential decayed learning_rate :              9.517639731938721e-08
      batch rate adapted learning_rate :              9.517639731938721e-11
      fit adapted learning_rate :              1.3492801211738814e-11
    epoch : 44 ; learning_rate : 1.3492801211738814e-11 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.4765221941395257
    Epoch 44, Loss: 1.7383879645873526, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.506951760314699e-08
      batch rate adapted learning_rate :              9.506951760314699e-11
      fit adapted learning_rate :              4.7395030068024994e-11
    epoch : 45 ; learning_rate : 4.7395030068024994e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.426796097810425
    Epoch 45, Loss: 1.7383879039888763, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.496275790903479e-08
      batch rate adapted learning_rate :              9.496275790903478e-11
      fit adapted learning_rate :              3.022526135983092e-11
    epoch : 46 ; learning_rate : 3.022526135983092e-11 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4310277338851838
    Epoch 46, Loss: 1.7383878275878146, fit: 0.16666666666666666
      exponential decayed learning_rate :              9.485611810227e-08
      batch rate adapted learning_rate :              9.485611810226999e-11
      fit adapted learning_rate :              2.206050140847624e-11
    epoch : 47 ; learning_rate : 2.206050140847624e-11 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4159854292023268
    Epoch 47, Loss: 1.7383877773349754, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.474959804822342e-08
      batch rate adapted learning_rate :              9.474959804822342e-11
      fit adapted learning_rate :              3.015741568383844e-11
    epoch : 48 ; learning_rate : 3.015741568383844e-11 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4725653886970604
    Epoch 48, Loss: 1.738387726908811, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.464319761241698e-08
      batch rate adapted learning_rate :              9.464319761241698e-11
      fit adapted learning_rate :              3.012354997635625e-11
    epoch : 49 ; learning_rate : 3.012354997635625e-11 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4694168672175125
    Epoch 49, Loss: 1.7383876690769042, fit: 0.05
      exponential decayed learning_rate :              9.453691666052363e-08
      batch rate adapted learning_rate :              9.453691666052363e-11
      fit adapted learning_rate :              6.271772202366272e-11
    epoch : 50 ; learning_rate : 6.271772202366272e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4416124983143486
    Epoch 50, Loss: 1.738387581341698, fit: 0.08333333333333333
    Epoch 50, Loss: 1.738387581341698
      exponential decayed learning_rate :              9.443075505836722e-08
      batch rate adapted learning_rate :              9.443075505836721e-11
      fit adapted learning_rate :              4.70765876189685e-11
    epoch : 51 ; learning_rate : 4.70765876189685e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4378487965838447
    Epoch 51, Loss: 1.7383874692273051, fit: 0.16666666666666666
      exponential decayed learning_rate :              9.432471267192218e-08
      batch rate adapted learning_rate :              9.432471267192218e-11
      fit adapted learning_rate :              2.1936913489434263e-11
    epoch : 52 ; learning_rate : 2.1936913489434263e-11 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4206914727460676
    Epoch 52, Loss: 1.738387399309384, fit: 0.1
      exponential decayed learning_rate :              9.421878936731353e-08
      batch rate adapted learning_rate :              9.421878936731354e-11
      fit adapted learning_rate :              4.055809938852513e-11
    epoch : 53 ; learning_rate : 4.055809938852513e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4408781324430968
    Epoch 53, Loss: 1.738387341169116, fit: 0.05
      exponential decayed learning_rate :              9.411298501081656e-08
      batch rate adapted learning_rate :              9.411298501081656e-11
      fit adapted learning_rate :              6.243647710577697e-11
    epoch : 54 ; learning_rate : 6.243647710577697e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4514433453029822
    Epoch 54, Loss: 1.7383872370236266, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.40072994688568e-08
      batch rate adapted learning_rate :              9.400729946885681e-11
      fit adapted learning_rate :              5.413221398796661e-11
    epoch : 55 ; learning_rate : 5.413221398796661e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.389873060169035
    Epoch 55, Loss: 1.7383871227359218, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.390173260800974e-08
      batch rate adapted learning_rate :              9.390173260800974e-11
      fit adapted learning_rate :              5.407142543288952e-11
    epoch : 56 ; learning_rate : 5.407142543288952e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4836226766145741
    Epoch 56, Loss: 1.7383870161773773, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.379628429500066e-08
      batch rate adapted learning_rate :              9.379628429500067e-11
      fit adapted learning_rate :              3.476823048805645e-11
    epoch : 57 ; learning_rate : 3.476823048805645e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4802860535173288
    Epoch 57, Loss: 1.7383869323671557, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.369095439670459e-08
      batch rate adapted learning_rate :              9.36909543967046e-11
      fit adapted learning_rate :              4.6707774612572397e-11
    epoch : 58 ; learning_rate : 4.6707774612572397e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5005299277304076
    Epoch 58, Loss: 1.7383868509937928, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.358574278014599e-08
      batch rate adapted learning_rate :              9.358574278014599e-11
      fit adapted learning_rate :              7.135487293104533e-11
    epoch : 59 ; learning_rate : 7.135487293104533e-11 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4762586527288302
    Epoch 59, Loss: 1.7383867279163734, fit: 0.15
      exponential decayed learning_rate :              9.348064931249868e-08
      batch rate adapted learning_rate :              9.348064931249868e-11
      fit adapted learning_rate :              2.5472591212155238e-11
    epoch : 60 ; learning_rate : 2.5472591212155238e-11 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.383297389313515
    Epoch 60, Loss: 1.7383866410198274, fit: 0.03333333333333333
    Epoch 60, Loss: 1.7383866410198274
      exponential decayed learning_rate :              9.337567386108561e-08
      batch rate adapted learning_rate :              9.337567386108562e-11
      fit adapted learning_rate :              7.119470493343132e-11
    epoch : 61 ; learning_rate : 7.119470493343132e-11 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4996057199254074
    Epoch 61, Loss: 1.7383865421544633, fit: 0.1
      exponential decayed learning_rate :              9.327081629337875e-08
      batch rate adapted learning_rate :              9.327081629337876e-11
      fit adapted learning_rate :              4.0150028064233303e-11
    epoch : 62 ; learning_rate : 4.0150028064233303e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4529711395299634
    Epoch 62, Loss: 1.7383864353952043, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.316607647699887e-08
      batch rate adapted learning_rate :              9.316607647699888e-11
      fit adapted learning_rate :              2.965340385422162e-11
    epoch : 63 ; learning_rate : 2.965340385422162e-11 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4407406622787855
    Epoch 63, Loss: 1.7383863657617347, fit: 0.15
      exponential decayed learning_rate :              9.306145427971542e-08
      batch rate adapted learning_rate :              9.306145427971543e-11
      fit adapted learning_rate :              2.5358364537578362e-11
    epoch : 64 ; learning_rate : 2.5358364537578362e-11 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4698350666897362
    Epoch 64, Loss: 1.7383863125847967, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.295694956944633e-08
      batch rate adapted learning_rate :              9.295694956944633e-11
      fit adapted learning_rate :              4.634185100493194e-11
    epoch : 65 ; learning_rate : 4.634185100493194e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5118931285682953
    Epoch 65, Loss: 1.7383862422884164, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.285256221425783e-08
      batch rate adapted learning_rate :              9.285256221425783e-11
      fit adapted learning_rate :              4.628981075099342e-11
    epoch : 66 ; learning_rate : 4.628981075099342e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4495292599635572
    Epoch 66, Loss: 1.738386149173909, fit: 0.16666666666666666
      exponential decayed learning_rate :              9.274829208236436e-08
      batch rate adapted learning_rate :              9.274829208236436e-11
      fit adapted learning_rate :              2.1570288443711892e-11
    epoch : 67 ; learning_rate : 2.1570288443711892e-11 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4818244840734054
    Epoch 67, Loss: 1.7383860839039937, fit: 0.13333333333333333
      exponential decayed learning_rate :              9.264413904212832e-08
      batch rate adapted learning_rate :              9.264413904212832e-11
      fit adapted learning_rate :              2.948727877814123e-11
    epoch : 68 ; learning_rate : 2.948727877814123e-11 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4478446901218374
    Epoch 68, Loss: 1.7383860328122804, fit: 0.05
      exponential decayed learning_rate :              9.25401029620599e-08
      batch rate adapted learning_rate :              9.25401029620599e-11
      fit adapted learning_rate :              6.139299501862401e-11
    epoch : 69 ; learning_rate : 6.139299501862401e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4612940899582192
    Epoch 69, Loss: 1.73838594368183, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.243618371081701e-08
      batch rate adapted learning_rate :              9.243618371081701e-11
      fit adapted learning_rate :              4.608223347293638e-11
    epoch : 70 ; learning_rate : 4.608223347293638e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4308106037560475
    Epoch 70, Loss: 1.738385842536317, fit: 0.11666666666666667
    Epoch 70, Loss: 1.738385842536317
      exponential decayed learning_rate :              9.233238115720502e-08
      batch rate adapted learning_rate :              9.233238115720502e-11
      fit adapted learning_rate :              3.4225593622538517e-11
    epoch : 71 ; learning_rate : 3.4225593622538517e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4221491634363574
    Epoch 71, Loss: 1.7383857606683066, fit: 0.05
      exponential decayed learning_rate :              9.222869517017663e-08
      batch rate adapted learning_rate :              9.222869517017663e-11
      fit adapted learning_rate :              6.118640072702604e-11
    epoch : 72 ; learning_rate : 6.118640072702604e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4594371546850542
    Epoch 72, Loss: 1.7383856684943673, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.21251256188317e-08
      batch rate adapted learning_rate :              9.21251256188317e-11
      fit adapted learning_rate :              3.4148768528855417e-11
    epoch : 73 ; learning_rate : 3.4148768528855417e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.459798514270311
    Epoch 73, Loss: 1.738385572030264, fit: 0.05
      exponential decayed learning_rate :              9.202167237241711e-08
      batch rate adapted learning_rate :              9.202167237241711e-11
      fit adapted learning_rate :              6.104905757324974e-11
    epoch : 74 ; learning_rate : 6.104905757324974e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.479220883785451
    Epoch 74, Loss: 1.7383854842952546, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.191833530032653e-08
      batch rate adapted learning_rate :              9.191833530032653e-11
      fit adapted learning_rate :              4.582407037708132e-11
    epoch : 75 ; learning_rate : 4.582407037708132e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4161695835453798
    Epoch 75, Loss: 1.7383853758911845, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.181511427210033e-08
      batch rate adapted learning_rate :              9.181511427210034e-11
      fit adapted learning_rate :              4.57726115724111e-11
    epoch : 76 ; learning_rate : 4.57726115724111e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4698540758704859
    Epoch 76, Loss: 1.7383852833948676, fit: 0.03333333333333333
      exponential decayed learning_rate :              9.171200915742535e-08
      batch rate adapted learning_rate :              9.171200915742535e-11
      fit adapted learning_rate :              6.992623625430332e-11
    epoch : 77 ; learning_rate : 6.992623625430332e-11 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.412748089954753
    Epoch 77, Loss: 1.7383851745584973, fit: 0.1
      exponential decayed learning_rate :              9.16090198261348e-08
      batch rate adapted learning_rate :              9.16090198261348e-11
      fit adapted learning_rate :              3.9434679175390943e-11
    epoch : 78 ; learning_rate : 3.9434679175390943e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4930452733821407
    Epoch 78, Loss: 1.7383850628676334, fit: 0.06666666666666667
      exponential decayed learning_rate :              9.150614614820807e-08
      batch rate adapted learning_rate :              9.150614614820807e-11
      fit adapted learning_rate :              5.269197511784649e-11
    epoch : 79 ; learning_rate : 5.269197511784649e-11 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4135996066151337
    Epoch 79, Loss: 1.7383849749353657, fit: 0.05
      exponential decayed learning_rate :              9.140338799377049e-08
      batch rate adapted learning_rate :              9.14033879937705e-11
      fit adapted learning_rate :              6.063887508410872e-11
    epoch : 80 ; learning_rate : 6.063887508410872e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.450603788342019
    Epoch 80, Loss: 1.7383848589312516, fit: 0.05
    Epoch 80, Loss: 1.7383848589312516
      exponential decayed learning_rate :              9.130074523309331e-08
      batch rate adapted learning_rate :              9.130074523309331e-11
      fit adapted learning_rate :              6.057077977955156e-11
    epoch : 81 ; learning_rate : 6.057077977955156e-11 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4597674094034903
    Epoch 81, Loss: 1.738384738700395, fit: 0.15
      exponential decayed learning_rate :              9.119821773659343e-08
      batch rate adapted learning_rate :              9.119821773659343e-11
      fit adapted learning_rate :              2.4850650233671082e-11
    epoch : 82 ; learning_rate : 2.4850650233671082e-11 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.425826367653955
    Epoch 82, Loss: 1.7383846559855258, fit: 0.16666666666666666
      exponential decayed learning_rate :              9.109580537483327e-08
      batch rate adapted learning_rate :              9.109580537483328e-11
      fit adapted learning_rate :              2.118597285007065e-11
    epoch : 83 ; learning_rate : 2.118597285007065e-11 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.460631782440067
    Epoch 83, Loss: 1.7383846132446847, fit: 0.1
      exponential decayed learning_rate :              9.09935080185206e-08
      batch rate adapted learning_rate :              9.099350801852061e-11
      fit adapted learning_rate :              3.9169721524845206e-11
    epoch : 84 ; learning_rate : 3.9169721524845206e-11 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.440054300527238
    Epoch 84, Loss: 1.7383845557306636, fit: 0.11666666666666667
      exponential decayed learning_rate :              9.08913255385084e-08
      batch rate adapted learning_rate :              9.08913255385084e-11
      fit adapted learning_rate :              3.369142583248648e-11
    epoch : 85 ; learning_rate : 3.369142583248648e-11 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4308675500297283
    Epoch 85, Loss: 1.7383844836098676, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.078925780579464e-08
      batch rate adapted learning_rate :              9.078925780579464e-11
      fit adapted learning_rate :              4.526119109514524e-11
    epoch : 86 ; learning_rate : 4.526119109514524e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4513455049309119
    Epoch 86, Loss: 1.73838440437682, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.068730469152219e-08
      batch rate adapted learning_rate :              9.068730469152218e-11
      fit adapted learning_rate :              4.521036438393122e-11
    epoch : 87 ; learning_rate : 4.521036438393122e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4883378013468327
    Epoch 87, Loss: 1.7383843193996646, fit: 0.08333333333333333
      exponential decayed learning_rate :              9.058546606697858e-08
      batch rate adapted learning_rate :              9.058546606697859e-11
      fit adapted learning_rate :              4.5159594749309966e-11
    epoch : 88 ; learning_rate : 4.5159594749309966e-11 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.424148983601573
    Epoch 88, Loss: 1.7383842292155187, fit: 0.03333333333333333
      Weights saved to src/weights_tanh_softmax_learning_rate_1e-07_hidden_size_784_loss_1.8419713507516633_fit_0.033333333333333332024-01-02175349
  self.fit : 0.03333333333333333
  self.loss : 1.8419713507516633
  current_accuracy : 0.1041
  LR: 1e-07, Epochs: 1, Hidden Size: 784, Samples: 1, Accuracy mean: 0.1041
  LR: 1e-07, Epochs: 10, Hidden Size: 784, Samples: 1, Accuracy mean: 0.1041
  LR: 1e-07, Epochs: 100, Hidden Size: 784, Samples: 1, Accuracy mean: 0.1041
  Results saved to test_combinations_results20240102175349
  normalized_accuracies :      [5.14346440e-02 5.14346440e-02 5.14346440e-02 0.00000000e+00
   2.12539851e-04 4.88841658e-03 1.32837407e-01 3.56004251e-01
   7.18597237e-01 8.43145590e-01 8.74814028e-01 1.00000000e+00]
file_path :  src/mnist_train.csv
save_file :  src/mnist_train.npz
file_path :  src/mnist_test.csv
save_file :  src/mnist_test.npz
file_path :  src/mnist_train.csv
save_file :  src/mnist_train.npz
file_path :  src/mnist_test.csv
save_file :  src/mnist_test.npz
batch_rate :  0.001
  LR: 0.9
  LR: 0.9, Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  LR: 0.9, Hidden Size: 784, Sample: 1/1
  LR: 0.9, Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.9
    batch_rate :          0.001
      exponential decayed learning_rate :              0.9
      batch rate adapted learning_rate :              0.0009000000000000001
      fit adapted learning_rate :              0.0009000000000000001
    epoch : 0 ; learning_rate : 0.0009000000000000001 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 0.7672203728321075
    Epoch 0, Loss: 1.3505071135524103, fit: 0.4166666666666667
    Epoch 0, Loss: 1.3505071135524103
file_path :  src/mnist_train.csv
save_file :  src/mnist_train.npz
file_path :  src/mnist_test.csv
save_file :  src/mnist_test.npz
batch_rate :  0.001
  LR: 0.9
  LR: 0.9, Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  LR: 0.9, Hidden Size: 784, Sample: 1/1
  LR: 0.9, Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.9
    batch_rate :          0.001
      exponential decayed learning_rate :              0.9
      batch rate adapted learning_rate :              0.0009000000000000001
      fit adapted learning_rate :              0.0009000000000000001
    epoch : 0 ; learning_rate : 0.0009000000000000001 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 0.7025108008205069
    Epoch 0, Loss: 1.346000930746073, fit: 0.5
    Epoch 0, Loss: 1.346000930746073
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_0.9641597587073093_fit_0.52024-01-02191039
  self.fit : 0.5
  self.loss : 0.9641597587073093
  current_accuracy : 0.4778
  LR: 0.9, Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          0.9
    batch_rate :          0.001
      exponential decayed learning_rate :              0.9
      batch rate adapted learning_rate :              0.0009000000000000001
      fit adapted learning_rate :              3.5156250000000003e-06
    epoch : 0 ; learning_rate : 3.5156250000000003e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.5998333033357272
    Epoch 0, Loss: 1.0058298547763185, fit: 0.4666666666666667
    Epoch 0, Loss: 1.0058298547763185
      exponential decayed learning_rate :              0.8900553503645301
      batch rate adapted learning_rate :              0.0008900553503645301
      fit adapted learning_rate :              5.8264877632151775e-06
    epoch : 1 ; learning_rate : 5.8264877632151775e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.6623746497784212
    Epoch 1, Loss: 1.00344794696642, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8802205852361404
      batch rate adapted learning_rate :              0.0008802205852361405
      fit adapted learning_rate :              4.469665971977972e-06
    epoch : 2 ; learning_rate : 4.469665971977972e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.5762605747392978
    Epoch 2, Loss: 1.000829579636582, fit: 0.5
      exponential decayed learning_rate :              0.8704944904338053
      batch rate adapted learning_rate :              0.0008704944904338053
      fit adapted learning_rate :              3.400369103257052e-06
    epoch : 3 ; learning_rate : 3.400369103257052e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.5837676581244816
    Epoch 3, Loss: 0.9988768120497349, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8608758651927264
      batch rate adapted learning_rate :              0.0008608758651927265
      fit adapted learning_rate :              2.56397928792866e-06
    epoch : 4 ; learning_rate : 2.56397928792866e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5905675724768819
    Epoch 4, Loss: 0.9974180842262093, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8513635220160889
      batch rate adapted learning_rate :              0.0008513635220160889
      fit adapted learning_rate :              1.058502331423996e-06
    epoch : 5 ; learning_rate : 1.058502331423996e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.6183612188572832
    Epoch 5, Loss: 0.9965354373274768, fit: 0.45
      exponential decayed learning_rate :              0.841956286528456
      batch rate adapted learning_rate :              0.0008419562865284561
      fit adapted learning_rate :              7.0500315402795055e-06
    epoch : 6 ; learning_rate : 7.0500315402795055e-06 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.6401497763875472
    Epoch 6, Loss: 0.9946446428217868, fit: 0.45
      exponential decayed learning_rate :              0.8326529973307818
      batch rate adapted learning_rate :              0.0008326529973307818
      fit adapted learning_rate :              6.972131436293847e-06
    epoch : 7 ; learning_rate : 6.972131436293847e-06 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.5585742372942948
    Epoch 7, Loss: 0.9911934185868458, fit: 0.5
      exponential decayed learning_rate :              0.8234525058570279
      batch rate adapted learning_rate :              0.0008234525058570279
      fit adapted learning_rate :              3.2166113510040154e-06
    epoch : 8 ; learning_rate : 3.2166113510040154e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.6563588153112453
    Epoch 8, Loss: 0.988795022946926, fit: 0.4666666666666667
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_1.0301864498429143_fit_0.46666666666666672024-01-02191156
  self.fit : 0.4666666666666667
  self.loss : 1.0301864498429143
  current_accuracy : 0.4889
  LR: 0.9, Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          0.9
    batch_rate :          0.001
      exponential decayed learning_rate :              0.9
      batch rate adapted learning_rate :              0.0009000000000000001
      fit adapted learning_rate :              5.891587511659807e-06
    epoch : 0 ; learning_rate : 5.891587511659807e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.6718306062118169
    Epoch 0, Loss: 0.9866537408565826, fit: 0.38333333333333336
    Epoch 0, Loss: 0.9866537408565826
      exponential decayed learning_rate :              0.8989893319423155
      batch rate adapted learning_rate :              0.0008989893319423154
      fit adapted learning_rate :              1.880002070557526e-05
    epoch : 1 ; learning_rate : 1.880002070557526e-05 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.5897961761122358
    Epoch 1, Loss: 0.9811059922676909, fit: 0.4
      exponential decayed learning_rate :              0.8979797988289894
      batch rate adapted learning_rate :              0.0008979797988289894
      fit adapted learning_rate :              1.5082612377899514e-05
    epoch : 2 ; learning_rate : 1.5082612377899514e-05 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.5919189332569225
    Epoch 2, Loss: 0.9734694811429471, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.8969713993855201
      batch rate adapted learning_rate :              0.0008969713993855201
      fit adapted learning_rate :              1.875782090130368e-05
    epoch : 3 ; learning_rate : 1.875782090130368e-05 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.5619723037308921
    Epoch 3, Loss: 0.9663407140719228, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.895964132338836
      batch rate adapted learning_rate :              0.000895964132338836
      fit adapted learning_rate :              2.668484006726639e-06
    epoch : 4 ; learning_rate : 2.668484006726639e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5980240879283077
    Epoch 4, Loss: 0.9617502333957607, fit: 0.5
      exponential decayed learning_rate :              0.8949579964172959
      batch rate adapted learning_rate :              0.0008949579964172959
      fit adapted learning_rate :              3.4959296735050623e-06
    epoch : 5 ; learning_rate : 3.4959296735050623e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.5771117338166029
    Epoch 5, Loss: 0.9604763492921253, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8939529903506866
      batch rate adapted learning_rate :              0.0008939529903506867
      fit adapted learning_rate :              2.0108002434659613e-06
    epoch : 6 ; learning_rate : 2.0108002434659613e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5506382882358661
    Epoch 6, Loss: 0.9593322571341304, fit: 0.4
      exponential decayed learning_rate :              0.8929491128702209
      batch rate adapted learning_rate :              0.000892949112870221
      fit adapted learning_rate :              1.4998116171626285e-05
    epoch : 7 ; learning_rate : 1.4998116171626285e-05 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.5935040671082739
    Epoch 7, Loss: 0.9558132561186813, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8919463627085368
      batch rate adapted learning_rate :              0.0008919463627085368
      fit adapted learning_rate :              2.0062866645698296e-06
    epoch : 8 ; learning_rate : 2.0062866645698296e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5138959509399231
    Epoch 8, Loss: 0.9523724025629535, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.8909447385996951
      batch rate adapted learning_rate :              0.0008909447385996951
      fit adapted learning_rate :              1.1944971536705265e-05
    epoch : 9 ; learning_rate : 1.1944971536705265e-05 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.5995417774328278
    Epoch 9, Loss: 0.9495457458300516, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.8899442392791785
      batch rate adapted learning_rate :              0.0008899442392791785
      fit adapted learning_rate :              9.462025833297993e-06
    epoch : 10 ; learning_rate : 9.462025833297993e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.549688181130364
    Epoch 10, Loss: 0.945263192066032, fit: 0.4166666666666667
    Epoch 10, Loss: 0.945263192066032
      exponential decayed learning_rate :              0.8889448634838898
      batch rate adapted learning_rate :              0.0008889448634838898
      fit adapted learning_rate :              1.1918159041720665e-05
    epoch : 11 ; learning_rate : 1.1918159041720665e-05 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.6057083607191003
    Epoch 11, Loss: 0.9409608360959587, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.8879466099521498
      batch rate adapted learning_rate :              0.0008879466099521498
      fit adapted learning_rate :              8.066718833365369e-07
    epoch : 12 ; learning_rate : 8.066718833365369e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.5888019125834184
    Epoch 12, Loss: 0.9385436263951226, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8869494774236966
      batch rate adapted learning_rate :              0.0008869494774236965
      fit adapted learning_rate :              2.6416353175894802e-06
    epoch : 13 ; learning_rate : 2.6416353175894802e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5877180036719724
    Epoch 13, Loss: 0.9378784750072802, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8859534646396829
      batch rate adapted learning_rate :              0.0008859534646396829
      fit adapted learning_rate :              1.9928066258810045e-06
    epoch : 14 ; learning_rate : 1.9928066258810045e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5323371888132461
    Epoch 14, Loss: 0.9369588923479835, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8849585703426759
      batch rate adapted learning_rate :              0.0008849585703426759
      fit adapted learning_rate :              1.1002711364742578e-06
    epoch : 15 ; learning_rate : 1.1002711364742578e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5121335362250949
    Epoch 15, Loss: 0.9363603508946152, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.883964793276654
      batch rate adapted learning_rate :              0.000883964793276654
      fit adapted learning_rate :              1.9883334366818906e-06
    epoch : 16 ; learning_rate : 1.9883334366818906e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5816430981704357
    Epoch 16, Loss: 0.9357485204202828, fit: 0.55
      exponential decayed learning_rate :              0.8829721321870068
      batch rate adapted learning_rate :              0.0008829721321870068
      fit adapted learning_rate :              1.484728711915202e-06
    epoch : 17 ; learning_rate : 1.484728711915202e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.5528096978896577
    Epoch 17, Loss: 0.9350849520621554, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.8819805858205323
      batch rate adapted learning_rate :              0.0008819805858205323
      fit adapted learning_rate :              8.012519359339081e-07
    epoch : 18 ; learning_rate : 8.012519359339081e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.5910747855334513
    Epoch 18, Loss: 0.9346327351039379, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8809901529254359
      batch rate adapted learning_rate :              0.000880990152925436
      fit adapted learning_rate :              4.473573754381238e-06
    epoch : 19 ; learning_rate : 4.473573754381238e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.522395035640183
    Epoch 19, Loss: 0.9336103433304368, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.8800008322513287
      batch rate adapted learning_rate :              0.0008800008322513288
      fit adapted learning_rate :              9.356305980282576e-06
    epoch : 20 ; learning_rate : 9.356305980282576e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.5818204958787259
    Epoch 20, Loss: 0.9308974613947069, fit: 0.5
    Epoch 20, Loss: 0.9308974613947069
      exponential decayed learning_rate :              0.8790126225492262
      batch rate adapted learning_rate :              0.0008790126225492262
      fit adapted learning_rate :              3.433643056832915e-06
    epoch : 21 ; learning_rate : 3.433643056832915e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.6072161785046312
    Epoch 21, Loss: 0.9284539162411507, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.8780255225715461
      batch rate adapted learning_rate :              0.0008780255225715461
      fit adapted learning_rate :              9.335304179951798e-06
    epoch : 22 ; learning_rate : 9.335304179951798e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.44553441599166266
    Epoch 22, Loss: 0.9259682278300496, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8770395310721073
      batch rate adapted learning_rate :              0.0008770395310721073
      fit adapted learning_rate :              2.612120147961313e-06
    epoch : 23 ; learning_rate : 2.612120147961313e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5414644967347482
    Epoch 23, Loss: 0.9236994499296276, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8760546468061281
      batch rate adapted learning_rate :              0.0008760546468061281
      fit adapted learning_rate :              1.970540863000197e-06
    epoch : 24 ; learning_rate : 1.970540863000197e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5319916921131036
    Epoch 24, Loss: 0.922835701977349, fit: 0.45
      exponential decayed learning_rate :              0.8750708685302246
      batch rate adapted learning_rate :              0.0008750708685302247
      fit adapted learning_rate :              7.327312975540516e-06
    epoch : 25 ; learning_rate : 7.327312975540516e-06 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.5479650609840548
    Epoch 25, Loss: 0.9210192718236376, fit: 0.6333333333333333
      exponential decayed learning_rate :              0.8740881950024092
      batch rate adapted learning_rate :              0.0008740881950024093
      fit adapted learning_rate :              2.8557928269475134e-07
    epoch : 26 ; learning_rate : 2.8557928269475134e-07 ; fit : 0.6333333333333333
    batch_size :          60
    best_batch_loss : 0.5496654771061651
    Epoch 26, Loss: 0.9196301373850619, fit: 0.55
      exponential decayed learning_rate :              0.873106624982089
      batch rate adapted learning_rate :              0.000873106624982089
      fit adapted learning_rate :              1.4681397378459212e-06
    epoch : 27 ; learning_rate : 1.4681397378459212e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.42538383210546005
    Epoch 27, Loss: 0.9193067269365476, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.8721261572300644
      batch rate adapted learning_rate :              0.0008721261572300643
      fit adapted learning_rate :              9.272581208334638e-06
    epoch : 28 ; learning_rate : 9.272581208334638e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.5687996307524151
    Epoch 28, Loss: 0.9172169531558728, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8711467905085268
      batch rate adapted learning_rate :              0.0008711467905085269
      fit adapted learning_rate :              1.0830989171137888e-06
    epoch : 29 ; learning_rate : 1.0830989171137888e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5694191987234081
    Epoch 29, Loss: 0.9153664621532488, fit: 0.6166666666666667
      exponential decayed learning_rate :              0.8701685235810587
      batch rate adapted learning_rate :              0.0008701685235810587
      fit adapted learning_rate :              4.0571031975252524e-07
    epoch : 30 ; learning_rate : 4.0571031975252524e-07 ; fit : 0.6166666666666667
    batch_size :          60
    best_batch_loss : 0.4957391509137416
    Epoch 30, Loss: 0.9150846458369467, fit: 0.45
    Epoch 30, Loss: 0.9150846458369467
      exponential decayed learning_rate :              0.8691913552126297
      batch rate adapted learning_rate :              0.0008691913552126297
      fit adapted learning_rate :              7.278081495244256e-06
    epoch : 31 ; learning_rate : 7.278081495244256e-06 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.48742818918190844
    Epoch 31, Loss: 0.9136603114088105, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.8682152841695976
      batch rate adapted learning_rate :              0.0008682152841695976
      fit adapted learning_rate :              1.1640235816912948e-05
    epoch : 32 ; learning_rate : 1.1640235816912948e-05 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.5067287842355938
    Epoch 32, Loss: 0.9101972871631759, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8672403092197045
      batch rate adapted learning_rate :              0.0008672403092197046
      fit adapted learning_rate :              1.078241979454432e-06
    epoch : 33 ; learning_rate : 1.078241979454432e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5513648036976607
    Epoch 33, Loss: 0.9079258388526464, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8662664291320767
      batch rate adapted learning_rate :              0.0008662664291320767
      fit adapted learning_rate :              1.9485238769902737e-06
    epoch : 34 ; learning_rate : 1.9485238769902737e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5309356895362424
    Epoch 34, Loss: 0.9073717097484685, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8652936426772231
      batch rate adapted learning_rate :              0.0008652936426772231
      fit adapted learning_rate :              1.946335753832374e-06
    epoch : 35 ; learning_rate : 1.946335753832374e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.473328571816881
    Epoch 35, Loss: 0.9066928383028453, fit: 0.45
      exponential decayed learning_rate :              0.8643219486270326
      batch rate adapted learning_rate :              0.0008643219486270326
      fit adapted learning_rate :              7.237308036383997e-06
    epoch : 36 ; learning_rate : 7.237308036383997e-06 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.5138827559223221
    Epoch 36, Loss: 0.9050856563446709, fit: 0.43333333333333335
      exponential decayed learning_rate :              0.8633513457547737
      batch rate adapted learning_rate :              0.0008633513457547737
      fit adapted learning_rate :              9.179286045337944e-06
    epoch : 37 ; learning_rate : 9.179286045337944e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.5427383039427693
    Epoch 37, Loss: 0.9021932713893664, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.8623818328350921
      batch rate adapted learning_rate :              0.0008623818328350921
      fit adapted learning_rate :              5.645331151792804e-06
    epoch : 38 ; learning_rate : 5.645331151792804e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.5486210482034136
    Epoch 38, Loss: 0.899566823689792, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8614134086440098
      batch rate adapted learning_rate :              0.0008614134086440099
      fit adapted learning_rate :              2.565580274007116e-06
    epoch : 39 ; learning_rate : 2.565580274007116e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.46686317234390096
    Epoch 39, Loss: 0.8981590471285265, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8604460719589235
      batch rate adapted learning_rate :              0.0008604460719589236
      fit adapted learning_rate :              4.369253108895599e-06
    epoch : 40 ; learning_rate : 4.369253108895599e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.5483988975238513
    Epoch 40, Loss: 0.8969775055063518, fit: 0.6166666666666667
    Epoch 40, Loss: 0.8969775055063518
      exponential decayed learning_rate :              0.8594798215586023
      batch rate adapted learning_rate :              0.0008594798215586023
      fit adapted learning_rate :              4.007267831182376e-07
    epoch : 41 ; learning_rate : 4.007267831182376e-07 ; fit : 0.6166666666666667
    batch_size :          60
    best_batch_loss : 0.5538894070174422
    Epoch 41, Loss: 0.8961451678199284, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.858514656223187
      batch rate adapted learning_rate :              0.000858514656223187
      fit adapted learning_rate :              4.359445586398896e-06
    epoch : 42 ; learning_rate : 4.359445586398896e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.4622453311596438
    Epoch 42, Loss: 0.8953318648944745, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.8575505747341883
      batch rate adapted learning_rate :              0.0008575505747341883
      fit adapted learning_rate :              5.613704729689593e-06
    epoch : 43 ; learning_rate : 5.613704729689593e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.5689271844284256
    Epoch 43, Loss: 0.8936398255617193, fit: 0.45
      exponential decayed learning_rate :              0.856587575874485
      batch rate adapted learning_rate :              0.0008565875758744849
      fit adapted learning_rate :              7.17254508761552e-06
    epoch : 44 ; learning_rate : 7.17254508761552e-06 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.5269538590010296
    Epoch 44, Loss: 0.89151658256326, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8556256584283229
      batch rate adapted learning_rate :              0.000855625658428323
      fit adapted learning_rate :              1.9245892131402427e-06
    epoch : 45 ; learning_rate : 1.9245892131402427e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.4275945056546219
    Epoch 45, Loss: 0.8899486902414451, fit: 0.55
      exponential decayed learning_rate :              0.8546648211813132
      batch rate adapted learning_rate :              0.0008546648211813131
      fit adapted learning_rate :              1.4371296135119862e-06
    epoch : 46 ; learning_rate : 1.4371296135119862e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.5640183927872122
    Epoch 46, Loss: 0.889399910338571, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.85370506292043
      batch rate adapted learning_rate :              0.00085370506292043
      fit adapted learning_rate :              1.9202691493823535e-06
    epoch : 47 ; learning_rate : 1.9202691493823535e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5045639670481797
    Epoch 47, Loss: 0.8888409632994491, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.8527463824340109
      batch rate adapted learning_rate :              0.0008527463824340109
      fit adapted learning_rate :              4.330154909147106e-06
    epoch : 48 ; learning_rate : 4.330154909147106e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.5450269080537546
    Epoch 48, Loss: 0.8878094989930073, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8517887785117528
      batch rate adapted learning_rate :              0.0008517887785117528
      fit adapted learning_rate :              2.5369148725121436e-06
    epoch : 49 ; learning_rate : 2.5369148725121436e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.4282353649629741
    Epoch 49, Loss: 0.8866753325320057, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8508322499447127
      batch rate adapted learning_rate :              0.0008508322499447128
      fit adapted learning_rate :              1.0578417995693537e-06
    epoch : 50 ; learning_rate : 1.0578417995693537e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5781737263664368
    Epoch 50, Loss: 0.8860863404223256, fit: 0.5
    Epoch 50, Loss: 0.8860863404223256
      exponential decayed learning_rate :              0.849876795525305
      batch rate adapted learning_rate :              0.0008498767955253051
      fit adapted learning_rate :              3.319831232520723e-06
    epoch : 51 ; learning_rate : 3.319831232520723e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.4940816864699025
    Epoch 51, Loss: 0.8853871819441286, fit: 0.4
      exponential decayed learning_rate :              0.8489224140472996
      batch rate adapted learning_rate :              0.0008489224140472996
      fit adapted learning_rate :              1.4258636693924686e-05
    epoch : 52 ; learning_rate : 1.4258636693924686e-05 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.5136314553384788
    Epoch 52, Loss: 0.8824868034953006, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8479691043058217
      batch rate adapted learning_rate :              0.0008479691043058218
      fit adapted learning_rate :              2.5255385917420353e-06
    epoch : 53 ; learning_rate : 2.5255385917420353e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5114431020096271
    Epoch 53, Loss: 0.8798192556677416, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8470168650973491
      batch rate adapted learning_rate :              0.0008470168650973491
      fit adapted learning_rate :              2.522702501538565e-06
    epoch : 54 ; learning_rate : 2.522702501538565e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5044200360857999
    Epoch 54, Loss: 0.8789917095337844, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8460656952197113
      batch rate adapted learning_rate :              0.0008460656952197113
      fit adapted learning_rate :              2.5198695961637357e-06
    epoch : 55 ; learning_rate : 2.5198695961637357e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.504375407260814
    Epoch 55, Loss: 0.878193088869291, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.8451155934720876
      batch rate adapted learning_rate :              0.0008451155934720877
      fit adapted learning_rate :              7.677612367481662e-07
    epoch : 56 ; learning_rate : 7.677612367481662e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.5055801104361595
    Epoch 56, Loss: 0.877684200381184, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.844166558655006
      batch rate adapted learning_rate :              0.000844166558655006
      fit adapted learning_rate :              7.668990681282663e-07
    epoch : 57 ; learning_rate : 7.668990681282663e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.5432718825655015
    Epoch 57, Loss: 0.8774423116053157, fit: 0.6666666666666666
      exponential decayed learning_rate :              0.8432185895703413
      batch rate adapted learning_rate :              0.0008432185895703414
      fit adapted learning_rate :              1.2851982770467034e-07
    epoch : 58 ; learning_rate : 1.2851982770467034e-07 ; fit : 0.6666666666666666
    batch_size :          60
    best_batch_loss : 0.5265541097202596
    Epoch 58, Loss: 0.8772988000396212, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.842271685021314
      batch rate adapted learning_rate :              0.000842271685021314
      fit adapted learning_rate :              2.50856975148206e-06
    epoch : 59 ; learning_rate : 2.50856975148206e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.49499493067555406
    Epoch 59, Loss: 0.8768926055767476, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8413258438124882
      batch rate adapted learning_rate :              0.0008413258438124882
      fit adapted learning_rate :              1.892424131730583e-06
    epoch : 60 ; learning_rate : 1.892424131730583e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5136847890964348
    Epoch 60, Loss: 0.8761852934084622, fit: 0.5666666666666667
    Epoch 60, Loss: 0.8761852934084622
      exponential decayed learning_rate :              0.8403810647497706
      batch rate adapted learning_rate :              0.0008403810647497706
      fit adapted learning_rate :              1.044847815673035e-06
    epoch : 61 ; learning_rate : 1.044847815673035e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5366974164235453
    Epoch 61, Loss: 0.8757223638386967, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8394373466404088
      batch rate adapted learning_rate :              0.0008394373466404088
      fit adapted learning_rate :              1.0436744886592102e-06
    epoch : 62 ; learning_rate : 1.0436744886592102e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.504882976598292
    Epoch 62, Loss: 0.8753982509782798, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.83849468829299
      batch rate adapted learning_rate :              0.00083849468829299
      fit adapted learning_rate :              2.4973205786645263e-06
    epoch : 63 ; learning_rate : 2.4973205786645263e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.47607831045131815
    Epoch 63, Loss: 0.8748377007751122, fit: 0.6
      exponential decayed learning_rate :              0.8375530885174388
      batch rate adapted learning_rate :              0.0008375530885174388
      fit adapted learning_rate :              5.48898792090789e-07
    epoch : 64 ; learning_rate : 5.48898792090789e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.43412472295031834
    Epoch 64, Loss: 0.874360283327813, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.836612546125017
      batch rate adapted learning_rate :              0.000836612546125017
      fit adapted learning_rate :              7.600364826461928e-07
    epoch : 65 ; learning_rate : 7.600364826461928e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.49348856008102887
    Epoch 65, Loss: 0.8741574702994167, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8356730599283205
      batch rate adapted learning_rate :              0.0008356730599283205
      fit adapted learning_rate :              1.8797091239692847e-06
    epoch : 66 ; learning_rate : 1.8797091239692847e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5425576451329992
    Epoch 66, Loss: 0.8737392921571087, fit: 0.5
      exponential decayed learning_rate :              0.8347346287412793
      batch rate adapted learning_rate :              0.0008347346287412794
      fit adapted learning_rate :              3.2606821435206225e-06
    epoch : 67 ; learning_rate : 3.2606821435206225e-06 ; fit : 0.5
    batch_size :          60
    best_batch_loss : 0.49105285303047047
    Epoch 67, Loss: 0.8729504794035977, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.8337972513791548
      batch rate adapted learning_rate :              0.0008337972513791549
      fit adapted learning_rate :              1.1178790337502642e-05
    epoch : 68 ; learning_rate : 1.1178790337502642e-05 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.48809640458414344
    Epoch 68, Loss: 0.8707031860259824, fit: 0.55
      exponential decayed learning_rate :              0.8328609266585392
      batch rate adapted learning_rate :              0.0008328609266585392
      fit adapted learning_rate :              1.4004660914715457e-06
    epoch : 69 ; learning_rate : 1.4004660914715457e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.4684865786204071
    Epoch 69, Loss: 0.8687546367416056, fit: 0.5666666666666667
      exponential decayed learning_rate :              0.8319256533973531
      batch rate adapted learning_rate :              0.0008319256533973531
      fit adapted learning_rate :              1.0343351822347496e-06
    epoch : 70 ; learning_rate : 1.0343351822347496e-06 ; fit : 0.5666666666666667
    batch_size :          60
    best_batch_loss : 0.5218732489396999
    Epoch 70, Loss: 0.8683857922782543, fit: 0.5333333333333333
    Epoch 70, Loss: 0.8683857922782543
      exponential decayed learning_rate :              0.8309914304148452
      batch rate adapted learning_rate :              0.0008309914304148453
      fit adapted learning_rate :              1.8691785682609575e-06
    epoch : 71 ; learning_rate : 1.8691785682609575e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.4994110956920769
    Epoch 71, Loss: 0.867940521373808, fit: 0.6333333333333333
      exponential decayed learning_rate :              0.8300582565315897
      batch rate adapted learning_rate :              0.0008300582565315898
      fit adapted learning_rate :              2.7119396286377477e-07
    epoch : 72 ; learning_rate : 2.7119396286377477e-07 ; fit : 0.6333333333333333
    batch_size :          60
    best_batch_loss : 0.45818876040771583
    Epoch 72, Loss: 0.8676094592470381, fit: 0.6
      exponential decayed learning_rate :              0.8291261305694854
      batch rate adapted learning_rate :              0.0008291261305694854
      fit adapted learning_rate :              5.433761009300182e-07
    epoch : 73 ; learning_rate : 5.433761009300182e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.512528072427114
    Epoch 73, Loss: 0.8674824458316716, fit: 0.45
      exponential decayed learning_rate :              0.8281950513517541
      batch rate adapted learning_rate :              0.0008281950513517541
      fit adapted learning_rate :              6.934803299121081e-06
    epoch : 74 ; learning_rate : 6.934803299121081e-06 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.5144984278311059
    Epoch 74, Loss: 0.866325657372044, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8272650177029388
      batch rate adapted learning_rate :              0.0008272650177029388
      fit adapted learning_rate :              1.8607966156647516e-06
    epoch : 75 ; learning_rate : 1.8607966156647516e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.5069883047469675
    Epoch 75, Loss: 0.8650086155006234, fit: 0.6
      exponential decayed learning_rate :              0.826336028448903
      batch rate adapted learning_rate :              0.000826336028448903
      fit adapted learning_rate :              5.415475796042733e-07
    epoch : 76 ; learning_rate : 5.415475796042733e-07 ; fit : 0.6
    batch_size :          60
    best_batch_loss : 0.48799403021320525
    Epoch 76, Loss: 0.8646344995611501, fit: 0.5833333333333334
      exponential decayed learning_rate :              0.8254080824168282
      batch rate adapted learning_rate :              0.0008254080824168282
      fit adapted learning_rate :              7.498575757840475e-07
    epoch : 77 ; learning_rate : 7.498575757840475e-07 ; fit : 0.5833333333333334
    batch_size :          60
    best_batch_loss : 0.46316336446351714
    Epoch 77, Loss: 0.8644407778934186, fit: 0.55
      exponential decayed learning_rate :              0.8244811784352133
      batch rate adapted learning_rate :              0.0008244811784352133
      fit adapted learning_rate :              1.3863754397598365e-06
    epoch : 78 ; learning_rate : 1.3863754397598365e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.42820933900536823
    Epoch 78, Loss: 0.8641196020322718, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8235553153338726
      batch rate adapted learning_rate :              0.0008235553153338726
      fit adapted learning_rate :              1.8524522502367907e-06
    epoch : 79 ; learning_rate : 1.8524522502367907e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.45527667389058596
    Epoch 79, Loss: 0.8636204101098535, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.8226304919439344
      batch rate adapted learning_rate :              0.0008226304919439345
      fit adapted learning_rate :              5.385110592274942e-06
    epoch : 80 ; learning_rate : 5.385110592274942e-06 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.5221841093766686
    Epoch 80, Loss: 0.8625141666979803, fit: 0.48333333333333334
    Epoch 80, Loss: 0.8625141666979803
      exponential decayed learning_rate :              0.8217067070978399
      batch rate adapted learning_rate :              0.0008217067070978399
      fit adapted learning_rate :              4.17253875819773e-06
    epoch : 81 ; learning_rate : 4.17253875819773e-06 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.5467386309118767
    Epoch 81, Loss: 0.8610823954011974, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8207839596293409
      batch rate adapted learning_rate :              0.0008207839596293409
      fit adapted learning_rate :              2.444572042779443e-06
    epoch : 82 ; learning_rate : 2.444572042779443e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.5288360508891637
    Epoch 82, Loss: 0.8600978817457784, fit: 0.6833333333333333
      exponential decayed learning_rate :              0.8198622483734995
      batch rate adapted learning_rate :              0.0008198622483734996
      fit adapted learning_rate :              8.290098558353412e-08
    epoch : 83 ; learning_rate : 8.290098558353412e-08 ; fit : 0.6833333333333333
    batch_size :          60
    best_batch_loss : 0.4492409231566877
    Epoch 83, Loss: 0.8597158901291442, fit: 0.5333333333333333
      exponential decayed learning_rate :              0.8189415721666855
      batch rate adapted learning_rate :              0.0008189415721666856
      fit adapted learning_rate :              1.8420743937006994e-06
    epoch : 84 ; learning_rate : 1.8420743937006994e-06 ; fit : 0.5333333333333333
    batch_size :          60
    best_batch_loss : 0.47614965363581874
    Epoch 84, Loss: 0.8594349223980725, fit: 0.6166666666666667
      exponential decayed learning_rate :              0.8180219298465756
      batch rate adapted learning_rate :              0.0008180219298465757
      fit adapted learning_rate :              3.8139731526581293e-07
    epoch : 85 ; learning_rate : 3.8139731526581293e-07 ; fit : 0.6166666666666667
    batch_size :          60
    best_batch_loss : 0.43950666392786863
    Epoch 85, Loss: 0.8590972347594712, fit: 0.55
      exponential decayed learning_rate :              0.8171033202521518
      batch rate adapted learning_rate :              0.0008171033202521519
      fit adapted learning_rate :              1.3739694787135938e-06
    epoch : 86 ; learning_rate : 1.3739694787135938e-06 ; fit : 0.55
    batch_size :          60
    best_batch_loss : 0.4511511531410715
    Epoch 86, Loss: 0.8588288917888287, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.8161857422236997
      batch rate adapted learning_rate :              0.0008161857422236997
      fit adapted learning_rate :              2.430876997226252e-06
    epoch : 87 ; learning_rate : 2.430876997226252e-06 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.4846380391578632
    Epoch 87, Loss: 0.8582702440660959, fit: 0.6166666666666667
      exponential decayed learning_rate :              0.8152691946028073
      batch rate adapted learning_rate :              0.0008152691946028074
      fit adapted learning_rate :              3.8011387066206286e-07
    epoch : 88 ; learning_rate : 3.8011387066206286e-07 ; fit : 0.6166666666666667
    batch_size :          60
    best_batch_loss : 0.48285725361764115
    Epoch 88, Loss: 0.8578471457370971, fit: 0.5666666666666667
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_0.8390022258763781_fit_0.56666666666666672024-01-02192255
  self.fit : 0.5666666666666667
  self.loss : 0.8390022258763781
  current_accuracy : 0.5604
  LR: 0.9, Epochs: 1, Hidden Size: 784, Samples: 1, Accuracy mean: 0.4778
  LR: 0.9, Epochs: 10, Hidden Size: 784, Samples: 1, Accuracy mean: 0.4889
  LR: 0.9, Epochs: 100, Hidden Size: 784, Samples: 1, Accuracy mean: 0.5604
  LR: 0.1
  LR: 0.1, Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  LR: 0.1, Hidden Size: 784, Sample: 1/1
  LR: 0.1, Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.1
    batch_rate :          0.001
      exponential decayed learning_rate :              0.1
      batch rate adapted learning_rate :              0.0001
      fit adapted learning_rate :              0.0001
    epoch : 0 ; learning_rate : 0.0001 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.3943510473149023
    Epoch 0, Loss: 1.7210191360170484, fit: 0.23333333333333334
    Epoch 0, Loss: 1.7210191360170484
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.1_hidden_size_784_loss_1.4738799599234045_fit_0.233333333333333342024-01-02192325
  self.fit : 0.23333333333333334
  self.loss : 1.4738799599234045
  current_accuracy : 0.1348
  LR: 0.1, Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          0.1
    batch_rate :          0.001
      exponential decayed learning_rate :              0.1
      batch rate adapted learning_rate :              0.0001
      fit adapted learning_rate :              1.1935830708885835e-05
    epoch : 0 ; learning_rate : 1.1935830708885835e-05 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.351112743405167
    Epoch 0, Loss: 1.6556859559504133, fit: 0.08333333333333333
    Epoch 0, Loss: 1.6556859559504133
      exponential decayed learning_rate :              0.09889503892939223
      batch rate adapted learning_rate :              9.889503892939224e-05
      fit adapted learning_rate :              4.9302168158702156e-05
    epoch : 1 ; learning_rate : 4.9302168158702156e-05 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.128642975247458
    Epoch 1, Loss: 1.6210262077702173, fit: 0.25
      exponential decayed learning_rate :              0.09780228724846006
      batch rate adapted learning_rate :              9.780228724846007e-05
      fit adapted learning_rate :              9.79127207393107e-06
    epoch : 2 ; learning_rate : 9.79127207393107e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.2192933638443042
    Epoch 2, Loss: 1.5843696148654702, fit: 0.1
      exponential decayed learning_rate :              0.0967216100482006
      batch rate adapted learning_rate :              9.672161004820059e-05
      fit adapted learning_rate :              4.163548162415689e-05
    epoch : 3 ; learning_rate : 4.163548162415689e-05 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.276885089473204
    Epoch 3, Loss: 1.5509831051866483, fit: 0.25
      exponential decayed learning_rate :              0.09565287391030293
      batch rate adapted learning_rate :              9.565287391030293e-05
      fit adapted learning_rate :              9.576088039024314e-06
    epoch : 4 ; learning_rate : 9.576088039024314e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.131928271205911
    Epoch 4, Loss: 1.517860243783201, fit: 0.11666666666666667
      exponential decayed learning_rate :              0.09459594689067655
      batch rate adapted learning_rate :              9.459594689067654e-05
      fit adapted learning_rate :              3.5064647917042157e-05
    epoch : 5 ; learning_rate : 3.5064647917042157e-05 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.1410396292159861
    Epoch 5, Loss: 1.4908029703601096, fit: 0.23333333333333334
      exponential decayed learning_rate :              0.09355069850316178
      batch rate adapted learning_rate :              9.355069850316178e-05
      fit adapted learning_rate :              1.1166053000317583e-05
    epoch : 6 ; learning_rate : 1.1166053000317583e-05 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.1464987804402957
    Epoch 6, Loss: 1.4623599190485934, fit: 0.25
      exponential decayed learning_rate :              0.0925169997034202
      batch rate adapted learning_rate :              9.25169997034202e-05
      fit adapted learning_rate :              9.262146530977477e-06
    epoch : 7 ; learning_rate : 9.262146530977477e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.0660560422217396
    Epoch 7, Loss: 1.4502250729110377, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.0914947228730031
      batch rate adapted learning_rate :              9.14947228730031e-05
      fit adapted learning_rate :              3.5699815661467484e-06
    epoch : 8 ; learning_rate : 3.5699815661467484e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 1.1046469875727245
    Epoch 8, Loss: 1.4428007525505377, fit: 0.25
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.1_hidden_size_784_loss_1.452920461149639_fit_0.252024-01-02192436
  self.fit : 0.25
  self.loss : 1.452920461149639
  current_accuracy : 0.2539
  LR: 0.1, Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          0.1
    batch_rate :          0.001
      exponential decayed learning_rate :              0.1
      batch rate adapted learning_rate :              0.0001
      fit adapted learning_rate :              1.001129150390625e-05
    epoch : 0 ; learning_rate : 1.001129150390625e-05 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.059690048968948
    Epoch 0, Loss: 1.434802752982311, fit: 0.3
    Epoch 0, Loss: 1.434802752982311
      exponential decayed learning_rate :              0.09988770354914617
      batch rate adapted learning_rate :              9.988770354914618e-05
      fit adapted learning_rate :              5.758327333078211e-06
    epoch : 1 ; learning_rate : 5.758327333078211e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 1.1256451997110806
    Epoch 1, Loss: 1.4256413034275983, fit: 0.21666666666666667
      exponential decayed learning_rate :              0.09977553320322105
      batch rate adapted learning_rate :              9.977553320322105e-05
      fit adapted learning_rate :              1.4144803472531514e-05
    epoch : 2 ; learning_rate : 1.4144803472531514e-05 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.0830241950063255
    Epoch 2, Loss: 1.4143308422891259, fit: 0.2
      exponential decayed learning_rate :              0.09966348882061334
      batch rate adapted learning_rate :              9.966348882061334e-05
      fit adapted learning_rate :              1.672075879257016e-05
    epoch : 3 ; learning_rate : 1.672075879257016e-05 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.0142533728685132
    Epoch 3, Loss: 1.397431365084045, fit: 0.25
      exponential decayed learning_rate :              0.09955157025987066
      batch rate adapted learning_rate :              9.955157025987067e-05
      fit adapted learning_rate :              9.966397895431693e-06
    epoch : 4 ; learning_rate : 9.966397895431693e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.0411934652261756
    Epoch 4, Loss: 1.3829066161670072, fit: 0.25
      exponential decayed learning_rate :              0.09943977737969956
      batch rate adapted learning_rate :              9.943977737969956e-05
      fit adapted learning_rate :              9.955205984317152e-06
    epoch : 5 ; learning_rate : 9.955205984317152e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.0076679279749972
    Epoch 5, Loss: 1.3722213325347066, fit: 0.26666666666666666
      exponential decayed learning_rate :              0.09932811003896519
      batch rate adapted learning_rate :              9.932811003896519e-05
      fit adapted learning_rate :              8.307753094144412e-06
    epoch : 6 ; learning_rate : 8.307753094144412e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.0060949207550902
    Epoch 6, Loss: 1.3625267001761812, fit: 0.25
      exponential decayed learning_rate :              0.09921656809669122
      batch rate adapted learning_rate :              9.921656809669122e-05
      fit adapted learning_rate :              9.932859852331408e-06
    epoch : 7 ; learning_rate : 9.932859852331408e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.0196024544914644
    Epoch 7, Loss: 1.3526987751823152, fit: 0.3
      exponential decayed learning_rate :              0.09910515141205965
      batch rate adapted learning_rate :              9.910515141205966e-05
      fit adapted learning_rate :              5.713214759653926e-06
    epoch : 8 ; learning_rate : 5.713214759653926e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 0.9762689553395582
    Epoch 8, Loss: 1.3445999002846079, fit: 0.4
      exponential decayed learning_rate :              0.09899385984441057
      batch rate adapted learning_rate :              9.899385984441058e-05
      fit adapted learning_rate :              1.6627167089642945e-06
    epoch : 9 ; learning_rate : 1.6627167089642945e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.9432161693821043
    Epoch 9, Loss: 1.340760283873229, fit: 0.23333333333333334
      exponential decayed learning_rate :              0.09888269325324206
      batch rate adapted learning_rate :              9.888269325324206e-05
      fit adapted learning_rate :              1.1802470867093846e-05
    epoch : 10 ; learning_rate : 1.1802470867093846e-05 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 0.8308579055482805
    Epoch 10, Loss: 1.3338106658324957, fit: 0.18333333333333332
    Epoch 10, Loss: 1.3338106658324957
      exponential decayed learning_rate :              0.09877165149820999
      batch rate adapted learning_rate :              9.877165149820999e-05
      fit adapted learning_rate :              1.954298742382091e-05
    epoch : 11 ; learning_rate : 1.954298742382091e-05 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 0.9319258364605908
    Epoch 11, Loss: 1.3182932538613803, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.09866073443912776
      batch rate adapted learning_rate :              9.866073443912777e-05
      fit adapted learning_rate :              2.5538954473682145e-06
    epoch : 12 ; learning_rate : 2.5538954473682145e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.9681883695772674
    Epoch 12, Loss: 1.3077827736198342, fit: 0.3
      exponential decayed learning_rate :              0.09854994193596628
      batch rate adapted learning_rate :              9.854994193596629e-05
      fit adapted learning_rate :              5.681208038224001e-06
    epoch : 13 ; learning_rate : 5.681208038224001e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 0.8758087729749012
    Epoch 13, Loss: 1.3039664545891818, fit: 0.31666666666666665
      exponential decayed learning_rate :              0.09843927384885366
      batch rate adapted learning_rate :              9.843927384885367e-05
      fit adapted learning_rate :              4.679821109658772e-06
    epoch : 14 ; learning_rate : 4.679821109658772e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 0.8995167762336209
    Epoch 14, Loss: 1.2992180020481348, fit: 0.2833333333333333
      exponential decayed learning_rate :              0.0983287300380751
      batch rate adapted learning_rate :              9.83287300380751e-05
      fit adapted learning_rate :              6.842551450612421e-06
    epoch : 15 ; learning_rate : 6.842551450612421e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 0.9383586186328249
    Epoch 15, Loss: 1.2940158711227547, fit: 0.31666666666666665
      exponential decayed learning_rate :              0.09821831036407268
      batch rate adapted learning_rate :              9.821831036407269e-05
      fit adapted learning_rate :              4.669316465118936e-06
    epoch : 16 ; learning_rate : 4.669316465118936e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 0.9457662006854759
    Epoch 16, Loss: 1.2887008877684303, fit: 0.35
      exponential decayed learning_rate :              0.0981080146874452
      batch rate adapted learning_rate :              9.81080146874452e-05
      fit adapted learning_rate :              3.126160998315168e-06
    epoch : 17 ; learning_rate : 3.126160998315168e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.8663787244505775
    Epoch 17, Loss: 1.2851743495620707, fit: 0.31666666666666665
      exponential decayed learning_rate :              0.09799784286894803
      batch rate adapted learning_rate :              9.799784286894803e-05
      fit adapted learning_rate :              4.658835400018211e-06
    epoch : 18 ; learning_rate : 4.658835400018211e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 0.8160551097639369
    Epoch 18, Loss: 1.2816791377460266, fit: 0.26666666666666666
      exponential decayed learning_rate :              0.09788779476949289
      batch rate adapted learning_rate :              9.788779476949289e-05
      fit adapted learning_rate :              8.187285850462761e-06
    epoch : 19 ; learning_rate : 8.187285850462761e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 0.8656833060640853
    Epoch 19, Loss: 1.2759546791688101, fit: 0.21666666666666667
      exponential decayed learning_rate :              0.09777787025014764
      batch rate adapted learning_rate :              9.777787025014764e-05
      fit adapted learning_rate :              1.3861602281132939e-05
    epoch : 20 ; learning_rate : 1.3861602281132939e-05 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 0.8757757048351474
    Epoch 20, Loss: 1.2662338210757975, fit: 0.3
    Epoch 20, Loss: 1.2662338210757975
      exponential decayed learning_rate :              0.09766806917213625
      batch rate adapted learning_rate :              9.766806917213625e-05
      fit adapted learning_rate :              5.630369828316e-06
    epoch : 21 ; learning_rate : 5.630369828316e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 0.9237960496563686
    Epoch 21, Loss: 1.2578802624885241, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.09755839139683846
      batch rate adapted learning_rate :              9.755839139683846e-05
      fit adapted learning_rate :              2.5253606012296257e-06
    epoch : 22 ; learning_rate : 2.5253606012296257e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.7922518027259013
    Epoch 22, Loss: 1.254452514305651, fit: 0.4
      exponential decayed learning_rate :              0.0974488367857897
      batch rate adapted learning_rate :              9.74488367857897e-05
      fit adapted learning_rate :              1.636766254468009e-06
    epoch : 23 ; learning_rate : 1.636766254468009e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.864622303742247
    Epoch 23, Loss: 1.2526617644059206, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.0973394052006809
      batch rate adapted learning_rate :              9.733940520068091e-05
      fit adapted learning_rate :              2.519692005180928e-06
    epoch : 24 ; learning_rate : 2.519692005180928e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.8754136311342239
    Epoch 24, Loss: 1.2508989682095883, fit: 0.25
      exponential decayed learning_rate :              0.09723009650335829
      batch rate adapted learning_rate :              9.723009650335829e-05
      fit adapted learning_rate :              9.733988390480556e-06
    epoch : 25 ; learning_rate : 9.733988390480556e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 0.8204990805832821
    Epoch 25, Loss: 1.2457860005398438, fit: 0.45
      exponential decayed learning_rate :              0.09712091055582324
      batch rate adapted learning_rate :              9.712091055582324e-05
      fit adapted learning_rate :              8.132316292362255e-07
    epoch : 26 ; learning_rate : 8.132316292362255e-07 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.829454303501291
    Epoch 26, Loss: 1.2414792417666891, fit: 0.31666666666666665
      exponential decayed learning_rate :              0.09701184722023211
      batch rate adapted learning_rate :              9.701184722023212e-05
      fit adapted learning_rate :              4.611960986275812e-06
    epoch : 27 ; learning_rate : 4.611960986275812e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 0.7987636045301727
    Epoch 27, Loss: 1.239305736968721, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09690290635889603
      batch rate adapted learning_rate :              9.690290635889603e-05
      fit adapted learning_rate :              2.0264719293627416e-06
    epoch : 28 ; learning_rate : 2.0264719293627416e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.8662689970079015
    Epoch 28, Loss: 1.2365570237307721, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.09679408783428077
      batch rate adapted learning_rate :              9.679408783428078e-05
      fit adapted learning_rate :              4.915100236669271e-07
    epoch : 29 ; learning_rate : 4.915100236669271e-07 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.8625591915376941
    Epoch 29, Loss: 1.2355521141598471, fit: 0.31666666666666665
      exponential decayed learning_rate :              0.09668539150900651
      batch rate adapted learning_rate :              9.668539150900652e-05
      fit adapted learning_rate :              4.596441221968043e-06
    epoch : 30 ; learning_rate : 4.596441221968043e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 0.805515476901889
    Epoch 30, Loss: 1.233525226543388, fit: 0.38333333333333336
    Epoch 30, Loss: 1.233525226543388
      exponential decayed learning_rate :              0.09657681724584775
      batch rate adapted learning_rate :              9.657681724584776e-05
      fit adapted learning_rate :              2.0196526247733034e-06
    epoch : 31 ; learning_rate : 2.0196526247733034e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.7789105245531787
    Epoch 31, Loss: 1.230896467306338, fit: 0.35
      exponential decayed learning_rate :              0.09646836490773307
      batch rate adapted learning_rate :              9.646836490773307e-05
      fit adapted learning_rate :              3.073914408588915e-06
    epoch : 32 ; learning_rate : 3.073914408588915e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.7959086911160647
    Epoch 32, Loss: 1.2288943135744146, fit: 0.31666666666666665
      exponential decayed learning_rate :              0.09636003435774494
      batch rate adapted learning_rate :              9.636003435774494e-05
      fit adapted learning_rate :              4.580973683402183e-06
    epoch : 33 ; learning_rate : 4.580973683402183e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 0.817565844815133
    Epoch 33, Loss: 1.2259063557697434, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09625182545911964
      batch rate adapted learning_rate :              9.625182545911965e-05
      fit adapted learning_rate :              2.012856267906165e-06
    epoch : 34 ; learning_rate : 2.012856267906165e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.8102775844069037
    Epoch 34, Loss: 1.223368645095848, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.09614373807524701
      batch rate adapted learning_rate :              9.614373807524702e-05
      fit adapted learning_rate :              2.863485469345624e-07
    epoch : 35 ; learning_rate : 2.863485469345624e-07 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.8843266082688149
    Epoch 35, Loss: 1.2224837917074551, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.09603577206967029
      batch rate adapted learning_rate :              9.603577206967029e-05
      fit adapted learning_rate :              2.4859466379154883e-06
    epoch : 36 ; learning_rate : 2.4859466379154883e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.8281511988070211
    Epoch 36, Loss: 1.2214316577179825, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.09592792730608596
      batch rate adapted learning_rate :              9.592792730608595e-05
      fit adapted learning_rate :              6.279641983732731e-07
    epoch : 37 ; learning_rate : 6.279641983732731e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.8564422997960441
    Epoch 37, Loss: 1.220237165144818, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.09582020364834357
      batch rate adapted learning_rate :              9.582020364834356e-05
      fit adapted learning_rate :              2.4803665131277253e-06
    epoch : 38 ; learning_rate : 2.4803665131277253e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.7799606156290897
    Epoch 38, Loss: 1.219090425176514, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09571260096044554
      batch rate adapted learning_rate :              9.571260096044555e-05
      fit adapted learning_rate :              3.734556598974864e-06
    epoch : 39 ; learning_rate : 3.734556598974864e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.842107545127861
    Epoch 39, Loss: 1.2166942692489726, fit: 0.25
      exponential decayed learning_rate :              0.09560511910654707
      batch rate adapted learning_rate :              9.560511910654707e-05
      fit adapted learning_rate :              9.571307166413197e-06
    epoch : 40 ; learning_rate : 9.571307166413197e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 0.8661645092816674
    Epoch 40, Loss: 1.2117752129954897, fit: 0.43333333333333335
    Epoch 40, Loss: 1.2117752129954897
      exponential decayed learning_rate :              0.09549775795095582
      batch rate adapted learning_rate :              9.549775795095582e-05
      fit adapted learning_rate :              1.0153470440865674e-06
    epoch : 41 ; learning_rate : 1.0153470440865674e-06 ; fit : 0.43333333333333335
    batch_size :          60
    best_batch_loss : 0.8163069128399653
    Epoch 41, Loss: 1.2078285066173404, fit: 0.3
      exponential decayed learning_rate :              0.0953905173581319
      batch rate adapted learning_rate :              9.53905173581319e-05
      fit adapted learning_rate :              5.499073498566759e-06
    epoch : 42 ; learning_rate : 5.499073498566759e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 0.753942618287553
    Epoch 42, Loss: 1.205433145003385, fit: 0.5166666666666667
      exponential decayed learning_rate :              0.09528339719268758
      batch rate adapted learning_rate :              9.528339719268758e-05
      fit adapted learning_rate :              2.8378616100573073e-07
    epoch : 43 ; learning_rate : 2.8378616100573073e-07 ; fit : 0.5166666666666667
    batch_size :          60
    best_batch_loss : 0.8441690514987994
    Epoch 43, Loss: 1.2032915329583813, fit: 0.4166666666666667
      exponential decayed learning_rate :              0.09517639731938722
      batch rate adapted learning_rate :              9.517639731938723e-05
      fit adapted learning_rate :              1.2760380163791908e-06
    epoch : 44 ; learning_rate : 1.2760380163791908e-06 ; fit : 0.4166666666666667
    batch_size :          60
    best_batch_loss : 0.892987492892856
    Epoch 44, Loss: 1.2027211369650253, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.095069517603147
      batch rate adapted learning_rate :              9.5069517603147e-05
      fit adapted learning_rate :              3.7094644880971883e-06
    epoch : 45 ; learning_rate : 3.7094644880971883e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.7952728996874752
    Epoch 45, Loss: 1.2009335781166801, fit: 0.35
      exponential decayed learning_rate :              0.0949627579090348
      batch rate adapted learning_rate :              9.49627579090348e-05
      fit adapted learning_rate :              3.0259390225502123e-06
    epoch : 46 ; learning_rate : 3.0259390225502123e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.8299301100456103
    Epoch 46, Loss: 1.1984008269465387, fit: 0.36666666666666664
      exponential decayed learning_rate :              0.09485611810227002
      batch rate adapted learning_rate :              9.485611810227002e-05
      fit adapted learning_rate :              2.455410549633354e-06
    epoch : 47 ; learning_rate : 2.455410549633354e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 0.8259411154409716
    Epoch 47, Loss: 1.196426226281249, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.09474959804822343
      batch rate adapted learning_rate :              9.474959804822344e-05
      fit adapted learning_rate :              6.202506095507773e-07
    epoch : 48 ; learning_rate : 6.202506095507773e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.8444938857055031
    Epoch 48, Loss: 1.195292229472996, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09464319761241699
      batch rate adapted learning_rate :              9.4643197612417e-05
      fit adapted learning_rate :              1.9792160057239264e-06
    epoch : 49 ; learning_rate : 1.9792160057239264e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.8087936170748568
    Epoch 49, Loss: 1.1943308623688966, fit: 0.4
      exponential decayed learning_rate :              0.09453691666052365
      batch rate adapted learning_rate :              9.453691666052365e-05
      fit adapted learning_rate :              1.5878571781368203e-06
    epoch : 50 ; learning_rate : 1.5878571781368203e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.834422878912463
    Epoch 50, Loss: 1.1930411810594796, fit: 0.2833333333333333
    Epoch 50, Loss: 1.1930411810594796
      exponential decayed learning_rate :              0.09443075505836723
      batch rate adapted learning_rate :              9.443075505836723e-05
      fit adapted learning_rate :              6.571297114860063e-06
    epoch : 51 ; learning_rate : 6.571297114860063e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 0.8073774310780591
    Epoch 51, Loss: 1.1900751785991945, fit: 0.31666666666666665
      exponential decayed learning_rate :              0.09432471267192219
      batch rate adapted learning_rate :              9.43247126719222e-05
      fit adapted learning_rate :              4.484214117653208e-06
    epoch : 52 ; learning_rate : 4.484214117653208e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 0.7759340090658582
    Epoch 52, Loss: 1.1860760238515682, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.09421878936731354
      batch rate adapted learning_rate :              9.421878936731354e-05
      fit adapted learning_rate :              6.167758253335224e-07
    epoch : 53 ; learning_rate : 6.167758253335224e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.7678527297610297
    Epoch 53, Loss: 1.1842279261648458, fit: 0.35
      exponential decayed learning_rate :              0.09411298501081657
      batch rate adapted learning_rate :              9.411298501081657e-05
      fit adapted learning_rate :              2.998861449934985e-06
    epoch : 54 ; learning_rate : 2.998861449934985e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.8233473165559013
    Epoch 54, Loss: 1.182956111804716, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09400729946885682
      batch rate adapted learning_rate :              9.400729946885681e-05
      fit adapted learning_rate :              1.965917852074273e-06
    epoch : 55 ; learning_rate : 1.965917852074273e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.7134602954484875
    Epoch 55, Loss: 1.1811570244851655, fit: 0.48333333333333334
      exponential decayed learning_rate :              0.09390173260800974
      batch rate adapted learning_rate :              9.390173260800975e-05
      fit adapted learning_rate :              4.7682295323188593e-07
    epoch : 56 ; learning_rate : 4.7682295323188593e-07 ; fit : 0.48333333333333334
    batch_size :          60
    best_batch_loss : 0.7095905881382107
    Epoch 56, Loss: 1.180275247680625, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09379628429500067
      batch rate adapted learning_rate :              9.379628429500068e-05
      fit adapted learning_rate :              3.659784907715317e-06
    epoch : 57 ; learning_rate : 3.659784907715317e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.772612972419827
    Epoch 57, Loss: 1.1788311165179335, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.0936909543967046
      batch rate adapted learning_rate :              9.36909543967046e-05
      fit adapted learning_rate :              3.655675099155068e-06
    epoch : 58 ; learning_rate : 3.655675099155068e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.8173593133211677
    Epoch 58, Loss: 1.1762488369301127, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.093585742780146
      batch rate adapted learning_rate :              9.3585742780146e-05
      fit adapted learning_rate :              6.126317704810168e-07
    epoch : 59 ; learning_rate : 6.126317704810168e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.8075303486671708
    Epoch 59, Loss: 1.1747029685644979, fit: 0.45
      exponential decayed learning_rate :              0.09348064931249869
      batch rate adapted learning_rate :              9.34806493124987e-05
      fit adapted learning_rate :              7.827502883508069e-07
    epoch : 60 ; learning_rate : 7.827502883508069e-07 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.7660171512504826
    Epoch 60, Loss: 1.1742159502800409, fit: 0.45
    Epoch 60, Loss: 1.1742159502800409
      exponential decayed learning_rate :              0.09337567386108563
      batch rate adapted learning_rate :              9.337567386108563e-05
      fit adapted learning_rate :              7.818712875579406e-07
    epoch : 61 ; learning_rate : 7.818712875579406e-07 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.7465873672710395
    Epoch 61, Loss: 1.1736740878159233, fit: 0.3333333333333333
      exponential decayed learning_rate :              0.09327081629337876
      batch rate adapted learning_rate :              9.327081629337876e-05
      fit adapted learning_rate :              3.639281964807954e-06
    epoch : 62 ; learning_rate : 3.639281964807954e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 0.7576448411045618
    Epoch 62, Loss: 1.1720843662563392, fit: 0.45
      exponential decayed learning_rate :              0.09316607647699889
      batch rate adapted learning_rate :              9.316607647699888e-05
      fit adapted learning_rate :              7.801162461238249e-07
    epoch : 63 ; learning_rate : 7.801162461238249e-07 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.8302446235191628
    Epoch 63, Loss: 1.170580701722229, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.09306145427971543
      batch rate adapted learning_rate :              9.306145427971543e-05
      fit adapted learning_rate :              6.091996687236351e-07
    epoch : 64 ; learning_rate : 6.091996687236351e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.7920166288299965
    Epoch 64, Loss: 1.1700962731972775, fit: 0.31666666666666665
      exponential decayed learning_rate :              0.09295694956944633
      batch rate adapted learning_rate :              9.295694956944633e-05
      fit adapted learning_rate :              4.4191904092316375e-06
    epoch : 65 ; learning_rate : 4.4191904092316375e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 0.7991451574828051
    Epoch 65, Loss: 1.1684016631012597, fit: 0.45
      exponential decayed learning_rate :              0.09285256221425785
      batch rate adapted learning_rate :              9.285256221425785e-05
      fit adapted learning_rate :              7.774910677434067e-07
    epoch : 66 ; learning_rate : 7.774910677434067e-07 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.7698316514642687
    Epoch 66, Loss: 1.1665667681149237, fit: 0.38333333333333336
      exponential decayed learning_rate :              0.09274829208236438
      batch rate adapted learning_rate :              9.274829208236437e-05
      fit adapted learning_rate :              1.939588991326403e-06
    epoch : 67 ; learning_rate : 1.939588991326403e-06 ; fit : 0.38333333333333336
    batch_size :          60
    best_batch_loss : 0.8003057387571731
    Epoch 67, Loss: 1.1656504287384792, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.09264413904212832
      batch rate adapted learning_rate :              9.264413904212832e-05
      fit adapted learning_rate :              6.064678362323088e-07
    epoch : 68 ; learning_rate : 6.064678362323088e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.6596161232320339
    Epoch 68, Loss: 1.1647686651424052, fit: 0.35
      exponential decayed learning_rate :              0.0925401029620599
      batch rate adapted learning_rate :              9.25401029620599e-05
      fit adapted learning_rate :              2.948742379322476e-06
    epoch : 69 ; learning_rate : 2.948742379322476e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 0.7697843946157872
    Epoch 69, Loss: 1.163527191074241, fit: 0.4666666666666667
      exponential decayed learning_rate :              0.09243618371081702
      batch rate adapted learning_rate :              9.243618371081702e-05
      fit adapted learning_rate :              6.051065173068236e-07
    epoch : 70 ; learning_rate : 6.051065173068236e-07 ; fit : 0.4666666666666667
    batch_size :          60
    best_batch_loss : 0.7649237354707453
    Epoch 70, Loss: 1.1623520507701546, fit: 0.45
    Epoch 70, Loss: 1.1623520507701546
      exponential decayed learning_rate :              0.09233238115720503
      batch rate adapted learning_rate :              9.233238115720504e-05
      fit adapted learning_rate :              7.731353869110927e-07
    epoch : 71 ; learning_rate : 7.731353869110927e-07 ; fit : 0.45
    batch_size :          60
    best_batch_loss : 0.764495985562031
    Epoch 71, Loss: 1.1618909162762021, fit: 0.4
      exponential decayed learning_rate :              0.09222869517017664
      batch rate adapted learning_rate :              9.222869517017664e-05
      fit adapted learning_rate :              1.5490879206695136e-06
    epoch : 72 ; learning_rate : 1.5490879206695136e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 0.8123806332678559
    Epoch 72, Loss: 1.16111416069929, fit: 0.45
      exponential decayed learning_rate :              0.09212512561883171
      batch rate adapted learning_rate :              9.212512561883172e-05
      fit adapted learning_rate :              7.713999546733287e-07
    epoch : 73 ; learning_rate : 7.713999546733287e-07 ; fit : 0.45
    batch_size :          60
file_path :  src/mnist_train.csv
save_file :  src/mnist_train.npz
file_path :  src/mnist_test.csv
save_file :  src/mnist_test.npz
batch_rate :  0.001
  LR: 0.9
  Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  Sample: 1/1
  Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.9
    batch_rate :          0.001
file_path :  src/mnist_train.csv
save_file :  src/mnist_train.npz
file_path :  src/mnist_test.csv
save_file :  src/mnist_test.npz
batch_rate :  0.001
  LR: 0.9
  Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  Sample: 1/1
  Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.9
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0009000000000000001
    epoch : 0 ; learning_rate : 0.0 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.453225606335326
    Epoch 0, Loss: 1.717762301202198, fit: 0.08333333333333333
    Epoch 0, Loss: 1.717762301202198
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_1.772917766832314_fit_0.08333333333333333_2024-01-02_194138
file_path :  src/mnist_train.csv
save_file :  src/mnist_train.npz
file_path :  src/mnist_test.csv
save_file :  src/mnist_test.npz
batch_rate :  0.001
  LR: 0.9
  Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  Sample: 1/1
  Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.9
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              0.0
    epoch : 0 ; learning_rate : 0.0 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.5201602747781309
    Epoch 0, Loss: 1.8167572133189085, fit: 0.1
    Epoch 0, Loss: 1.8167572133189085
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_1.781453381862332_fit_0.1_2024-01-02_194250
file_path :  src/mnist_train.csv
save_file :  src/mnist_train.npz
file_path :  src/mnist_test.csv
save_file :  src/mnist_test.npz
batch_rate :  0.001
  LR: 0.9
  Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  Sample: 1/1
  Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.9
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              0.0
    epoch : 0 ; learning_rate : 0.0 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.4690549794672914
    Epoch 0, Loss: 1.7397120183973007, fit: 0.08333333333333333
    Epoch 0, Loss: 1.7397120183973007
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_1.775541822798391_fit_0.08333333333333333_2024-01-02_194444
  self.fit : 0.08333333333333333
  self.loss : 1.775541822798391
  current_accuracy : 0.1032
  Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          0.9
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              5.0377339618129914e-06
    epoch : 0 ; learning_rate : 5.0377339618129914e-06 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4549073336844007
    Epoch 0, Loss: 1.7375837954206574, fit: 0.11666666666666667
    Epoch 0, Loss: 1.7375837954206574
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.4187396519520105e-06
    epoch : 1 ; learning_rate : 4.4187396519520105e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4361087120336564
    Epoch 1, Loss: 1.7337426615215867, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              5.173659659592089e-06
    epoch : 2 ; learning_rate : 5.173659659592089e-06 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4610099319925631
    Epoch 2, Loss: 1.729491302100637, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.97695938322368e-06
    epoch : 3 ; learning_rate : 3.97695938322368e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4254079526659411
    Epoch 3, Loss: 1.7241321121028832, fit: 0.05
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              5.1498867535928275e-06
    epoch : 4 ; learning_rate : 5.1498867535928275e-06 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4425523856698619
    Epoch 4, Loss: 1.7190536696259673, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.589078420424242e-06
    epoch : 5 ; learning_rate : 3.589078420424242e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.42772785184779
    Epoch 5, Loss: 1.7140785771455807, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.729429588750871e-06
    epoch : 6 ; learning_rate : 4.729429588750871e-06 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4249276113886153
    Epoch 6, Loss: 1.7093433300827956, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.05018395277246e-06
    epoch : 7 ; learning_rate : 4.05018395277246e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.439707865022403
    Epoch 7, Loss: 1.7047318750245262, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.2444614421320375e-06
    epoch : 8 ; learning_rate : 4.2444614421320375e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4152092234222229
    Epoch 8, Loss: 1.7002270951626437, fit: 0.08333333333333333
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_1.729691703767017_fit_0.08333333333333333_2024-01-02_194550
  self.fit : 0.08333333333333333
  self.loss : 1.729691703767017
  current_accuracy : 0.1257
  Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          0.9
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.657454454487768e-06
    epoch : 0 ; learning_rate : 4.657454454487768e-06 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4387752905800515
    Epoch 0, Loss: 1.6954533740087008, fit: 0.11666666666666667
    Epoch 0, Loss: 1.6954533740087008
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.845701101259953e-06
    epoch : 1 ; learning_rate : 3.845701101259953e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4028796246989372
    Epoch 1, Loss: 1.6904285757617117, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.7669820689590067e-06
    epoch : 2 ; learning_rate : 3.7669820689590067e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.3328103806239417
    Epoch 2, Loss: 1.6859507318744913, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              5.120603365680919e-06
    epoch : 3 ; learning_rate : 5.120603365680919e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.364067856714602
    Epoch 3, Loss: 1.6806373567747162, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.962526511058894e-06
    epoch : 4 ; learning_rate : 4.962526511058894e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.3096137306681106
    Epoch 4, Loss: 1.6750249054510813, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.8424544798232054e-06
    epoch : 5 ; learning_rate : 4.8424544798232054e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.3281304732037316
    Epoch 5, Loss: 1.66927652409198, fit: 0.25
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.8583265224412365e-06
    epoch : 6 ; learning_rate : 2.8583265224412365e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.2846762488504122
    Epoch 6, Loss: 1.664838665334039, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.776300358198462e-06
    epoch : 7 ; learning_rate : 4.776300358198462e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.3348440053642459
    Epoch 7, Loss: 1.6604902549775618, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.4533866176412085e-06
    epoch : 8 ; learning_rate : 3.4533866176412085e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.3525826529621532
    Epoch 8, Loss: 1.655917953598668, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.363669948972068e-06
    epoch : 9 ; learning_rate : 3.363669948972068e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.2433861197216662
    Epoch 9, Loss: 1.6520845826482409, fit: 0.26666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.5374394848581135e-06
    epoch : 10 ; learning_rate : 2.5374394848581135e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.3167090957649588
    Epoch 10, Loss: 1.6489154887152342, fit: 0.11666666666666667
    Epoch 10, Loss: 1.6489154887152342
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.255365028342026e-06
    epoch : 11 ; learning_rate : 4.255365028342026e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.3227049182358412
    Epoch 11, Loss: 1.6451018161416067, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.63523501373532e-06
    epoch : 12 ; learning_rate : 3.63523501373532e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.3548192453647399
    Epoch 12, Loss: 1.640821414858363, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.0799533816370595e-06
    epoch : 13 ; learning_rate : 4.0799533816370595e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.3315522294779243
    Epoch 13, Loss: 1.636357429806146, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.86370953824228e-06
    epoch : 14 ; learning_rate : 4.86370953824228e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.3654233090085925
    Epoch 14, Loss: 1.6311484143088624, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.9750297901860632e-06
    epoch : 15 ; learning_rate : 2.9750297901860632e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.2713323745767535
    Epoch 15, Loss: 1.6266263203705629, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.316569156768185e-06
    epoch : 16 ; learning_rate : 4.316569156768185e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.2527536157848607
    Epoch 16, Loss: 1.6223443467540737, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.3778434980500572e-06
    epoch : 17 ; learning_rate : 3.3778434980500572e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.319665877959373
    Epoch 17, Loss: 1.6179140221942636, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.081187190049067e-06
    epoch : 18 ; learning_rate : 4.081187190049067e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.330854233341941
    Epoch 18, Loss: 1.6137188099107356, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.459911509953758e-06
    epoch : 19 ; learning_rate : 3.459911509953758e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.3367843320625103
    Epoch 19, Loss: 1.6094812001295373, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.00026087901575e-06
    epoch : 20 ; learning_rate : 4.00026087901575e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.2932918460683254
    Epoch 20, Loss: 1.60524092252151, fit: 0.1
    Epoch 20, Loss: 1.60524092252151
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.191409807235003e-06
    epoch : 21 ; learning_rate : 4.191409807235003e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.2531099545113669
    Epoch 21, Loss: 1.6008018233868073, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.573795781468967e-06
    epoch : 22 ; learning_rate : 4.573795781468967e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.2949851951289915
    Epoch 22, Loss: 1.5959700789857247, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.1678978673978084e-06
    epoch : 23 ; learning_rate : 3.1678978673978084e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.2433233039525198
    Epoch 23, Loss: 1.591750867305837, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.298732460278284e-06
    epoch : 24 ; learning_rate : 4.298732460278284e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.2497104976054638
    Epoch 24, Loss: 1.5876082290520839, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.1027398086474766e-06
    epoch : 25 ; learning_rate : 3.1027398086474766e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.2525063744718694
    Epoch 25, Loss: 1.5836143626212023, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.390715157981141e-06
    epoch : 26 ; learning_rate : 4.390715157981141e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.1637988983788068
    Epoch 26, Loss: 1.579602976178521, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.339976557360924e-06
    epoch : 27 ; learning_rate : 4.339976557360924e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.216820945519729
    Epoch 27, Loss: 1.5749054139003118, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.5032361347929793e-06
    epoch : 28 ; learning_rate : 3.5032361347929793e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.2797996700243919
    Epoch 28, Loss: 1.5709000456713835, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.7243909744086103e-06
    epoch : 29 ; learning_rate : 3.7243909744086103e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.2713679437626817
    Epoch 29, Loss: 1.567243107636096, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.240426403323076e-06
    epoch : 30 ; learning_rate : 4.240426403323076e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.236894770322528
    Epoch 30, Loss: 1.5632998172520605, fit: 0.2
    Epoch 30, Loss: 1.5632998172520605
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.3517307811102797e-06
    epoch : 31 ; learning_rate : 3.3517307811102797e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.180339365699964
    Epoch 31, Loss: 1.5595936363148795, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.711586447642729e-06
    epoch : 32 ; learning_rate : 3.711586447642729e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.2746015924261844
    Epoch 32, Loss: 1.5561618680529166, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.4926471034601563e-06
    epoch : 33 ; learning_rate : 3.4926471034601563e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.236883243290378
    Epoch 33, Loss: 1.552656970156981, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.1193667277134942e-06
    epoch : 34 ; learning_rate : 3.1193667277134942e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.2397548368483222
    Epoch 34, Loss: 1.5492973974233017, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.7086253587180203e-06
    epoch : 35 ; learning_rate : 3.7086253587180203e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.1843251674800077
    Epoch 35, Loss: 1.5459753054833942, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.877821904411709e-06
    epoch : 36 ; learning_rate : 4.877821904411709e-06 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.1673876560881027
    Epoch 36, Loss: 1.5416443744107398, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.385561297857273e-06
    epoch : 37 ; learning_rate : 3.385561297857273e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.1957979818118905
    Epoch 37, Loss: 1.5374090635005313, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.8591952332585988e-06
    epoch : 38 ; learning_rate : 2.8591952332585988e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.2524558708497044
    Epoch 38, Loss: 1.534292895784233, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.2548885158132625e-06
    epoch : 39 ; learning_rate : 3.2548885158132625e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.154137732969072
    Epoch 39, Loss: 1.531139900291207, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.821309877276798e-06
    epoch : 40 ; learning_rate : 3.821309877276798e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.163331177509986
    Epoch 40, Loss: 1.5276350118308595, fit: 0.16666666666666666
    Epoch 40, Loss: 1.5276350118308595
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.556381335730166e-06
    epoch : 41 ; learning_rate : 3.556381335730166e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.203108533577716
    Epoch 41, Loss: 1.5238889242407152, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.939969645630402e-06
    epoch : 42 ; learning_rate : 2.939969645630402e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.2156782717798085
    Epoch 42, Loss: 1.5206092140333916, fit: 0.25
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.977551617806872e-06
    epoch : 43 ; learning_rate : 2.977551617806872e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.1599996447109717
    Epoch 43, Loss: 1.5176408794660698, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.2637020089206904e-06
    epoch : 44 ; learning_rate : 3.2637020089206904e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.1865264623045162
    Epoch 44, Loss: 1.5144321124470708, fit: 0.2833333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.1568640591700857e-06
    epoch : 45 ; learning_rate : 2.1568640591700857e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.1749372386924477
    Epoch 45, Loss: 1.511732303580244, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.896272371466177e-06
    epoch : 46 ; learning_rate : 2.896272371466177e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.07109095840115
    Epoch 46, Loss: 1.5091226175429393, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.838659471708006e-06
    epoch : 47 ; learning_rate : 3.838659471708006e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.1384958170953448
    Epoch 47, Loss: 1.50585957540373, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.5041771282309036e-06
    epoch : 48 ; learning_rate : 3.5041771282309036e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.18137471241713
    Epoch 48, Loss: 1.5021708228800752, fit: 0.2833333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.253094995388767e-06
    epoch : 49 ; learning_rate : 2.253094995388767e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.106227363695937
    Epoch 49, Loss: 1.4993993308541174, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.1960661001435107e-06
    epoch : 50 ; learning_rate : 3.1960661001435107e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.0689119748715286
    Epoch 50, Loss: 1.4968032391483816, fit: 0.2
    Epoch 50, Loss: 1.4968032391483816
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.378097956523416e-06
    epoch : 51 ; learning_rate : 3.378097956523416e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.1427528294723603
    Epoch 51, Loss: 1.4936267480181784, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.7991584354374852e-06
    epoch : 52 ; learning_rate : 2.7991584354374852e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.1684617047821155
    Epoch 52, Loss: 1.490686889143549, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.5551636075485602e-06
    epoch : 53 ; learning_rate : 3.5551636075485602e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.1480952995677436
    Epoch 53, Loss: 1.4876063156243644, fit: 0.25
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.6895146784874153e-06
    epoch : 54 ; learning_rate : 2.6895146784874153e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.1447457547339568
    Epoch 54, Loss: 1.484615941942808, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.058868905337588e-06
    epoch : 55 ; learning_rate : 3.058868905337588e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.1284572731086058
    Epoch 55, Loss: 1.4818560930943836, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.994103596586872e-06
    epoch : 56 ; learning_rate : 3.994103596586872e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.0920350633048868
    Epoch 56, Loss: 1.4784790907257797, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.9298773391575902e-06
    epoch : 57 ; learning_rate : 2.9298773391575902e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.1403402980341473
    Epoch 57, Loss: 1.4750969707699082, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.345560583265559e-06
    epoch : 58 ; learning_rate : 3.345560583265559e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.152149373612984
    Epoch 58, Loss: 1.4719740087814601, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.811910179350099e-06
    epoch : 59 ; learning_rate : 2.811910179350099e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.1470062995886485
    Epoch 59, Loss: 1.4690075509688945, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.459144580932909e-06
    epoch : 60 ; learning_rate : 3.459144580932909e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.144580208858837
    Epoch 60, Loss: 1.465963693087602, fit: 0.13333333333333333
    Epoch 60, Loss: 1.465963693087602
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.634662267138576e-06
    epoch : 61 ; learning_rate : 3.634662267138576e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.125446943891402
    Epoch 61, Loss: 1.462480123565483, fit: 0.26666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.349179105151695e-06
    epoch : 62 ; learning_rate : 2.349179105151695e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.1232297957134383
    Epoch 62, Loss: 1.459527627841648, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.742941515657928e-06
    epoch : 63 ; learning_rate : 2.742941515657928e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.131520916970228
    Epoch 63, Loss: 1.4570348479665027, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.853898009047385e-06
    epoch : 64 ; learning_rate : 2.853898009047385e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.0639837417822569
    Epoch 64, Loss: 1.4543087202762024, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.277163345515585e-06
    epoch : 65 ; learning_rate : 3.277163345515585e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.1310769518186206
    Epoch 65, Loss: 1.4513406049949535, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.091669701885744e-06
    epoch : 66 ; learning_rate : 4.091669701885744e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.09990360347228
    Epoch 66, Loss: 1.4477659330852046, fit: 0.25
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.6030252729895836e-06
    epoch : 67 ; learning_rate : 2.6030252729895836e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.1096468193074174
    Epoch 67, Loss: 1.4445235602819766, fit: 0.2833333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.3650988786213986e-06
    epoch : 68 ; learning_rate : 2.3650988786213986e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.1124063182467456
    Epoch 68, Loss: 1.4421255262428918, fit: 0.26666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.3974369648904798e-06
    epoch : 69 ; learning_rate : 2.3974369648904798e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.1147914276600963
    Epoch 69, Loss: 1.4398372581175234, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.393018763634363e-06
    epoch : 70 ; learning_rate : 3.393018763634363e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.1033235237989063
    Epoch 70, Loss: 1.4370608009218606, fit: 0.16666666666666666
    Epoch 70, Loss: 1.4370608009218606
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.3430369738549275e-06
    epoch : 71 ; learning_rate : 3.3430369738549275e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.0691164986091897
    Epoch 71, Loss: 1.4339032347179943, fit: 0.31666666666666665
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              1.9318086263022e-06
    epoch : 72 ; learning_rate : 1.9318086263022e-06 ; fit : 0.31666666666666665
    batch_size :          60
    best_batch_loss : 1.096034404439531
    Epoch 72, Loss: 1.431298353455544, fit: 0.35
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              1.7773975893687236e-06
    epoch : 73 ; learning_rate : 1.7773975893687236e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 1.0755012717906658
    Epoch 73, Loss: 1.4295924217014497, fit: 0.3
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.2877139908304005e-06
    epoch : 74 ; learning_rate : 2.2877139908304005e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 1.0786205397860376
    Epoch 74, Loss: 1.4276547639539803, fit: 0.3
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.23365420502654e-06
    epoch : 75 ; learning_rate : 2.23365420502654e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 1.0926855120666012
    Epoch 75, Loss: 1.4255616877263144, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.5131308604144543e-06
    epoch : 76 ; learning_rate : 2.5131308604144543e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.1132446576216093
    Epoch 76, Loss: 1.4233297624988548, fit: 0.25
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.4599624354349056e-06
    epoch : 77 ; learning_rate : 2.4599624354349056e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.0671602067910753
    Epoch 77, Loss: 1.4210556360024906, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.3008670368764427e-06
    epoch : 78 ; learning_rate : 3.3008670368764427e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.1125639373670775
    Epoch 78, Loss: 1.418406614834919, fit: 0.36666666666666664
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              1.4344030807570301e-06
    epoch : 79 ; learning_rate : 1.4344030807570301e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 1.0224038191555485
    Epoch 79, Loss: 1.4162068849876088, fit: 0.2833333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.3222777788256465e-06
    epoch : 80 ; learning_rate : 2.3222777788256465e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.043305969486725
    Epoch 80, Loss: 1.414484236885987, fit: 0.23333333333333334
    Epoch 80, Loss: 1.414484236885987
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.754615735949267e-06
    epoch : 81 ; learning_rate : 2.754615735949267e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.0674515902326152
    Epoch 81, Loss: 1.4121522481724595, fit: 0.2833333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.2744357767234114e-06
    epoch : 82 ; learning_rate : 2.2744357767234114e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.032067517966202
    Epoch 82, Loss: 1.4098541398292677, fit: 0.2833333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.1006213387466015e-06
    epoch : 83 ; learning_rate : 2.1006213387466015e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.0755324013696048
    Epoch 83, Loss: 1.407821731511738, fit: 0.25
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.736463798108166e-06
    epoch : 84 ; learning_rate : 2.736463798108166e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 0.995024422515252
    Epoch 84, Loss: 1.4056096020002014, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.752049903415519e-06
    epoch : 85 ; learning_rate : 2.752049903415519e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 0.9862139987107933
    Epoch 85, Loss: 1.4030889502737625, fit: 0.25
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.8151345788004663e-06
    epoch : 86 ; learning_rate : 2.8151345788004663e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.097094180213697
    Epoch 86, Loss: 1.4005103811254358, fit: 0.25
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.7207049000489204e-06
    epoch : 87 ; learning_rate : 2.7207049000489204e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.01712472135207
    Epoch 87, Loss: 1.3979329026962874, fit: 0.4
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              1.430712873544999e-06
    epoch : 88 ; learning_rate : 1.430712873544999e-06 ; fit : 0.4
    batch_size :          60
    best_batch_loss : 1.0535437864128716
    Epoch 88, Loss: 1.3960037002369525, fit: 0.26666666666666666
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_1.4197921845899077_fit_0.26666666666666666_2024-01-02_195617
  self.fit : 0.26666666666666666
  self.loss : 1.4197921845899077
  current_accuracy : 0.2753
   Accuracy mean: 0.1032
   Accuracy mean: 0.1257
   Accuracy mean: 0.2753
  LR: 0.1
  Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  Sample: 1/1
  Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.1
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              0.0
    epoch : 0 ; learning_rate : 0.0 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.4927902608011299
    Epoch 0, Loss: 1.759182364745043, fit: 0.05
    Epoch 0, Loss: 1.759182364745043
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.1_hidden_size_784_loss_1.864382308394407_fit_0.05_2024-01-02_195624
  self.fit : 0.05
  self.loss : 1.864382308394407
  current_accuracy : 0.1018
  Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          0.1
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.48044634834237e-07
    epoch : 0 ; learning_rate : 6.48044634834237e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4824413536915289
    Epoch 0, Loss: 1.7587877780869035, fit: 0.06666666666666667
    Epoch 0, Loss: 1.7587877780869035
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.079475537879607e-07
    epoch : 1 ; learning_rate : 6.079475537879607e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.3707999074022765
    Epoch 1, Loss: 1.7581873729268693, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              3.8400319026416695e-07
    epoch : 2 ; learning_rate : 3.8400319026416695e-07 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.4529020334009992
    Epoch 2, Loss: 1.7577991411036786, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.651121275732065e-07
    epoch : 3 ; learning_rate : 4.651121275732065e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4987230538672696
    Epoch 3, Loss: 1.7574958225793678, fit: 0.2
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              3.7407286339920067e-07
    epoch : 4 ; learning_rate : 3.7407286339920067e-07 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.482524947869303
    Epoch 4, Loss: 1.757314492733975, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.7679333543326407e-07
    epoch : 5 ; learning_rate : 4.7679333543326407e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.5039691359223062
    Epoch 5, Loss: 1.7570400256549, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.880845232408449e-07
    epoch : 6 ; learning_rate : 5.880845232408449e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4948704376902309
    Epoch 6, Loss: 1.7568057093567087, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.838095784216914e-07
    epoch : 7 ; learning_rate : 5.838095784216914e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.433314407669991
    Epoch 7, Loss: 1.7562904140861149, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              3.92868376252656e-07
    epoch : 8 ; learning_rate : 3.92868376252656e-07 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.5239325010049691
    Epoch 8, Loss: 1.7558838866092, fit: 0.11666666666666667
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.1_hidden_size_784_loss_1.7351628883479624_fit_0.11666666666666667_2024-01-02_195727
  self.fit : 0.11666666666666667
  self.loss : 1.7351628883479624
  current_accuracy : 0.102
  Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          0.1
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.224211504838314e-07
    epoch : 0 ; learning_rate : 5.224211504838314e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4807688389356684
    Epoch 0, Loss: 1.7554682017958578, fit: 0.13333333333333333
    Epoch 0, Loss: 1.7554682017958578
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.003957815969575e-07
    epoch : 1 ; learning_rate : 5.003957815969575e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4929641821296902
    Epoch 1, Loss: 1.754909634025032, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.599720588425714e-07
    epoch : 2 ; learning_rate : 5.599720588425714e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5063373581031205
    Epoch 2, Loss: 1.7543147514382735, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.210453152146258e-07
    epoch : 3 ; learning_rate : 4.210453152146258e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4186795246253565
    Epoch 3, Loss: 1.7538762373245536, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.593284435445305e-07
    epoch : 4 ; learning_rate : 4.593284435445305e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4734473642227457
    Epoch 4, Loss: 1.7533083541755032, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.403020211531371e-07
    epoch : 5 ; learning_rate : 5.403020211531371e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4803642126563825
    Epoch 5, Loss: 1.7526302168284242, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.167403271456672e-07
    epoch : 6 ; learning_rate : 6.167403271456672e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4737198246523067
    Epoch 6, Loss: 1.7517397870938392, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.057111082771405e-07
    epoch : 7 ; learning_rate : 5.057111082771405e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4736966809093053
    Epoch 7, Loss: 1.7507791494125997, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.175173021688555e-07
    epoch : 8 ; learning_rate : 5.175173021688555e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4784357682576992
    Epoch 8, Loss: 1.7499457417862507, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.434752970350822e-07
    epoch : 9 ; learning_rate : 4.434752970350822e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.519208501484321
    Epoch 9, Loss: 1.7491992169116017, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.358837931508789e-07
    epoch : 10 ; learning_rate : 5.358837931508789e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4473829611839268
    Epoch 10, Loss: 1.7484274197997687, fit: 0.18333333333333332
    Epoch 10, Loss: 1.7484274197997687
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.137588558320589e-07
    epoch : 11 ; learning_rate : 4.137588558320589e-07 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.4645002008203936
    Epoch 11, Loss: 1.7476209225511108, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.5164893028247954e-07
    epoch : 12 ; learning_rate : 4.5164893028247954e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4992115183841201
    Epoch 12, Loss: 1.746952860542928, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.084403638438687e-07
    epoch : 13 ; learning_rate : 5.084403638438687e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.5208265608023102
    Epoch 13, Loss: 1.7462773392110784, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.339633257177487e-07
    epoch : 14 ; learning_rate : 5.339633257177487e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4329261568337337
    Epoch 14, Loss: 1.74566209953986, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.287398929322082e-07
    epoch : 15 ; learning_rate : 6.287398929322082e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.485237637817249
    Epoch 15, Loss: 1.745036013774799, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.887341669461535e-07
    epoch : 16 ; learning_rate : 6.887341669461535e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4397730095547479
    Epoch 16, Loss: 1.7443889248929552, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.404886548752738e-07
    epoch : 17 ; learning_rate : 4.404886548752738e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4430252813927134
    Epoch 17, Loss: 1.7437184335422609, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.273617226544177e-07
    epoch : 18 ; learning_rate : 5.273617226544177e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4966470506866643
    Epoch 18, Loss: 1.7431546807166953, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.621756361518664e-07
    epoch : 19 ; learning_rate : 5.621756361518664e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.454618569743576
    Epoch 19, Loss: 1.7425519536401628, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.149761256523394e-07
    epoch : 20 ; learning_rate : 5.149761256523394e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4676186025381868
    Epoch 20, Loss: 1.7419456653994643, fit: 0.05
    Epoch 20, Loss: 1.7419456653994643
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.964206687050711e-07
    epoch : 21 ; learning_rate : 5.964206687050711e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4873526367550454
    Epoch 21, Loss: 1.7413221733035997, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.617471652663393e-07
    epoch : 22 ; learning_rate : 4.617471652663393e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4347355517218878
    Epoch 22, Loss: 1.7407963238246034, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.174748122098138e-07
    epoch : 23 ; learning_rate : 5.174748122098138e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.459503566814005
    Epoch 23, Loss: 1.7401464391906045, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.317471686819854e-07
    epoch : 24 ; learning_rate : 4.317471686819854e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4966302584180855
    Epoch 24, Loss: 1.7395937765105567, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.916851618615137e-07
    epoch : 25 ; learning_rate : 5.916851618615137e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4229745149656992
    Epoch 25, Loss: 1.7390062515638551, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.985230930312649e-07
    epoch : 26 ; learning_rate : 5.985230930312649e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4908698690950573
    Epoch 26, Loss: 1.7383182773344352, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.317222775197684e-07
    epoch : 27 ; learning_rate : 6.317222775197684e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.3855019036850769
    Epoch 27, Loss: 1.7375884748749961, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.6380524143119003e-07
    epoch : 28 ; learning_rate : 4.6380524143119003e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4718523196452424
    Epoch 28, Loss: 1.7369010012776198, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.125303163411941e-07
    epoch : 29 ; learning_rate : 5.125303163411941e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.479760755354553
    Epoch 29, Loss: 1.7362455889164232, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.689132365317487e-07
    epoch : 30 ; learning_rate : 5.689132365317487e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.3994874726871798
    Epoch 30, Loss: 1.7354499330651645, fit: 0.25
    Epoch 30, Loss: 1.7354499330651645
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              3.1696319173766944e-07
    epoch : 31 ; learning_rate : 3.1696319173766944e-07 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.443226603831231
    Epoch 31, Loss: 1.734676565253756, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.277963550025015e-07
    epoch : 32 ; learning_rate : 5.277963550025015e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4934516162380964
    Epoch 32, Loss: 1.7339588324233486, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.778731080604134e-07
    epoch : 33 ; learning_rate : 4.778731080604134e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.462843971661281
    Epoch 33, Loss: 1.733168891990374, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.026733255383374e-07
    epoch : 34 ; learning_rate : 5.026733255383374e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4762568062422772
    Epoch 34, Loss: 1.732344838717002, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.269617240120999e-07
    epoch : 35 ; learning_rate : 4.269617240120999e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.483006959565684
    Epoch 35, Loss: 1.731546571534546, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.485749360517425e-07
    epoch : 36 ; learning_rate : 5.485749360517425e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4682672308628544
    Epoch 36, Loss: 1.7307343815287517, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.829257092764135e-07
    epoch : 37 ; learning_rate : 5.829257092764135e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4259610810236993
    Epoch 37, Loss: 1.729836623087557, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.527347374428639e-07
    epoch : 38 ; learning_rate : 6.527347374428639e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4192710907005817
    Epoch 38, Loss: 1.7289364414572246, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.6859120593104376e-07
    epoch : 39 ; learning_rate : 4.6859120593104376e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4583950687730047
    Epoch 39, Loss: 1.7280439608360392, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.497593391034294e-07
    epoch : 40 ; learning_rate : 5.497593391034294e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5153241633497316
    Epoch 40, Loss: 1.7273439868925111, fit: 0.13333333333333333
    Epoch 40, Loss: 1.7273439868925111
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.6364691630530787e-07
    epoch : 41 ; learning_rate : 4.6364691630530787e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4661248395866424
    Epoch 41, Loss: 1.7266037862706307, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.1338282088579876e-07
    epoch : 42 ; learning_rate : 4.1338282088579876e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4548137953512323
    Epoch 42, Loss: 1.7259537399408271, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.3680456783603654e-07
    epoch : 43 ; learning_rate : 4.3680456783603654e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.470817451769044
    Epoch 43, Loss: 1.725306526154511, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.673755957158816e-07
    epoch : 44 ; learning_rate : 6.673755957158816e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4295456385427783
    Epoch 44, Loss: 1.7243936614038438, fit: 0.016666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              7.157760608405135e-07
    epoch : 45 ; learning_rate : 7.157760608405135e-07 ; fit : 0.016666666666666666
    batch_size :          60
    best_batch_loss : 1.4714774691193113
    Epoch 45, Loss: 1.7234482245785485, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.352202302119925e-07
    epoch : 46 ; learning_rate : 5.352202302119925e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.421045034201606
    Epoch 46, Loss: 1.7225723399060642, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.765335227379746e-07
    epoch : 47 ; learning_rate : 4.765335227379746e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.432642123161178
    Epoch 47, Loss: 1.721867942948118, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.280503533802451e-07
    epoch : 48 ; learning_rate : 6.280503533802451e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4328768021893112
    Epoch 48, Loss: 1.7210080860278507, fit: 0.2
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              3.8219944785810523e-07
    epoch : 49 ; learning_rate : 3.8219944785810523e-07 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.4116794140090865
    Epoch 49, Loss: 1.720280863904483, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              3.9247410528421866e-07
    epoch : 50 ; learning_rate : 3.9247410528421866e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4463202895002263
    Epoch 50, Loss: 1.719769106965194, fit: 0.13333333333333333
    Epoch 50, Loss: 1.719769106965194
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.395536557726517e-07
    epoch : 51 ; learning_rate : 4.395536557726517e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.424357542086652
    Epoch 51, Loss: 1.7191010852254849, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.572226159116566e-07
    epoch : 52 ; learning_rate : 5.572226159116566e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4639844836009919
    Epoch 52, Loss: 1.718392412502293, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.38996820873803e-07
    epoch : 53 ; learning_rate : 6.38996820873803e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4164377159228105
    Epoch 53, Loss: 1.7175829752180427, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              3.3197223009150356e-07
    epoch : 54 ; learning_rate : 3.3197223009150356e-07 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.423306805269612
    Epoch 54, Loss: 1.716927068070175, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.733495263931043e-07
    epoch : 55 ; learning_rate : 5.733495263931043e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4169439600136813
    Epoch 55, Loss: 1.7163082306436788, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.422574778038386e-07
    epoch : 56 ; learning_rate : 5.422574778038386e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4128420094738203
    Epoch 56, Loss: 1.7156038657957051, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.220054613838932e-07
    epoch : 57 ; learning_rate : 5.220054613838932e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4341383284598304
    Epoch 57, Loss: 1.7149447392108252, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.463697850754401e-07
    epoch : 58 ; learning_rate : 5.463697850754401e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4323342826168508
    Epoch 58, Loss: 1.7142675844818467, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.888938490142994e-07
    epoch : 59 ; learning_rate : 4.888938490142994e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.373414856833172
    Epoch 59, Loss: 1.7136950078366062, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.659828277021375e-07
    epoch : 60 ; learning_rate : 5.659828277021375e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.3974481381056962
    Epoch 60, Loss: 1.7130785339312458, fit: 0.11666666666666667
    Epoch 60, Loss: 1.7130785339312458
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.000540306106418e-07
    epoch : 61 ; learning_rate : 5.000540306106418e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4464342163728725
    Epoch 61, Loss: 1.7124771867246587, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.293932396388343e-07
    epoch : 62 ; learning_rate : 5.293932396388343e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.3968084519675041
    Epoch 62, Loss: 1.7118497026983965, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.121853159860914e-07
    epoch : 63 ; learning_rate : 5.121853159860914e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4660920002607554
    Epoch 63, Loss: 1.7112685551970412, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.167687100737243e-07
    epoch : 64 ; learning_rate : 6.167687100737243e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4392154088207758
    Epoch 64, Loss: 1.7105782477918987, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.3119063792601397e-07
    epoch : 65 ; learning_rate : 4.3119063792601397e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4496508353126634
    Epoch 65, Loss: 1.7098878137999851, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.082558348358369e-07
    epoch : 66 ; learning_rate : 4.082558348358369e-07 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.4288112512761628
    Epoch 66, Loss: 1.7093472801347225, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.047646374123284e-07
    epoch : 67 ; learning_rate : 4.047646374123284e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.353521147395214
    Epoch 67, Loss: 1.7088498858979997, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.945776134025161e-07
    epoch : 68 ; learning_rate : 5.945776134025161e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4253273641675213
    Epoch 68, Loss: 1.7081345287606557, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.53865517439172e-07
    epoch : 69 ; learning_rate : 6.53865517439172e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.419241489729374
    Epoch 69, Loss: 1.707423259954209, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              3.8276998671319346e-07
    epoch : 70 ; learning_rate : 3.8276998671319346e-07 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.463060781662177
    Epoch 70, Loss: 1.7067535997134538, fit: 0.18333333333333332
    Epoch 70, Loss: 1.7067535997134538
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              3.3735420358431105e-07
    epoch : 71 ; learning_rate : 3.3735420358431105e-07 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.4324658443858749
    Epoch 71, Loss: 1.7062867626089437, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.733047109912882e-07
    epoch : 72 ; learning_rate : 4.733047109912882e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4380352780966434
    Epoch 72, Loss: 1.7057884020346492, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.903336191045194e-07
    epoch : 73 ; learning_rate : 4.903336191045194e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.416188526114348
    Epoch 73, Loss: 1.7051955849660305, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.701543561909617e-07
    epoch : 74 ; learning_rate : 4.701543561909617e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.452145059327642
    Epoch 74, Loss: 1.7046287906758069, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.3486919494714246e-07
    epoch : 75 ; learning_rate : 4.3486919494714246e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4084467496394202
    Epoch 75, Loss: 1.7040862983739382, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.170946034291483e-07
    epoch : 76 ; learning_rate : 6.170946034291483e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4254664483521002
    Epoch 76, Loss: 1.7035049404164422, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.269489814467095e-07
    epoch : 77 ; learning_rate : 4.269489814467095e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.442881555580398
    Epoch 77, Loss: 1.7028757324451107, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.669460422496154e-07
    epoch : 78 ; learning_rate : 5.669460422496154e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4587768178773275
    Epoch 78, Loss: 1.7023604639288288, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.22896771959623e-07
    epoch : 79 ; learning_rate : 4.22896771959623e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4072976953422984
    Epoch 79, Loss: 1.7018095149917456, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.450144777786492e-07
    epoch : 80 ; learning_rate : 4.450144777786492e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4143514185205581
    Epoch 80, Loss: 1.7013380568681047, fit: 0.11666666666666667
    Epoch 80, Loss: 1.7013380568681047
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.034175855334915e-07
    epoch : 81 ; learning_rate : 5.034175855334915e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4399521936289144
    Epoch 81, Loss: 1.7008132611203253, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.5112498570227646e-07
    epoch : 82 ; learning_rate : 4.5112498570227646e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4392229802437793
    Epoch 82, Loss: 1.7002986824884818, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.459612379537711e-07
    epoch : 83 ; learning_rate : 5.459612379537711e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4317492372904532
    Epoch 83, Loss: 1.6997820489532882, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.3425587103772555e-07
    epoch : 84 ; learning_rate : 4.3425587103772555e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4485269233814781
    Epoch 84, Loss: 1.699283923958184, fit: 0.2
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              3.9410819530650543e-07
    epoch : 85 ; learning_rate : 3.9410819530650543e-07 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.4514496515837214
    Epoch 85, Loss: 1.6988587609306762, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.5531608044674476e-07
    epoch : 86 ; learning_rate : 4.5531608044674476e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4416070489140034
    Epoch 86, Loss: 1.6984253651543884, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.211283617584861e-07
    epoch : 87 ; learning_rate : 4.211283617584861e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4055186120480614
    Epoch 87, Loss: 1.697992338062906, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.26148898344243e-07
    epoch : 88 ; learning_rate : 4.26148898344243e-07 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.3726895357374762
    Epoch 88, Loss: 1.697579294352005, fit: 0.18333333333333332
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.1_hidden_size_784_loss_1.5439370283472793_fit_0.18333333333333332_2024-01-02_200742
  self.fit : 0.18333333333333332
  self.loss : 1.5439370283472793
  current_accuracy : 0.1121
   Accuracy mean: 0.1018
   Accuracy mean: 0.102
   Accuracy mean: 0.1121
  LR: 0.0001
  Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  Sample: 1/1
  Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.0001
    batch_rate :          0.001
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              0.0
    epoch : 0 ; learning_rate : 0.0 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.4615234654232552
    Epoch 0, Loss: 1.7064794159461312, fit: 0.15
    Epoch 0, Loss: 1.7064794159461312
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.0001_hidden_size_784_loss_1.6562723878389651_fit_0.15_2024-01-02_200749
  self.fit : 0.15
  self.loss : 1.6562723878389651
  current_accuracy : 0.1118
  Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          0.0001
    batch_rate :          0.001
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.543549721551909e-10
    epoch : 0 ; learning_rate : 4.543549721551909e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.441675718322224
    Epoch 0, Loss: 1.7064790435888897, fit: 0.21666666666666667
    Epoch 0, Loss: 1.7064790435888897
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.431153097403999e-10
    epoch : 1 ; learning_rate : 3.431153097403999e-10 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.4046949350808082
    Epoch 1, Loss: 1.7064785029412757, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.938516625367669e-10
    epoch : 2 ; learning_rate : 4.938516625367669e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4154902748178206
    Epoch 2, Loss: 1.706477874249659, fit: 0.15
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.333050726072495e-10
    epoch : 3 ; learning_rate : 4.333050726072495e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.3824571279114508
    Epoch 3, Loss: 1.7064771516140878, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.991905267979424e-10
    epoch : 4 ; learning_rate : 5.991905267979424e-10 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.453750024546956
    Epoch 4, Loss: 1.7064764414798679, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.135883727058112e-10
    epoch : 5 ; learning_rate : 5.135883727058112e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4375391772714206
    Epoch 5, Loss: 1.706475567874087, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.9579005081301e-10
    epoch : 6 ; learning_rate : 4.9579005081301e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4244126287728904
    Epoch 6, Loss: 1.7064748422703238, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.80578423207331e-10
    epoch : 7 ; learning_rate : 4.80578423207331e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4184527659086057
    Epoch 7, Loss: 1.7064741299239188, fit: 0.16666666666666666
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.3565140848218894e-10
    epoch : 8 ; learning_rate : 4.3565140848218894e-10 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4625602954446184
    Epoch 8, Loss: 1.7064734467894043, fit: 0.1
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.0001_hidden_size_784_loss_1.7020281840688198_fit_0.1_2024-01-02_200852
  self.fit : 0.1
  self.loss : 1.7020281840688198
  current_accuracy : 0.1118
  Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          0.0001
    batch_rate :          0.001
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.930605343225812e-10
    epoch : 0 ; learning_rate : 4.930605343225812e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.3952422886944413
    Epoch 0, Loss: 1.7064727526277204, fit: 0.1
    Epoch 0, Loss: 1.7064727526277204
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.262949704286636e-10
    epoch : 1 ; learning_rate : 5.262949704286636e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4331571773095844
    Epoch 1, Loss: 1.7064719872819383, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.508081373791189e-10
    epoch : 2 ; learning_rate : 5.508081373791189e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.3839547933830838
    Epoch 2, Loss: 1.7064712204289454, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.725862115352835e-10
    epoch : 3 ; learning_rate : 4.725862115352835e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4211994475190843
    Epoch 3, Loss: 1.7064704510835889, fit: 0.18333333333333332
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.7417716128847743e-10
    epoch : 4 ; learning_rate : 3.7417716128847743e-10 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.3752231700226114
    Epoch 4, Loss: 1.7064698315650788, fit: 0.05
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              6.034596444746407e-10
    epoch : 5 ; learning_rate : 6.034596444746407e-10 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.2865173952553326
    Epoch 5, Loss: 1.7064690727490546, fit: 0.16666666666666666
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.1620552296781516e-10
    epoch : 6 ; learning_rate : 4.1620552296781516e-10 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4224115720068375
    Epoch 6, Loss: 1.7064683509968634, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.815059109022475e-10
    epoch : 7 ; learning_rate : 4.815059109022475e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4053207735242323
    Epoch 7, Loss: 1.706467669539952, fit: 0.18333333333333332
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.095576506552336e-10
    epoch : 8 ; learning_rate : 4.095576506552336e-10 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.452005360099567
    Epoch 8, Loss: 1.706467002171897, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.852283265041255e-10
    epoch : 9 ; learning_rate : 5.852283265041255e-10 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.434203991864051
    Epoch 9, Loss: 1.7064662475388241, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.268019760650862e-10
    epoch : 10 ; learning_rate : 5.268019760650862e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.2905691220795272
    Epoch 10, Loss: 1.7064654268750048, fit: 0.1
    Epoch 10, Loss: 1.7064654268750048
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.389162785025702e-10
    epoch : 11 ; learning_rate : 5.389162785025702e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4070382270323436
    Epoch 11, Loss: 1.7064646360159634, fit: 0.2
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.5484095244785514e-10
    epoch : 12 ; learning_rate : 3.5484095244785514e-10 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.438127667691605
    Epoch 12, Loss: 1.7064640066161703, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.473207283308015e-10
    epoch : 13 ; learning_rate : 5.473207283308015e-10 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.3725164602363156
    Epoch 13, Loss: 1.7064633156447084, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.997166854433823e-10
    epoch : 14 ; learning_rate : 4.997166854433823e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4279829846362608
    Epoch 14, Loss: 1.706462570255354, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.243368935738271e-10
    epoch : 15 ; learning_rate : 5.243368935738271e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.379420075203145
    Epoch 15, Loss: 1.706461804326312, fit: 0.16666666666666666
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.081063688051704e-10
    epoch : 16 ; learning_rate : 4.081063688051704e-10 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4540672094407785
    Epoch 16, Loss: 1.706461102626901, fit: 0.05
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              6.265120774887296e-10
    epoch : 17 ; learning_rate : 6.265120774887296e-10 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4028300303198726
    Epoch 17, Loss: 1.7064603107311465, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.47742336953699e-10
    epoch : 18 ; learning_rate : 5.47742336953699e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4234442327813497
    Epoch 18, Loss: 1.706459491685981, fit: 0.2
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.6548276634402144e-10
    epoch : 19 ; learning_rate : 3.6548276634402144e-10 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.4621497818319837
    Epoch 19, Loss: 1.7064587986244648, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.602828117037832e-10
    epoch : 20 ; learning_rate : 5.602828117037832e-10 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4078739530988442
    Epoch 20, Loss: 1.7064581489058734, fit: 0.15
    Epoch 20, Loss: 1.7064581489058734
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.5234821282149346e-10
    epoch : 21 ; learning_rate : 4.5234821282149346e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4020508555679634
    Epoch 21, Loss: 1.706457360551519, fit: 0.15
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.5382797932397193e-10
    epoch : 22 ; learning_rate : 4.5382797932397193e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4251635398084592
    Epoch 22, Loss: 1.7064566923339117, fit: 0.18333333333333332
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.761427870803941e-10
    epoch : 23 ; learning_rate : 3.761427870803941e-10 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.4370713444530663
    Epoch 23, Loss: 1.706456078636258, fit: 0.2
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.719604881453923e-10
    epoch : 24 ; learning_rate : 3.719604881453923e-10 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.3865541886471948
    Epoch 24, Loss: 1.706455527147956, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.791122059940189e-10
    epoch : 25 ; learning_rate : 4.791122059940189e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.427601328096602
    Epoch 25, Loss: 1.7064549186403768, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.184197125865773e-10
    epoch : 26 ; learning_rate : 5.184197125865773e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4592648930168424
    Epoch 26, Loss: 1.7064541731703198, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.071090504609815e-10
    epoch : 27 ; learning_rate : 5.071090504609815e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.3835184264725053
    Epoch 27, Loss: 1.706453395517635, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.193683845324557e-10
    epoch : 28 ; learning_rate : 5.193683845324557e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.3062860289731744
    Epoch 28, Loss: 1.7064526322269529, fit: 0.15
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.531063370041373e-10
    epoch : 29 ; learning_rate : 4.531063370041373e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.419268088202924
    Epoch 29, Loss: 1.706451917159886, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.255375691651378e-10
    epoch : 30 ; learning_rate : 5.255375691651378e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4346523258326593
    Epoch 30, Loss: 1.7064512012928479, fit: 0.18333333333333332
    Epoch 30, Loss: 1.7064512012928479
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.957879092862358e-10
    epoch : 31 ; learning_rate : 3.957879092862358e-10 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.479430160230365
    Epoch 31, Loss: 1.7064505066445275, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.426312187987468e-10
    epoch : 32 ; learning_rate : 5.426312187987468e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4405568376740585
    Epoch 32, Loss: 1.7064498203192138, fit: 0.18333333333333332
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.775392107665154e-10
    epoch : 33 ; learning_rate : 3.775392107665154e-10 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.4279584453673204
    Epoch 33, Loss: 1.7064491340146046, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.6172897479734044e-10
    epoch : 34 ; learning_rate : 4.6172897479734044e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4109303679329648
    Epoch 34, Loss: 1.7064485012280963, fit: 0.2
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.559307224269946e-10
    epoch : 35 ; learning_rate : 3.559307224269946e-10 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.3520344326708895
    Epoch 35, Loss: 1.7064479132360302, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.15868598624823e-10
    epoch : 36 ; learning_rate : 5.15868598624823e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4084889183200378
    Epoch 36, Loss: 1.7064472503698112, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.397690007056104e-10
    epoch : 37 ; learning_rate : 5.397690007056104e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4026269207393207
    Epoch 37, Loss: 1.7064464864972209, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.619658867229183e-10
    epoch : 38 ; learning_rate : 5.619658867229183e-10 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4404573966025758
    Epoch 38, Loss: 1.7064457020214905, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.71619906485685e-10
    epoch : 39 ; learning_rate : 5.71619906485685e-10 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4585155420337585
    Epoch 39, Loss: 1.7064448247858377, fit: 0.15
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.5684597056574684e-10
    epoch : 40 ; learning_rate : 4.5684597056574684e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.401342234869089
    Epoch 40, Loss: 1.7064440270796204, fit: 0.11666666666666667
    Epoch 40, Loss: 1.7064440270796204
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.066356134126357e-10
    epoch : 41 ; learning_rate : 5.066356134126357e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4296747063187012
    Epoch 41, Loss: 1.706443345880965, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.676222358164435e-10
    epoch : 42 ; learning_rate : 5.676222358164435e-10 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4507699295792904
    Epoch 42, Loss: 1.706442563840896, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.933547559215425e-10
    epoch : 43 ; learning_rate : 4.933547559215425e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4162539865253136
    Epoch 43, Loss: 1.7064417554825577, fit: 0.18333333333333332
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.8417170328592603e-10
    epoch : 44 ; learning_rate : 3.8417170328592603e-10 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.3729275947492876
    Epoch 44, Loss: 1.7064411272295892, fit: 0.16666666666666666
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.2256804300893966e-10
    epoch : 45 ; learning_rate : 4.2256804300893966e-10 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4388162349626328
    Epoch 45, Loss: 1.706440512837551, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.502984687767006e-10
    epoch : 46 ; learning_rate : 5.502984687767006e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.429996945387326
    Epoch 46, Loss: 1.7064398201439663, fit: 0.03333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              6.185898092340369e-10
    epoch : 47 ; learning_rate : 6.185898092340369e-10 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4089708399447016
    Epoch 47, Loss: 1.706438899777901, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.326407759914771e-10
    epoch : 48 ; learning_rate : 5.326407759914771e-10 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.3576899444901307
    Epoch 48, Loss: 1.706438088119741, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.109253068543584e-10
    epoch : 49 ; learning_rate : 5.109253068543584e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.377842568674858
    Epoch 49, Loss: 1.7064373259572962, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.782855864173155e-10
    epoch : 50 ; learning_rate : 4.782855864173155e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.3532046521180694
    Epoch 50, Loss: 1.7064365823855785, fit: 0.13333333333333333
    Epoch 50, Loss: 1.7064365823855785
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.962486192729003e-10
    epoch : 51 ; learning_rate : 4.962486192729003e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4043066945722893
    Epoch 51, Loss: 1.706435872053515, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.335914861094383e-10
    epoch : 52 ; learning_rate : 5.335914861094383e-10 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4319602386905268
    Epoch 52, Loss: 1.706435107399542, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.936293250838279e-10
    epoch : 53 ; learning_rate : 5.936293250838279e-10 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4018267478082937
    Epoch 53, Loss: 1.7064342643184798, fit: 0.15
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.5705338921850415e-10
    epoch : 54 ; learning_rate : 4.5705338921850415e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.3404785404474466
    Epoch 54, Loss: 1.7064334799950933, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.706626839137806e-10
    epoch : 55 ; learning_rate : 5.706626839137806e-10 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4526099174689264
    Epoch 55, Loss: 1.7064327472329972, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.605685519429501e-10
    epoch : 56 ; learning_rate : 5.605685519429501e-10 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4225380314751321
    Epoch 56, Loss: 1.706431898375996, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.487389841087634e-10
    epoch : 57 ; learning_rate : 4.487389841087634e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.35402541726178
    Epoch 57, Loss: 1.7064311353054338, fit: 0.15
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.928136421014149e-10
    epoch : 58 ; learning_rate : 3.928136421014149e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4302309685420687
    Epoch 58, Loss: 1.7064305464612426, fit: 0.16666666666666666
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.105103204050633e-10
    epoch : 59 ; learning_rate : 4.105103204050633e-10 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4479665295646744
    Epoch 59, Loss: 1.7064299274220354, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              6.059036517332385e-10
    epoch : 60 ; learning_rate : 6.059036517332385e-10 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.3770899351811954
    Epoch 60, Loss: 1.7064291965988712, fit: 0.05
    Epoch 60, Loss: 1.7064291965988712
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              6.051569644139604e-10
    epoch : 61 ; learning_rate : 6.051569644139604e-10 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.3694478517688027
    Epoch 61, Loss: 1.7064282840036307, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.034576892194405e-10
    epoch : 62 ; learning_rate : 5.034576892194405e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.3770709045923737
    Epoch 62, Loss: 1.7064274638686248, fit: 0.16666666666666666
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.2353778285752826e-10
    epoch : 63 ; learning_rate : 4.2353778285752826e-10 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4697521102997533
    Epoch 63, Loss: 1.706426770947888, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.713955592418606e-10
    epoch : 64 ; learning_rate : 4.713955592418606e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.3729983657429121
    Epoch 64, Loss: 1.7064261232037699, fit: 0.15
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.456553557335832e-10
    epoch : 65 ; learning_rate : 4.456553557335832e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.3411205933482477
    Epoch 65, Loss: 1.7064254534973053, fit: 0.16666666666666666
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.412710778970206e-10
    epoch : 66 ; learning_rate : 4.412710778970206e-10 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4459255338558354
    Epoch 66, Loss: 1.706424787456039, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              6.08146509176887e-10
    epoch : 67 ; learning_rate : 6.08146509176887e-10 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.449639613164708
    Epoch 67, Loss: 1.7064240503159698, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.778907180883269e-10
    epoch : 68 ; learning_rate : 5.778907180883269e-10 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.3774289214128264
    Epoch 68, Loss: 1.7064231420126106, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.486359430638133e-10
    epoch : 69 ; learning_rate : 5.486359430638133e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4321467776051642
    Epoch 69, Loss: 1.7064222996415273, fit: 0.2
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.6707410898336237e-10
    epoch : 70 ; learning_rate : 3.6707410898336237e-10 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.4290092423372356
    Epoch 70, Loss: 1.706421595292347, fit: 0.11666666666666667
    Epoch 70, Loss: 1.706421595292347
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.826423291533236e-10
    epoch : 71 ; learning_rate : 4.826423291533236e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.3964279909800745
    Epoch 71, Loss: 1.7064209958812486, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.798356063290006e-10
    epoch : 72 ; learning_rate : 4.798356063290006e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4342908385149065
    Epoch 72, Loss: 1.7064202855884525, fit: 0.15
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.408752790315647e-10
    epoch : 73 ; learning_rate : 4.408752790315647e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.36521883640601
    Epoch 73, Loss: 1.706419619243735, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.145680761631992e-10
    epoch : 74 ; learning_rate : 5.145680761631992e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.376410770188511
    Epoch 74, Loss: 1.7064188658139379, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.593357521323301e-10
    epoch : 75 ; learning_rate : 4.593357521323301e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.396845445032619
    Epoch 75, Loss: 1.70641817315619, fit: 0.16666666666666666
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.1277073318609086e-10
    epoch : 76 ; learning_rate : 4.1277073318609086e-10 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4265008630991074
    Epoch 76, Loss: 1.7064175222387186, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.840940979700817e-10
    epoch : 77 ; learning_rate : 4.840940979700817e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.432487420693703
    Epoch 77, Loss: 1.70641687462059, fit: 0.21666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.2733264399460833e-10
    epoch : 78 ; learning_rate : 3.2733264399460833e-10 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.437836852577756
    Epoch 78, Loss: 1.7064162702100578, fit: 0.15
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.619638996839034e-10
    epoch : 79 ; learning_rate : 4.619638996839034e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.3646533818736917
    Epoch 79, Loss: 1.7064156506867247, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              6.0544434186749e-10
    epoch : 80 ; learning_rate : 6.0544434186749e-10 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.3539830923886795
    Epoch 80, Loss: 1.7064148767224665, fit: 0.13333333333333333
    Epoch 80, Loss: 1.7064148767224665
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.790211902997437e-10
    epoch : 81 ; learning_rate : 4.790211902997437e-10 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.3908750345052907
    Epoch 81, Loss: 1.7064140978951687, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.521887861418076e-10
    epoch : 82 ; learning_rate : 4.521887861418076e-10 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4082611684894184
    Epoch 82, Loss: 1.7064133874415965, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.859155645301682e-10
    epoch : 83 ; learning_rate : 5.859155645301682e-10 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4573569521821832
    Epoch 83, Loss: 1.7064126296939137, fit: 0.05
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              6.372298048901306e-10
    epoch : 84 ; learning_rate : 6.372298048901306e-10 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4118657818366622
    Epoch 84, Loss: 1.7064117223334274, fit: 0.1
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              5.124695766005504e-10
    epoch : 85 ; learning_rate : 5.124695766005504e-10 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.459741287214366
    Epoch 85, Loss: 1.7064108886533969, fit: 0.2
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.7766364060414015e-10
    epoch : 86 ; learning_rate : 3.7766364060414015e-10 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.429052866800828
    Epoch 86, Loss: 1.706410224958407, fit: 0.18333333333333332
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              3.7384521597670353e-10
    epoch : 87 ; learning_rate : 3.7384521597670353e-10 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.4074724751717695
    Epoch 87, Loss: 1.7064096594703613, fit: 0.15
      batch rate adapted learning_rate :              1.0000000000000001e-07
      loss adapted learning_rate :              4.442775655413725e-10
    epoch : 88 ; learning_rate : 4.442775655413725e-10 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4095686205645284
    Epoch 88, Loss: 1.70640906645051, fit: 0.13333333333333333
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.0001_hidden_size_784_loss_1.671004230695524_fit_0.13333333333333333_2024-01-02_201911
  self.fit : 0.13333333333333333
  self.loss : 1.671004230695524
  current_accuracy : 0.1116
   Accuracy mean: 0.1118
   Accuracy mean: 0.1118
   Accuracy mean: 0.1116
  LR: 1e-07
  Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  Sample: 1/1
  Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          1e-07
    batch_rate :          0.001
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              0.0
    epoch : 0 ; learning_rate : 0.0 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.456567470158398
    Epoch 0, Loss: 1.7495650176253692, fit: 0.13333333333333333
    Epoch 0, Loss: 1.7495650176253692
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_1e-07_hidden_size_784_loss_1.696657731937358_fit_0.13333333333333333_2024-01-02_201919
  self.fit : 0.13333333333333333
  self.loss : 1.696657731937358
  current_accuracy : 0.0959
  Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          1e-07
    batch_rate :          0.001
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.884079469415826e-13
    epoch : 0 ; learning_rate : 4.884079469415826e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.445565009249082
    Epoch 0, Loss: 1.7495650172806558, fit: 0.08333333333333333
    Epoch 0, Loss: 1.7495650172806558
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.432939447282199e-13
    epoch : 1 ; learning_rate : 5.432939447282199e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.46914748777532
    Epoch 1, Loss: 1.7495650165106271, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.605768223328384e-13
    epoch : 2 ; learning_rate : 5.605768223328384e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.407662877124732
    Epoch 2, Loss: 1.7495650157503477, fit: 0.03333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.936175264810438e-13
    epoch : 3 ; learning_rate : 5.936175264810438e-13 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4953831549330383
    Epoch 3, Loss: 1.749565014898988, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.650736993423831e-13
    epoch : 4 ; learning_rate : 5.650736993423831e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4990676457200214
    Epoch 4, Loss: 1.749565014039656, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.904441323849623e-13
    epoch : 5 ; learning_rate : 5.904441323849623e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.475648762601716
    Epoch 5, Loss: 1.7495650132013763, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.800863424354389e-13
    epoch : 6 ; learning_rate : 4.800863424354389e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4310976563008457
    Epoch 6, Loss: 1.7495650124453062, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.283457327617963e-13
    epoch : 7 ; learning_rate : 5.283457327617963e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4059305962466138
    Epoch 7, Loss: 1.7495650116943613, fit: 0.16666666666666666
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.3176606600842183e-13
    epoch : 8 ; learning_rate : 4.3176606600842183e-13 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4836099864478205
    Epoch 8, Loss: 1.7495650109733496, fit: 0.11666666666666667
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_1e-07_hidden_size_784_loss_1.721120964269082_fit_0.11666666666666667_2024-01-02_202021
  self.fit : 0.11666666666666667
  self.loss : 1.721120964269082
  current_accuracy : 0.0959
  Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          1e-07
    batch_rate :          0.001
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.098403267343721e-13
    epoch : 0 ; learning_rate : 5.098403267343721e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.47035636722237
    Epoch 0, Loss: 1.7495650103346905, fit: 0.1
    Epoch 0, Loss: 1.7495650103346905
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.373574876019753e-13
    epoch : 1 ; learning_rate : 5.373574876019753e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.471220979839157
    Epoch 1, Loss: 1.749565009620554, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.286145922381704e-13
    epoch : 2 ; learning_rate : 5.286145922381704e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4663557242471092
    Epoch 2, Loss: 1.749565008772662, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.176086223213624e-13
    epoch : 3 ; learning_rate : 5.176086223213624e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4126474930753077
    Epoch 3, Loss: 1.7495650079958873, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.825004329870296e-13
    epoch : 4 ; learning_rate : 5.825004329870296e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4842178504121082
    Epoch 4, Loss: 1.749565007166716, fit: 0.05
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.999938751713499e-13
    epoch : 5 ; learning_rate : 5.999938751713499e-13 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.489284625912835
    Epoch 5, Loss: 1.7495650063603176, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.893211802336463e-13
    epoch : 6 ; learning_rate : 4.893211802336463e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.514463594016559
    Epoch 6, Loss: 1.7495650056026424, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.633319984590093e-13
    epoch : 7 ; learning_rate : 5.633319984590093e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4957117170406513
    Epoch 7, Loss: 1.7495650048270939, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.624644654208854e-13
    epoch : 8 ; learning_rate : 4.624644654208854e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.519229053971401
    Epoch 8, Loss: 1.749565004045198, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.499697241649486e-13
    epoch : 9 ; learning_rate : 5.499697241649486e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4810306630545955
    Epoch 9, Loss: 1.7495650033512027, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.161946982163151e-13
    epoch : 10 ; learning_rate : 5.161946982163151e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.476139901272724
    Epoch 10, Loss: 1.7495650025909586, fit: 0.06666666666666667
    Epoch 10, Loss: 1.7495650025909586
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.203486168126616e-13
    epoch : 11 ; learning_rate : 6.203486168126616e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5051695084650367
    Epoch 11, Loss: 1.749565001761882, fit: 0.05
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.547039178551196e-13
    epoch : 12 ; learning_rate : 6.547039178551196e-13 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4672308645993215
    Epoch 12, Loss: 1.7495650007704957, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.232308564791591e-13
    epoch : 13 ; learning_rate : 6.232308564791591e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4348085889335584
    Epoch 13, Loss: 1.7495649998224774, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.144013317805239e-13
    epoch : 14 ; learning_rate : 5.144013317805239e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4748525143750821
    Epoch 14, Loss: 1.7495649990495237, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.142282439242195e-13
    epoch : 15 ; learning_rate : 6.142282439242195e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4907737571510231
    Epoch 15, Loss: 1.7495649982090462, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.494396935248538e-13
    epoch : 16 ; learning_rate : 5.494396935248538e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5045171895450637
    Epoch 16, Loss: 1.74956499729737, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.915980635658015e-13
    epoch : 17 ; learning_rate : 4.915980635658015e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4895780940066847
    Epoch 17, Loss: 1.7495649966964308, fit: 0.03333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.660468341177229e-13
    epoch : 18 ; learning_rate : 6.660468341177229e-13 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4300252760105925
    Epoch 18, Loss: 1.7495649957715673, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.122073339997082e-13
    epoch : 19 ; learning_rate : 5.122073339997082e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4669371842480883
    Epoch 19, Loss: 1.7495649948952616, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.782205979882764e-13
    epoch : 20 ; learning_rate : 4.782205979882764e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4110557953606604
    Epoch 20, Loss: 1.749564994173074, fit: 0.13333333333333333
    Epoch 20, Loss: 1.749564994173074
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.877326740456348e-13
    epoch : 21 ; learning_rate : 4.877326740456348e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4284817364944318
    Epoch 21, Loss: 1.749564993497691, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.974172294404826e-13
    epoch : 22 ; learning_rate : 4.974172294404826e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4728089519021783
    Epoch 22, Loss: 1.7495649927994132, fit: 0.03333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.512764149794371e-13
    epoch : 23 ; learning_rate : 6.512764149794371e-13 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4702800148806072
    Epoch 23, Loss: 1.7495649918567793, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.890279896713996e-13
    epoch : 24 ; learning_rate : 4.890279896713996e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4512255710119115
    Epoch 24, Loss: 1.7495649911550524, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.910590334885249e-13
    epoch : 25 ; learning_rate : 4.910590334885249e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4918391575686734
    Epoch 25, Loss: 1.7495649904103159, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.836358774559117e-13
    epoch : 26 ; learning_rate : 5.836358774559117e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.407565555137342
    Epoch 26, Loss: 1.7495649895683094, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.181512415657861e-13
    epoch : 27 ; learning_rate : 6.181512415657861e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.482383708608351
    Epoch 27, Loss: 1.7495649887365354, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.336816323014052e-13
    epoch : 28 ; learning_rate : 5.336816323014052e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4560392196529564
    Epoch 28, Loss: 1.7495649879589021, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.284130527715013e-13
    epoch : 29 ; learning_rate : 4.284130527715013e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.5128689298744769
    Epoch 29, Loss: 1.749564987232101, fit: 0.15
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.549125451104732e-13
    epoch : 30 ; learning_rate : 4.549125451104732e-13 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.5073663616083997
    Epoch 30, Loss: 1.7495649866149081, fit: 0.11666666666666667
    Epoch 30, Loss: 1.7495649866149081
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.916623763971937e-13
    epoch : 31 ; learning_rate : 4.916623763971937e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4639837378815088
    Epoch 31, Loss: 1.7495649859253122, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.658563655566652e-13
    epoch : 32 ; learning_rate : 4.658563655566652e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4898518928421283
    Epoch 32, Loss: 1.7495649852492596, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.909068591227831e-13
    epoch : 33 ; learning_rate : 4.909068591227831e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4481843228639035
    Epoch 33, Loss: 1.7495649845190786, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.778001605267107e-13
    epoch : 34 ; learning_rate : 5.778001605267107e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4313003530017394
    Epoch 34, Loss: 1.749564983709831, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.717868532821256e-13
    epoch : 35 ; learning_rate : 5.717868532821256e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4097013618630305
    Epoch 35, Loss: 1.7495649828316782, fit: 0.15
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.60626921240062e-13
    epoch : 36 ; learning_rate : 4.60626921240062e-13 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4657812466998148
    Epoch 36, Loss: 1.749564982146436, fit: 0.03333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.620914369480143e-13
    epoch : 37 ; learning_rate : 6.620914369480143e-13 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4828062945700187
    Epoch 37, Loss: 1.7495649813360803, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.693846948453089e-13
    epoch : 38 ; learning_rate : 5.693846948453089e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4903414295986357
    Epoch 38, Loss: 1.7495649804002462, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.723030007070476e-13
    epoch : 39 ; learning_rate : 4.723030007070476e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4450993443767266
    Epoch 39, Loss: 1.7495649796616508, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.323968875190722e-13
    epoch : 40 ; learning_rate : 5.323968875190722e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4927119464765435
    Epoch 40, Loss: 1.7495649789377183, fit: 0.06666666666666667
    Epoch 40, Loss: 1.7495649789377183
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.834143446588183e-13
    epoch : 41 ; learning_rate : 5.834143446588183e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4836671731235578
    Epoch 41, Loss: 1.7495649781512497, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.380235915226914e-13
    epoch : 42 ; learning_rate : 5.380235915226914e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4465350087001583
    Epoch 42, Loss: 1.7495649773376898, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.130716318840963e-13
    epoch : 43 ; learning_rate : 6.130716318840963e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4072267987547369
    Epoch 43, Loss: 1.7495649765288366, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.409495734852874e-13
    epoch : 44 ; learning_rate : 5.409495734852874e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.512124722112971
    Epoch 44, Loss: 1.749564975681334, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.542216386037956e-13
    epoch : 45 ; learning_rate : 5.542216386037956e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4734489536496154
    Epoch 45, Loss: 1.7495649748580646, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.659775024953165e-13
    epoch : 46 ; learning_rate : 5.659775024953165e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5001162115886824
    Epoch 46, Loss: 1.7495649740461272, fit: 0.15
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.321419831179803e-13
    epoch : 47 ; learning_rate : 4.321419831179803e-13 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.5089066699359681
    Epoch 47, Loss: 1.7495649733276255, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.339452313415253e-13
    epoch : 48 ; learning_rate : 5.339452313415253e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4193011331485779
    Epoch 48, Loss: 1.7495649726293345, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.521724791309219e-13
    epoch : 49 ; learning_rate : 5.521724791309219e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5256533436140312
    Epoch 49, Loss: 1.7495649717730202, fit: 0.016666666666666666
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.866509300525512e-13
    epoch : 50 ; learning_rate : 6.866509300525512e-13 ; fit : 0.016666666666666666
    batch_size :          60
    best_batch_loss : 1.4422946381425557
    Epoch 50, Loss: 1.7495649709782515, fit: 0.1
    Epoch 50, Loss: 1.7495649709782515
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.553144295194914e-13
    epoch : 51 ; learning_rate : 5.553144295194914e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5448816478128677
    Epoch 51, Loss: 1.7495649700194364, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.21328419625148e-13
    epoch : 52 ; learning_rate : 5.21328419625148e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.5150592821953035
    Epoch 52, Loss: 1.7495649693332174, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.323881240437113e-13
    epoch : 53 ; learning_rate : 5.323881240437113e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4799368034962177
    Epoch 53, Loss: 1.7495649685534942, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.010847847138697e-13
    epoch : 54 ; learning_rate : 5.010847847138697e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4383524201853475
    Epoch 54, Loss: 1.749564967678878, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.922732343416348e-13
    epoch : 55 ; learning_rate : 5.922732343416348e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4685523412533608
    Epoch 55, Loss: 1.74956496696764, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.711909856437386e-13
    epoch : 56 ; learning_rate : 5.711909856437386e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4894040956320191
    Epoch 56, Loss: 1.7495649660762325, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.359400855319375e-13
    epoch : 57 ; learning_rate : 5.359400855319375e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.500175729832422
    Epoch 57, Loss: 1.7495649652808989, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.905968087814093e-13
    epoch : 58 ; learning_rate : 4.905968087814093e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.476561995833669
    Epoch 58, Loss: 1.7495649645460354, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.045911283932136e-13
    epoch : 59 ; learning_rate : 6.045911283932136e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.450992660740009
    Epoch 59, Loss: 1.749564963762362, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.337590195158973e-13
    epoch : 60 ; learning_rate : 5.337590195158973e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4392492102720453
    Epoch 60, Loss: 1.7495649629113361, fit: 0.05
    Epoch 60, Loss: 1.7495649629113361
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.400417794363161e-13
    epoch : 61 ; learning_rate : 6.400417794363161e-13 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4503261909996448
    Epoch 61, Loss: 1.7495649620473823, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.540877599085429e-13
    epoch : 62 ; learning_rate : 5.540877599085429e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5399299585506787
    Epoch 62, Loss: 1.7495649612655675, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.003221550147516e-13
    epoch : 63 ; learning_rate : 5.003221550147516e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.3407887005828523
    Epoch 63, Loss: 1.7495649604862726, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.570597391751184e-13
    epoch : 64 ; learning_rate : 5.570597391751184e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4799748072743701
    Epoch 64, Loss: 1.7495649596900986, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.224170763460426e-13
    epoch : 65 ; learning_rate : 5.224170763460426e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4943271970836964
    Epoch 65, Loss: 1.7495649589036626, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.143328695555452e-13
    epoch : 66 ; learning_rate : 5.143328695555452e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4857793738469967
    Epoch 66, Loss: 1.7495649581471189, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.101406609790095e-13
    epoch : 67 ; learning_rate : 5.101406609790095e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4883112738243034
    Epoch 67, Loss: 1.7495649573627836, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.571126294748538e-13
    epoch : 68 ; learning_rate : 5.571126294748538e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.46791492117436
    Epoch 68, Loss: 1.7495649565818756, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.593600760558082e-13
    epoch : 69 ; learning_rate : 5.593600760558082e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4762493333395763
    Epoch 69, Loss: 1.7495649558657465, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.062273093225175e-13
    epoch : 70 ; learning_rate : 5.062273093225175e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.5150100445270174
    Epoch 70, Loss: 1.7495649550075072, fit: 0.08333333333333333
    Epoch 70, Loss: 1.7495649550075072
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.307948273323788e-13
    epoch : 71 ; learning_rate : 5.307948273323788e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5122632814060377
    Epoch 71, Loss: 1.749564954305533, fit: 0.06666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.565778872535248e-13
    epoch : 72 ; learning_rate : 5.565778872535248e-13 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4592370058126685
    Epoch 72, Loss: 1.7495649534556983, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.223626470332926e-13
    epoch : 73 ; learning_rate : 5.223626470332926e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4195747955578866
    Epoch 73, Loss: 1.7495649527144264, fit: 0.05
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.052944357524348e-13
    epoch : 74 ; learning_rate : 6.052944357524348e-13 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4715163722780693
    Epoch 74, Loss: 1.7495649518212641, fit: 0.18333333333333332
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.0275080288363536e-13
    epoch : 75 ; learning_rate : 4.0275080288363536e-13 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.4653349441757513
    Epoch 75, Loss: 1.7495649511010765, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.83915387288027e-13
    epoch : 76 ; learning_rate : 4.83915387288027e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4779812808047843
    Epoch 76, Loss: 1.7495649505634885, fit: 0.05
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.252049481613907e-13
    epoch : 77 ; learning_rate : 6.252049481613907e-13 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4968866656563213
    Epoch 77, Loss: 1.7495649497656742, fit: 0.16666666666666666
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.2903514941842037e-13
    epoch : 78 ; learning_rate : 4.2903514941842037e-13 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.3813517065976593
    Epoch 78, Loss: 1.7495649488900964, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.253941180421404e-13
    epoch : 79 ; learning_rate : 5.253941180421404e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4867364679476027
    Epoch 79, Loss: 1.7495649482551037, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.466927746830602e-13
    epoch : 80 ; learning_rate : 5.466927746830602e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4321668244445855
    Epoch 80, Loss: 1.749564947476852, fit: 0.13333333333333333
    Epoch 80, Loss: 1.749564947476852
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.905372131581096e-13
    epoch : 81 ; learning_rate : 4.905372131581096e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4494458644716146
    Epoch 81, Loss: 1.749564946708036, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.697709959226923e-13
    epoch : 82 ; learning_rate : 4.697709959226923e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.5230870098223837
    Epoch 82, Loss: 1.7495649460289924, fit: 0.03333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              6.629046695142419e-13
    epoch : 83 ; learning_rate : 6.629046695142419e-13 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4758331359673988
    Epoch 83, Loss: 1.7495649450932338, fit: 0.11666666666666667
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.086541003102899e-13
    epoch : 84 ; learning_rate : 5.086541003102899e-13 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4730289774810743
    Epoch 84, Loss: 1.7495649443542765, fit: 0.08333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.229786841044451e-13
    epoch : 85 ; learning_rate : 5.229786841044451e-13 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.494099337886129
    Epoch 85, Loss: 1.7495649436153085, fit: 0.15
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.837508787130163e-13
    epoch : 86 ; learning_rate : 4.837508787130163e-13 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.462225027517007
    Epoch 86, Loss: 1.7495649428210822, fit: 0.1
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              5.636642090150653e-13
    epoch : 87 ; learning_rate : 5.636642090150653e-13 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.491514181531187
    Epoch 87, Loss: 1.7495649420397394, fit: 0.13333333333333333
      batch rate adapted learning_rate :              1e-10
      loss adapted learning_rate :              4.922620061216947e-13
    epoch : 88 ; learning_rate : 4.922620061216947e-13 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.5183005691520306
    Epoch 88, Loss: 1.7495649412306973, fit: 0.08333333333333333
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_1e-07_hidden_size_784_loss_1.7658563560190297_fit_0.08333333333333333_2024-01-02_203038
  self.fit : 0.08333333333333333
  self.loss : 1.7658563560190297
  current_accuracy : 0.0959
   Accuracy mean: 0.0959
   Accuracy mean: 0.0959
   Accuracy mean: 0.0959
  Results saved to test_combinations_results20240102203039
  normalized_accuracies :      [0.         0.         0.         0.08862876 0.08862876 0.08751394
   0.0328874  0.03400223 0.090301   0.04069119 0.16610925 1.        ]
file_path :  src/mnist_train.csv
save_file :  src/mnist_train.npz
file_path :  src/mnist_test.csv
save_file :  src/mnist_test.npz
batch_rate :  0.001
  LR: 0.9
  Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  Sample: 1/1
  Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.9
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              0.0
    epoch : 0 ; learning_rate : 0.0 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.5673650113550048
    Epoch 0, Loss: 1.797164556066859, fit: 0.11666666666666667
    Epoch 0, Loss: 1.797164556066859
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_1.7131752552830628_fit_0.11666666666666667_2024-01-03_005700
  self.fit : 0.11666666666666667
  self.loss : 1.7131752552830628
  current_accuracy : 0.0794
  Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          0.9
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.525305341270288e-06
    epoch : 0 ; learning_rate : 4.525305341270288e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.544604411601823
    Epoch 0, Loss: 1.7949283453134146, fit: 0.06666666666666667
    Epoch 0, Loss: 1.7949283453134146
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              5.375629264089335e-06
    epoch : 1 ; learning_rate : 5.375629264089335e-06 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.549708484080238
    Epoch 1, Loss: 1.788669331116755, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              5.84762681723226e-06
    epoch : 2 ; learning_rate : 5.84762681723226e-06 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4943181475295462
    Epoch 2, Loss: 1.7808038185240171, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.364999154176171e-06
    epoch : 3 ; learning_rate : 4.364999154176171e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.529568546041648
    Epoch 3, Loss: 1.7732669783103676, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              5.919134523661396e-06
    epoch : 4 ; learning_rate : 5.919134523661396e-06 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.513760199021541
    Epoch 4, Loss: 1.7653169653141512, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.679993494909197e-06
    epoch : 5 ; learning_rate : 4.679993494909197e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4587579601342429
    Epoch 5, Loss: 1.7566430399002773, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.953716777416674e-06
    epoch : 6 ; learning_rate : 4.953716777416674e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4810637036608745
    Epoch 6, Loss: 1.7496416300659607, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.519942348189014e-06
    epoch : 7 ; learning_rate : 4.519942348189014e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4996658084104306
    Epoch 7, Loss: 1.7410296020722171, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              5.670858071941901e-06
    epoch : 8 ; learning_rate : 5.670858071941901e-06 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4211662627574613
    Epoch 8, Loss: 1.7338211697169765, fit: 0.08333333333333333
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_1.7634199857573327_fit_0.08333333333333333_2024-01-03_005802
  self.fit : 0.08333333333333333
  self.loss : 1.7634199857573327
  current_accuracy : 0.1
  Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          0.9
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.935257136112098e-06
    epoch : 0 ; learning_rate : 4.935257136112098e-06 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.465956009764658
    Epoch 0, Loss: 1.7265827195084111, fit: 0.1
    Epoch 0, Loss: 1.7265827195084111
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.663394419326845e-06
    epoch : 1 ; learning_rate : 4.663394419326845e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.459097549084776
    Epoch 1, Loss: 1.7201087078540995, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.032192673433945e-06
    epoch : 2 ; learning_rate : 4.032192673433945e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.435038005054473
    Epoch 2, Loss: 1.7137769075235028, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.684080200433007e-06
    epoch : 3 ; learning_rate : 3.684080200433007e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.4677597271400662
    Epoch 3, Loss: 1.7079252939136633, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.381655733973153e-06
    epoch : 4 ; learning_rate : 4.381655733973153e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.3922509106477576
    Epoch 4, Loss: 1.702185856797586, fit: 0.05
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              5.50747804685916e-06
    epoch : 5 ; learning_rate : 5.50747804685916e-06 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.363700936629543
    Epoch 5, Loss: 1.6955386553055916, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.825782620499916e-06
    epoch : 6 ; learning_rate : 3.825782620499916e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.3024352092231795
    Epoch 6, Loss: 1.6894481382577016, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.4283191313582233e-06
    epoch : 7 ; learning_rate : 3.4283191313582233e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.3882232780140185
    Epoch 7, Loss: 1.6847435107789375, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              5.12584624576568e-06
    epoch : 8 ; learning_rate : 5.12584624576568e-06 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.3858550960332823
    Epoch 8, Loss: 1.6794748985623897, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.9992639272246985e-06
    epoch : 9 ; learning_rate : 3.9992639272246985e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.3157371028528757
    Epoch 9, Loss: 1.6737628154916833, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.901591199869857e-06
    epoch : 10 ; learning_rate : 3.901591199869857e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.3662750818605
    Epoch 10, Loss: 1.6685590695780197, fit: 0.25
    Epoch 10, Loss: 1.6685590695780197
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.939296712523065e-06
    epoch : 11 ; learning_rate : 2.939296712523065e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.2739706160018334
    Epoch 11, Loss: 1.664132281238891, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.314877324604885e-06
    epoch : 12 ; learning_rate : 4.314877324604885e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.335188101304252
    Epoch 12, Loss: 1.6596045951438332, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.9807352158447874e-06
    epoch : 13 ; learning_rate : 4.9807352158447874e-06 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.2463580561397676
    Epoch 13, Loss: 1.65350500913332, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.932163252276673e-06
    epoch : 14 ; learning_rate : 3.932163252276673e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.264006571606206
    Epoch 14, Loss: 1.6481164591917292, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.94404422180063e-06
    epoch : 15 ; learning_rate : 3.94404422180063e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.3291221882260078
    Epoch 15, Loss: 1.6431108607666023, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.611569735186743e-06
    epoch : 16 ; learning_rate : 3.611569735186743e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.2849137857639037
    Epoch 16, Loss: 1.6384766504399213, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.3142924465456386e-06
    epoch : 17 ; learning_rate : 4.3142924465456386e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.3031813555536003
    Epoch 17, Loss: 1.633507572795946, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.625108400591349e-06
    epoch : 18 ; learning_rate : 4.625108400591349e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.3455002393125293
    Epoch 18, Loss: 1.6279699626908146, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.2102412664026568e-06
    epoch : 19 ; learning_rate : 3.2102412664026568e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.3135324276544493
    Epoch 19, Loss: 1.623149832727065, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.5751358621315922e-06
    epoch : 20 ; learning_rate : 3.5751358621315922e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.2975661899831863
    Epoch 20, Loss: 1.619101456560335, fit: 0.13333333333333333
    Epoch 20, Loss: 1.619101456560335
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.145228867873381e-06
    epoch : 21 ; learning_rate : 4.145228867873381e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.313587725484236
    Epoch 21, Loss: 1.6144521752941816, fit: 0.2833333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.464468680634305e-06
    epoch : 22 ; learning_rate : 2.464468680634305e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.2603155145104392
    Epoch 22, Loss: 1.610534415204441, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.843533110721106e-06
    epoch : 23 ; learning_rate : 4.843533110721106e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.3179523400826707
    Epoch 23, Loss: 1.6063168057247081, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.8792681192060166e-06
    epoch : 24 ; learning_rate : 3.8792681192060166e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.2421705842355253
    Epoch 24, Loss: 1.601100121651639, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.362044471638882e-06
    epoch : 25 ; learning_rate : 4.362044471638882e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.2962227693230772
    Epoch 25, Loss: 1.5962698543958416, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.4778284803612743e-06
    epoch : 26 ; learning_rate : 3.4778284803612743e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.28771035347683
    Epoch 26, Loss: 1.5914132024720409, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.6570615964892074e-06
    epoch : 27 ; learning_rate : 3.6570615964892074e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.2863841128078521
    Epoch 27, Loss: 1.5869784664764799, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.6140180321644678e-06
    epoch : 28 ; learning_rate : 3.6140180321644678e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.2955703128614309
    Epoch 28, Loss: 1.582392310639568, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.784462645963819e-06
    epoch : 29 ; learning_rate : 3.784462645963819e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.283437655276564
    Epoch 29, Loss: 1.5777730348753158, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.996407595775485e-06
    epoch : 30 ; learning_rate : 3.996407595775485e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.2578916178656172
    Epoch 30, Loss: 1.5728857907065068, fit: 0.26666666666666666
    Epoch 30, Loss: 1.5728857907065068
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.7868251614966182e-06
    epoch : 31 ; learning_rate : 2.7868251614966182e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.237138778778715
    Epoch 31, Loss: 1.5685864564822543, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.88485379458025e-06
    epoch : 32 ; learning_rate : 2.88485379458025e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.106967575962311
    Epoch 32, Loss: 1.56504152446192, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.457854779917346e-06
    epoch : 33 ; learning_rate : 4.457854779917346e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.1730380718641036
    Epoch 33, Loss: 1.5605945786244202, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.010129886744271e-06
    epoch : 34 ; learning_rate : 3.010129886744271e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.2363886976654024
    Epoch 34, Loss: 1.5561180121993945, fit: 0.26666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.3669824851713237e-06
    epoch : 35 ; learning_rate : 2.3669824851713237e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.1652930138551725
    Epoch 35, Loss: 1.5529574101214036, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.304280163674426e-06
    epoch : 36 ; learning_rate : 3.304280163674426e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.1491921638960045
    Epoch 36, Loss: 1.5497024765676137, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.2492896831617825e-06
    epoch : 37 ; learning_rate : 4.2492896831617825e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.230014001058677
    Epoch 37, Loss: 1.5452265906393554, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.3019894071177987e-06
    epoch : 38 ; learning_rate : 3.3019894071177987e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.2127066712720713
    Epoch 38, Loss: 1.540726515554021, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.956452329033741e-06
    epoch : 39 ; learning_rate : 2.956452329033741e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.1790600126874873
    Epoch 39, Loss: 1.5370468877387253, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.2209170128809577e-06
    epoch : 40 ; learning_rate : 3.2209170128809577e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.2034683503458041
    Epoch 40, Loss: 1.5333003447860867, fit: 0.13333333333333333
    Epoch 40, Loss: 1.5333003447860867
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.191939729828329e-06
    epoch : 41 ; learning_rate : 4.191939729828329e-06 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.1478084921617913
    Epoch 41, Loss: 1.5288106022208026, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.84424859684289e-06
    epoch : 42 ; learning_rate : 2.84424859684289e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.1501474089357164
    Epoch 42, Loss: 1.524379638201874, fit: 0.26666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.4886911898517243e-06
    epoch : 43 ; learning_rate : 2.4886911898517243e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.1704520100566531
    Epoch 43, Loss: 1.5209809665382839, fit: 0.15
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.007023912790444e-06
    epoch : 44 ; learning_rate : 4.007023912790444e-06 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.1659442785109246
    Epoch 44, Loss: 1.5167264899748039, fit: 0.2833333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.3093082913467814e-06
    epoch : 45 ; learning_rate : 2.3093082913467814e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.152455000738279
    Epoch 45, Loss: 1.5127362742400068, fit: 0.3
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.205126061939697e-06
    epoch : 46 ; learning_rate : 2.205126061939697e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 1.166856687598751
    Epoch 46, Loss: 1.5098766965114054, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.1727764647881305e-06
    epoch : 47 ; learning_rate : 4.1727764647881305e-06 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.1851174017156556
    Epoch 47, Loss: 1.5057927026195241, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.691473425612597e-06
    epoch : 48 ; learning_rate : 2.691473425612597e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.1859889695560417
    Epoch 48, Loss: 1.5014528570952743, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.6621012211074115e-06
    epoch : 49 ; learning_rate : 3.6621012211074115e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.0986306047706802
    Epoch 49, Loss: 1.4974272936981987, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.2735384387887765e-06
    epoch : 50 ; learning_rate : 3.2735384387887765e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.125216600297463
    Epoch 50, Loss: 1.4932130174023246, fit: 0.16666666666666666
    Epoch 50, Loss: 1.4932130174023246
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.5210478351712356e-06
    epoch : 51 ; learning_rate : 3.5210478351712356e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.1386911440757612
    Epoch 51, Loss: 1.4889813008950046, fit: 0.3
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.1591893954509622e-06
    epoch : 52 ; learning_rate : 2.1591893954509622e-06 ; fit : 0.3
    batch_size :          60
    best_batch_loss : 1.105900391623232
    Epoch 52, Loss: 1.4856194598057582, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.8194141086459994e-06
    epoch : 53 ; learning_rate : 2.8194141086459994e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.1345667699221904
    Epoch 53, Loss: 1.482554313560567, fit: 0.3333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              1.8604197831508672e-06
    epoch : 54 ; learning_rate : 1.8604197831508672e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 1.1166917148084574
    Epoch 54, Loss: 1.4797703231675448, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.0622371743363136e-06
    epoch : 55 ; learning_rate : 3.0622371743363136e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.1045547890298262
    Epoch 55, Loss: 1.476856896747155, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.800314784914361e-06
    epoch : 56 ; learning_rate : 2.800314784914361e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.1876503705974057
    Epoch 56, Loss: 1.473352075805467, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.6918591256715822e-06
    epoch : 57 ; learning_rate : 2.6918591256715822e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.139542169733976
    Epoch 57, Loss: 1.4700994314851314, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.0673192691701966e-06
    epoch : 58 ; learning_rate : 3.0673192691701966e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.129189120337348
    Epoch 58, Loss: 1.4666935479197616, fit: 0.18333333333333332
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.5256620480164222e-06
    epoch : 59 ; learning_rate : 3.5256620480164222e-06 ; fit : 0.18333333333333332
    batch_size :          60
    best_batch_loss : 1.0899266310055207
    Epoch 59, Loss: 1.4628145503412175, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.1833890615948262e-06
    epoch : 60 ; learning_rate : 3.1833890615948262e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.1551977251233145
    Epoch 60, Loss: 1.4589519662889137, fit: 0.26666666666666666
    Epoch 60, Loss: 1.4589519662889137
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.3562558177757487e-06
    epoch : 61 ; learning_rate : 2.3562558177757487e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.1089463959193162
    Epoch 61, Loss: 1.455799053291512, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.01268238267585e-06
    epoch : 62 ; learning_rate : 3.01268238267585e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.1148396699944263
    Epoch 62, Loss: 1.4528600276767811, fit: 0.35
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              1.9014548380142697e-06
    epoch : 63 ; learning_rate : 1.9014548380142697e-06 ; fit : 0.35
    batch_size :          60
    best_batch_loss : 1.0528170302883058
    Epoch 63, Loss: 1.4500623322481785, fit: 0.26666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.602117587647268e-06
    epoch : 64 ; learning_rate : 2.602117587647268e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.108433786393094
    Epoch 64, Loss: 1.4475711840562326, fit: 0.3333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              1.708663727363511e-06
    epoch : 65 ; learning_rate : 1.708663727363511e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 1.0960114618800432
    Epoch 65, Loss: 1.4451644808700572, fit: 0.36666666666666664
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              1.5803075255471731e-06
    epoch : 66 ; learning_rate : 1.5803075255471731e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 1.04925108003581
    Epoch 66, Loss: 1.4433436224738068, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.875284366078391e-06
    epoch : 67 ; learning_rate : 2.875284366078391e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 1.0307422021474684
    Epoch 67, Loss: 1.4408779557285476, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.401963611867277e-06
    epoch : 68 ; learning_rate : 3.401963611867277e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.0675744418669202
    Epoch 68, Loss: 1.4374016468159143, fit: 0.2833333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.370651675572477e-06
    epoch : 69 ; learning_rate : 2.370651675572477e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.1280698398024316
    Epoch 69, Loss: 1.4341640004790308, fit: 0.36666666666666664
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              1.7150180841882883e-06
    epoch : 70 ; learning_rate : 1.7150180841882883e-06 ; fit : 0.36666666666666664
    batch_size :          60
    best_batch_loss : 1.0659026434530299
    Epoch 70, Loss: 1.4318863018314263, fit: 0.26666666666666666
    Epoch 70, Loss: 1.4318863018314263
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.5353484598590327e-06
    epoch : 71 ; learning_rate : 2.5353484598590327e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.0634505317873313
    Epoch 71, Loss: 1.4295203961169363, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.678054787579691e-06
    epoch : 72 ; learning_rate : 2.678054787579691e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 0.9989083560929547
    Epoch 72, Loss: 1.4265397673362503, fit: 0.3333333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              1.7963332610841348e-06
    epoch : 73 ; learning_rate : 1.7963332610841348e-06 ; fit : 0.3333333333333333
    batch_size :          60
    best_batch_loss : 1.0913201140060944
    Epoch 73, Loss: 1.4240567418015286, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.2415226078333256e-06
    epoch : 74 ; learning_rate : 3.2415226078333256e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.1093146078405278
    Epoch 74, Loss: 1.4212497568920384, fit: 0.25
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.6950761682066474e-06
    epoch : 75 ; learning_rate : 2.6950761682066474e-06 ; fit : 0.25
    batch_size :          60
    best_batch_loss : 1.0740484314880987
    Epoch 75, Loss: 1.417873450477271, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.3181301887035615e-06
    epoch : 76 ; learning_rate : 3.3181301887035615e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.0191118714297556
    Epoch 76, Loss: 1.4145097173922347, fit: 0.26666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.3174419441501626e-06
    epoch : 77 ; learning_rate : 2.3174419441501626e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.0556780029967263
    Epoch 77, Loss: 1.411368183815878, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.8909009616927117e-06
    epoch : 78 ; learning_rate : 2.8909009616927117e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 1.058236182696253
    Epoch 78, Loss: 1.4084458687925276, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.897890499277987e-06
    epoch : 79 ; learning_rate : 2.897890499277987e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 0.9924001358829215
    Epoch 79, Loss: 1.4052488528553797, fit: 0.21666666666666667
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.8893672990305778e-06
    epoch : 80 ; learning_rate : 2.8893672990305778e-06 ; fit : 0.21666666666666667
    batch_size :          60
    best_batch_loss : 0.9777744692548348
    Epoch 80, Loss: 1.402035477171781, fit: 0.26666666666666666
    Epoch 80, Loss: 1.402035477171781
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.439650399360453e-06
    epoch : 81 ; learning_rate : 2.439650399360453e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.0482555955473671
    Epoch 81, Loss: 1.3991582265811835, fit: 0.26666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.246199795296174e-06
    epoch : 82 ; learning_rate : 2.246199795296174e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 1.0294777659738206
    Epoch 82, Loss: 1.3966151365854536, fit: 0.2
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.283968769146611e-06
    epoch : 83 ; learning_rate : 3.283968769146611e-06 ; fit : 0.2
    batch_size :          60
    best_batch_loss : 1.0204307803525692
    Epoch 83, Loss: 1.3936481564216683, fit: 0.16666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              3.7109071866388783e-06
    epoch : 84 ; learning_rate : 3.7109071866388783e-06 ; fit : 0.16666666666666666
    batch_size :          60
    best_batch_loss : 1.021027743817726
    Epoch 84, Loss: 1.3898071602042077, fit: 0.23333333333333334
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.5357458955332135e-06
    epoch : 85 ; learning_rate : 2.5357458955332135e-06 ; fit : 0.23333333333333334
    batch_size :          60
    best_batch_loss : 0.9594338291338288
    Epoch 85, Loss: 1.386514127008156, fit: 0.2833333333333333
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.2382307965319303e-06
    epoch : 86 ; learning_rate : 2.2382307965319303e-06 ; fit : 0.2833333333333333
    batch_size :          60
    best_batch_loss : 1.0543112704846185
    Epoch 86, Loss: 1.383974649005492, fit: 0.26666666666666666
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              2.4416846520467063e-06
    epoch : 87 ; learning_rate : 2.4416846520467063e-06 ; fit : 0.26666666666666666
    batch_size :          60
    best_batch_loss : 0.9705880726075958
    Epoch 87, Loss: 1.3814409517191477, fit: 0.1
      batch rate adapted learning_rate :              0.0009000000000000001
      loss adapted learning_rate :              4.576048880381622e-06
    epoch : 88 ; learning_rate : 4.576048880381622e-06 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.007027519490765
    Epoch 88, Loss: 1.3777010215245684, fit: 0.4
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.9_hidden_size_784_loss_1.1831605787243218_fit_0.4_2024-01-03_010823
  self.fit : 0.4
  self.loss : 1.1831605787243218
  current_accuracy : 0.2842
   Accuracy mean: 0.0794
   Accuracy mean: 0.1
   Accuracy mean: 0.2842
  LR: 0.1
  Hidden Size: 784
  accuracy_mean_list : [0.0, 0.0, 0.0]
  Sample: 1/1
  Epochs: 1
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          1
    learning_rate :          0.1
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              0.0
    epoch : 0 ; learning_rate : 0.0 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.5686098860632265
    Epoch 0, Loss: 1.8344683637335062, fit: 0.05
    Epoch 0, Loss: 1.8344683637335062
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.1_hidden_size_784_loss_1.866914186587684_fit_0.05_2024-01-03_010830
  self.fit : 0.05
  self.loss : 1.866914186587684
  current_accuracy : 0.0518
  Epochs: 10
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          9
    learning_rate :          0.1
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.506884047642719e-07
    epoch : 0 ; learning_rate : 6.506884047642719e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.6203283648214573
    Epoch 0, Loss: 1.8339471249886983, fit: 0.03333333333333333
    Epoch 0, Loss: 1.8339471249886983
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.910543215798555e-07
    epoch : 1 ; learning_rate : 6.910543215798555e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.577280844422448
    Epoch 1, Loss: 1.8328562718590666, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.905424852697999e-07
    epoch : 2 ; learning_rate : 5.905424852697999e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.6007568834100696
    Epoch 2, Loss: 1.8318037521302535, fit: 0.016666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              7.108707561619244e-07
    epoch : 3 ; learning_rate : 7.108707561619244e-07 ; fit : 0.016666666666666666
    batch_size :          60
    best_batch_loss : 1.588129041817807
    Epoch 3, Loss: 1.8307365013871888, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.458773722354358e-07
    epoch : 4 ; learning_rate : 6.458773722354358e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5808460595429314
    Epoch 4, Loss: 1.8295876488719716, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.282856284507168e-07
    epoch : 5 ; learning_rate : 5.282856284507168e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.5912700577176337
    Epoch 5, Loss: 1.8286498615126314, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.790207633892874e-07
    epoch : 6 ; learning_rate : 5.790207633892874e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.6002767840573215
    Epoch 6, Loss: 1.8277476998775501, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.781139169550771e-07
    epoch : 7 ; learning_rate : 5.781139169550771e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5860069818743239
    Epoch 7, Loss: 1.8268219196960505, fit: 0.016666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.645947768983531e-07
    epoch : 8 ; learning_rate : 6.645947768983531e-07 ; fit : 0.016666666666666666
    batch_size :          60
    best_batch_loss : 1.6209066033293449
    Epoch 8, Loss: 1.8257700368506513, fit: 0.03333333333333333
      Weights saved to src/weights/weights_tanh_softmax_learning_rate_0.1_hidden_size_784_loss_1.8943348364923254_fit_0.03333333333333333_2024-01-03_010933
  self.fit : 0.03333333333333333
  self.loss : 1.8943348364923254
  current_accuracy : 0.0547
  Epochs: 100
    train
    hidden_activation_function :          tanh
    output_activation_function :          softmax
    X.shape :          (60000, 784)
    y_one_hot.shape :          (60000, 10)
    epochs :          89
    learning_rate :          0.1
    batch_rate :          0.001
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.797829033635829e-07
    epoch : 0 ; learning_rate : 6.797829033635829e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.6304027286862393
    Epoch 0, Loss: 1.82471088632857, fit: 0.05
    Epoch 0, Loss: 1.82471088632857
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.11041393565598e-07
    epoch : 1 ; learning_rate : 6.11041393565598e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5967559376424008
    Epoch 1, Loss: 1.823643890118414, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.868924565650847e-07
    epoch : 2 ; learning_rate : 5.868924565650847e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.6241648793373136
    Epoch 2, Loss: 1.8226591814086661, fit: 0.016666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.818783177271458e-07
    epoch : 3 ; learning_rate : 6.818783177271458e-07 ; fit : 0.016666666666666666
    batch_size :          60
    best_batch_loss : 1.6317849608792092
    Epoch 3, Loss: 1.8216509781138843, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.630537067116055e-07
    epoch : 4 ; learning_rate : 6.630537067116055e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5531392238391362
    Epoch 4, Loss: 1.8206378746964802, fit: 0.016666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              7.035253513567773e-07
    epoch : 5 ; learning_rate : 7.035253513567773e-07 ; fit : 0.016666666666666666
    batch_size :          60
    best_batch_loss : 1.5841528984623983
    Epoch 5, Loss: 1.8194942423079163, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.25768189088316e-07
    epoch : 6 ; learning_rate : 5.25768189088316e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5602082282760723
    Epoch 6, Loss: 1.8185296427890527, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.765376748200184e-07
    epoch : 7 ; learning_rate : 5.765376748200184e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.534085110517513
    Epoch 7, Loss: 1.8176264047858763, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.711079799658849e-07
    epoch : 8 ; learning_rate : 5.711079799658849e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5823600822598396
    Epoch 8, Loss: 1.8167552495296178, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.894463665200962e-07
    epoch : 9 ; learning_rate : 5.894463665200962e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5453782887986403
    Epoch 9, Loss: 1.8157853226100351, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.434830774683374e-07
    epoch : 10 ; learning_rate : 6.434830774683374e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.570172539893025
    Epoch 10, Loss: 1.8147665730114504, fit: 0.1
    Epoch 10, Loss: 1.8147665730114504
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.382088342387615e-07
    epoch : 11 ; learning_rate : 5.382088342387615e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5491334984654626
    Epoch 11, Loss: 1.8138146337998258, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.219185948909818e-07
    epoch : 12 ; learning_rate : 6.219185948909818e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.6018888674107474
    Epoch 12, Loss: 1.8127510301259557, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.99692674707849e-07
    epoch : 13 ; learning_rate : 5.99692674707849e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.596184601995985
    Epoch 13, Loss: 1.811685867149003, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.966873240716911e-07
    epoch : 14 ; learning_rate : 5.966873240716911e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5952937495988018
    Epoch 14, Loss: 1.8106645553254337, fit: 0.0
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              7.226347091881335e-07
    epoch : 15 ; learning_rate : 7.226347091881335e-07 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.5182826331095114
    Epoch 15, Loss: 1.8094627115902766, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.115489287229629e-07
    epoch : 16 ; learning_rate : 6.115489287229629e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5816438928764094
    Epoch 16, Loss: 1.8083115717662475, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.117914892760886e-07
    epoch : 17 ; learning_rate : 6.117914892760886e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5877209512952741
    Epoch 17, Loss: 1.8072772944349202, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.190644590227245e-07
    epoch : 18 ; learning_rate : 5.190644590227245e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.6034482196214912
    Epoch 18, Loss: 1.8062526253265176, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.654373827392027e-07
    epoch : 19 ; learning_rate : 5.654373827392027e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5433371282240615
    Epoch 19, Loss: 1.8053878963132588, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.815321001152569e-07
    epoch : 20 ; learning_rate : 5.815321001152569e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5875773009286935
    Epoch 20, Loss: 1.8043609661919717, fit: 0.0
    Epoch 20, Loss: 1.8043609661919717
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              7.314082170978491e-07
    epoch : 21 ; learning_rate : 7.314082170978491e-07 ; fit : 0.0
    batch_size :          60
    best_batch_loss : 1.5778492514963338
    Epoch 21, Loss: 1.8032101813849966, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.154718675219751e-07
    epoch : 22 ; learning_rate : 6.154718675219751e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.6042102587122438
    Epoch 22, Loss: 1.802069437133725, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.974133920213422e-07
    epoch : 23 ; learning_rate : 4.974133920213422e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.542252038580276
    Epoch 23, Loss: 1.8010519483239054, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.987188683759119e-07
    epoch : 24 ; learning_rate : 4.987188683759119e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5735783870732432
    Epoch 24, Loss: 1.8001857889975486, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.285858401989157e-07
    epoch : 25 ; learning_rate : 6.285858401989157e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5439602543627824
    Epoch 25, Loss: 1.799190833904049, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.660860523971007e-07
    epoch : 26 ; learning_rate : 6.660860523971007e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.580380140359427
    Epoch 26, Loss: 1.7980667076265249, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.821798761506302e-07
    epoch : 27 ; learning_rate : 5.821798761506302e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5553572359697059
    Epoch 27, Loss: 1.7969886011412148, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.071568907161787e-07
    epoch : 28 ; learning_rate : 6.071568907161787e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.597320299419647
    Epoch 28, Loss: 1.795985343504588, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.376826591980823e-07
    epoch : 29 ; learning_rate : 5.376826591980823e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5406002528899843
    Epoch 29, Loss: 1.795001401722993, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.987115825889426e-07
    epoch : 30 ; learning_rate : 5.987115825889426e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5056030469761505
    Epoch 30, Loss: 1.7940869008352387, fit: 0.06666666666666667
    Epoch 30, Loss: 1.7940869008352387
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.951825040783887e-07
    epoch : 31 ; learning_rate : 5.951825040783887e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5721640058477553
    Epoch 31, Loss: 1.7930447638217486, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.517895176772207e-07
    epoch : 32 ; learning_rate : 5.517895176772207e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.518575677156673
    Epoch 32, Loss: 1.792081821079791, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.2875268042412534e-07
    epoch : 33 ; learning_rate : 4.2875268042412534e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.5192420930944293
    Epoch 33, Loss: 1.791231277509976, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.647727856178108e-07
    epoch : 34 ; learning_rate : 4.647727856178108e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.5767376850377237
    Epoch 34, Loss: 1.7904312102714928, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.826034173380324e-07
    epoch : 35 ; learning_rate : 5.826034173380324e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.538437686509378
    Epoch 35, Loss: 1.7895391554460172, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.735936898785952e-07
    epoch : 36 ; learning_rate : 4.735936898785952e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.5585729381641484
    Epoch 36, Loss: 1.7885616133723843, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.909192090493218e-07
    epoch : 37 ; learning_rate : 5.909192090493218e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5627682841818473
    Epoch 37, Loss: 1.7875669301777612, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.735256431128033e-07
    epoch : 38 ; learning_rate : 5.735256431128033e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.498658845757855
    Epoch 38, Loss: 1.7865435665782485, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.193085481330941e-07
    epoch : 39 ; learning_rate : 5.193085481330941e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4449012127109622
    Epoch 39, Loss: 1.7855772217517447, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.794157161959646e-07
    epoch : 40 ; learning_rate : 4.794157161959646e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.495191890147477
    Epoch 40, Loss: 1.784665714210297, fit: 0.05
    Epoch 40, Loss: 1.784665714210297
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.091794601848017e-07
    epoch : 41 ; learning_rate : 6.091794601848017e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5517941043076897
    Epoch 41, Loss: 1.783690260538581, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.253262284437452e-07
    epoch : 42 ; learning_rate : 5.253262284437452e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.525039179993352
    Epoch 42, Loss: 1.7826519854659564, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.996866936950387e-07
    epoch : 43 ; learning_rate : 5.996866936950387e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.501303073757729
    Epoch 43, Loss: 1.7816403173688906, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.28709436517946e-07
    epoch : 44 ; learning_rate : 6.28709436517946e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5375077974590012
    Epoch 44, Loss: 1.78054156727456, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.686030431011261e-07
    epoch : 45 ; learning_rate : 5.686030431011261e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.535309127678542
    Epoch 45, Loss: 1.7795068162003806, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.255427153492532e-07
    epoch : 46 ; learning_rate : 5.255427153492532e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5213188009903447
    Epoch 46, Loss: 1.7785084417417085, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.495935072292853e-07
    epoch : 47 ; learning_rate : 6.495935072292853e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4332441518519299
    Epoch 47, Loss: 1.7775345446158235, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.825743176670285e-07
    epoch : 48 ; learning_rate : 5.825743176670285e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.5341948962906329
    Epoch 48, Loss: 1.7764682424712803, fit: 0.016666666666666666
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.930262205430973e-07
    epoch : 49 ; learning_rate : 6.930262205430973e-07 ; fit : 0.016666666666666666
    batch_size :          60
    best_batch_loss : 1.5022330371697048
    Epoch 49, Loss: 1.7754386419390942, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.33407806040021e-07
    epoch : 50 ; learning_rate : 6.33407806040021e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4643370691186148
    Epoch 50, Loss: 1.774308649789523, fit: 0.05
    Epoch 50, Loss: 1.774308649789523
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.5640105432231e-07
    epoch : 51 ; learning_rate : 6.5640105432231e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.534782161987948
    Epoch 51, Loss: 1.7732628489493696, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.276855797781714e-07
    epoch : 52 ; learning_rate : 6.276855797781714e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5490279959732534
    Epoch 52, Loss: 1.772259487637531, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.205376792615382e-07
    epoch : 53 ; learning_rate : 5.205376792615382e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5070845683674192
    Epoch 53, Loss: 1.771324573798262, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.417379551646781e-07
    epoch : 54 ; learning_rate : 5.417379551646781e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4830880566908424
    Epoch 54, Loss: 1.7704842696249916, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.46354396017152e-07
    epoch : 55 ; learning_rate : 5.46354396017152e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5073951511151444
    Epoch 55, Loss: 1.769637208864908, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.234415473230778e-07
    epoch : 56 ; learning_rate : 5.234415473230778e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5319184984523742
    Epoch 56, Loss: 1.768810660605932, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.459530752913365e-07
    epoch : 57 ; learning_rate : 6.459530752913365e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5136392010823045
    Epoch 57, Loss: 1.767881815726914, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.648322162813527e-07
    epoch : 58 ; learning_rate : 6.648322162813527e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.518542444850756
    Epoch 58, Loss: 1.7668321224792098, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.051022579710345e-07
    epoch : 59 ; learning_rate : 6.051022579710345e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4874338801238616
    Epoch 59, Loss: 1.7658174536055136, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.6156464909707473e-07
    epoch : 60 ; learning_rate : 4.6156464909707473e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4715510275229018
    Epoch 60, Loss: 1.765030805811553, fit: 0.06666666666666667
    Epoch 60, Loss: 1.765030805811553
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.911102375522953e-07
    epoch : 61 ; learning_rate : 5.911102375522953e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.5191338189322978
    Epoch 61, Loss: 1.7641893271855582, fit: 0.13333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.726356623337686e-07
    epoch : 62 ; learning_rate : 4.726356623337686e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4906986112350822
    Epoch 62, Loss: 1.7633917316756562, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.790524338819875e-07
    epoch : 63 ; learning_rate : 5.790524338819875e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.527458686542154
    Epoch 63, Loss: 1.7625621090483559, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.106812145840785e-07
    epoch : 64 ; learning_rate : 5.106812145840785e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.5025268596753534
    Epoch 64, Loss: 1.7617616023180538, fit: 0.03333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.619257076099923e-07
    epoch : 65 ; learning_rate : 6.619257076099923e-07 ; fit : 0.03333333333333333
    batch_size :          60
    best_batch_loss : 1.4871767700453224
    Epoch 65, Loss: 1.7608605647494766, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.449447928751824e-07
    epoch : 66 ; learning_rate : 4.449447928751824e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.4987707247403461
    Epoch 66, Loss: 1.7599795901670903, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.771681725343355e-07
    epoch : 67 ; learning_rate : 5.771681725343355e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4363509624858868
    Epoch 67, Loss: 1.7591780473562688, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.168684498567593e-07
    epoch : 68 ; learning_rate : 6.168684498567593e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.4776522267038845
    Epoch 68, Loss: 1.758206878219115, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.377289612611501e-07
    epoch : 69 ; learning_rate : 6.377289612611501e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.434394469782766
    Epoch 69, Loss: 1.75716384501364, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.522897306937768e-07
    epoch : 70 ; learning_rate : 5.522897306937768e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.496267462182839
    Epoch 70, Loss: 1.7561866988862596, fit: 0.13333333333333333
    Epoch 70, Loss: 1.7561866988862596
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.5900457611831054e-07
    epoch : 71 ; learning_rate : 4.5900457611831054e-07 ; fit : 0.13333333333333333
    batch_size :          60
    best_batch_loss : 1.4644882437888769
    Epoch 71, Loss: 1.75532854935491, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.950327758840019e-07
    epoch : 72 ; learning_rate : 4.950327758840019e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4669776825489655
    Epoch 72, Loss: 1.75450947361874, fit: 0.15
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.569870435380344e-07
    epoch : 73 ; learning_rate : 4.569870435380344e-07 ; fit : 0.15
    batch_size :          60
    best_batch_loss : 1.531004669635649
    Epoch 73, Loss: 1.7537043990774532, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.117451923133858e-07
    epoch : 74 ; learning_rate : 5.117451923133858e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5122449157945517
    Epoch 74, Loss: 1.7528976465914796, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.921049324468114e-07
    epoch : 75 ; learning_rate : 4.921049324468114e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.4397800428879715
    Epoch 75, Loss: 1.7520944516243087, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.876086639562966e-07
    epoch : 76 ; learning_rate : 4.876086639562966e-07 ; fit : 0.11666666666666667
    batch_size :          60
    best_batch_loss : 1.472823561954697
    Epoch 76, Loss: 1.7512848137298662, fit: 0.08333333333333333
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.56133814107736e-07
    epoch : 77 ; learning_rate : 5.56133814107736e-07 ; fit : 0.08333333333333333
    batch_size :          60
    best_batch_loss : 1.4504898273231808
    Epoch 77, Loss: 1.7504611925863136, fit: 0.05
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.113377205059734e-07
    epoch : 78 ; learning_rate : 6.113377205059734e-07 ; fit : 0.05
    batch_size :          60
    best_batch_loss : 1.5120058324377534
    Epoch 78, Loss: 1.7495150628557914, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.7411128486078035e-07
    epoch : 79 ; learning_rate : 4.7411128486078035e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.4278837145591758
    Epoch 79, Loss: 1.7487047871558443, fit: 0.1
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.236339323689625e-07
    epoch : 80 ; learning_rate : 5.236339323689625e-07 ; fit : 0.1
    batch_size :          60
    best_batch_loss : 1.5139088666272689
    Epoch 80, Loss: 1.7479211840261253, fit: 0.06666666666666667
    Epoch 80, Loss: 1.7479211840261253
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              6.097502586725144e-07
    epoch : 81 ; learning_rate : 6.097502586725144e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.4312070143635742
    Epoch 81, Loss: 1.7470626582502513, fit: 0.06666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              5.96433077856698e-07
    epoch : 82 ; learning_rate : 5.96433077856698e-07 ; fit : 0.06666666666666667
    batch_size :          60
    best_batch_loss : 1.492362721340939
    Epoch 82, Loss: 1.746170268570461, fit: 0.11666666666666667
      batch rate adapted learning_rate :              0.0001
      loss adapted learning_rate :              4.984250138592766e-07
    epoch : 83 ; learning_rate : 4.984250138592766e-07 ; fit : 0.11666666666666667
    batch_size :          60
